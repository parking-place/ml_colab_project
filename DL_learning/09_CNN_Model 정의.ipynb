{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "n1-HdRR266M6",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convolutional Neural Network 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "CPU = \"cpu\"\n",
    "print(DEVICE, CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(4, 2, kernel_size=(3, 3), stride=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "layer = nn.Conv2d(in_channels=4,        # 입력 채널 수\n",
    "                    out_channels=2,     # 출력 채널 수\n",
    "                    kernel_size=3,      # 커널 크기 (3, 3) == 3\n",
    "                    stride=1,           # 스트라이드 (1, 1) == 1 default = 1\n",
    "                    padding=0,          # 패딩 (1, 1) == 1 default = 0\n",
    "                    )\n",
    "print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# layer.weight / layer.bias => layer의 파라미터\n",
    "layer.weight.shape\n",
    "# [2, 4, 3, 3] -> [out_channels, -> 필터의 갯수 \n",
    "#                  in_channels,  -> 입력 채널 수\n",
    "#                  kernel_size,  -> 커널 크기(height)\n",
    "#                  kernel_size  -> 커널 크기(width)\n",
    "#                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.1146, -0.1394], requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.bias\n",
    "# [2] -> [out_channels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data =  torch.ones(1, 4, 3, 3) # 데이터의 갯수: 1, ch:3, h:3, w:3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.2505, grad_fn=<AddBackward0>),\n",
       " tensor(0.0274, grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch1 = torch.sum(input_data[0, 0] * layer.weight[0, 0])\n",
    "ch2 = torch.sum(input_data[0, 1] * layer.weight[0, 1])\n",
    "ch3 = torch.sum(input_data[0, 2] * layer.weight[0, 2])\n",
    "ch4 = torch.sum(input_data[0, 3] * layer.weight[0, 3])\n",
    "\n",
    "result = ch1 + ch2 + ch3 + ch4 + layer.bias[0].item()\n",
    "\n",
    "ch1 = torch.sum(input_data[0, 0] * layer.weight[1, 0])\n",
    "ch2 = torch.sum(input_data[0, 1] * layer.weight[1, 1])\n",
    "ch3 = torch.sum(input_data[0, 2] * layer.weight[1, 2])\n",
    "ch4 = torch.sum(input_data[0, 3] * layer.weight[1, 3])\n",
    "\n",
    "result2 = ch1 + ch2 + ch3 + ch4 + layer.bias[1].item()\n",
    "\n",
    "result, result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.2505]],\n",
       "\n",
       "         [[ 0.0274]]]], grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result3 = layer(input_data)\n",
    "result3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, datasets, transforms\n",
    "from torchinfo import summary\n",
    "from module.data import load_mnist_dataset, load_fashion_mnist_dataset\n",
    "from module.train import fit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "CPU = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT_PATH =  'datasets'\n",
    "MODEL_SAVE_PATH = 'models'\n",
    "\n",
    "N_EPOCH = 1\n",
    "BATCH_SIZE = 128\n",
    "LR = 0.001\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "CPU = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = load_fashion_mnist_dataset(DATASET_ROOT_PATH, BATCH_SIZE, is_train=True)\n",
    "test_loader = load_fashion_mnist_dataset(DATASET_ROOT_PATH, BATCH_SIZE, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset FashionMNIST\n",
       "     Number of datapoints: 60000\n",
       "     Root location: datasets\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "            ),\n",
       " Dataset FashionMNIST\n",
       "     Number of datapoints: 10000\n",
       "     Root location: datasets\n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "            ))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset, test_loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 모델 정의\n",
    "#   Conv Layer: filter의 갯수(out channels)는 뒤로 갈수록 크게 한다.\n",
    "#   출력결과 (Feature Map)의 크기는 점점 줄여나간다. => Max Pooling\n",
    "# 1. Conv + ReLU + MaxPool\n",
    "# 2. Conv + BatchNorm + ReLU + MaxPool\n",
    "# 3. Conv + BatchNorm + ReLU + Dropout + MaxPool\n",
    "\n",
    "class FMnistCNNModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.block1 = nn.Sequential(nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),   # 3x3 필터, stride=1, padding=1 == output size = input size\n",
    "                                    nn.BatchNorm2d(32),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Dropout2d(0.3),\n",
    "                                    nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "                                    )\n",
    "        \n",
    "        self.block2 = nn.Sequential(nn.Conv2d(32, 64, kernel_size=3, padding='same'),       # padding='same' == padding=1\n",
    "                                    nn.BatchNorm2d(64),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Dropout2d(0.3),\n",
    "                                    nn.MaxPool2d(kernel_size=2),                 # stride가 kernel_size와 같으면 stride 생략 가능\n",
    "                                    )\n",
    "        \n",
    "        self.block3 = nn.Sequential(nn.Conv2d(64, 128, kernel_size=3, padding='same'),\n",
    "                                    nn.BatchNorm2d(128),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Dropout2d(0.3),\n",
    "                                    nn.MaxPool2d(kernel_size=2),\n",
    "                                    )\n",
    "        \n",
    "        self.output_block = nn.Sequential(\n",
    "                                    nn.Flatten(),\n",
    "                                    nn.Linear(128 * 3 * 3, 512),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Dropout(0.3),\n",
    "                                    nn.Linear(512, 10),\n",
    "                                    )\n",
    "        \n",
    "        self.blocks = nn.Sequential(self.block1, self.block2, self.block3, self.output_block)\n",
    "        \n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        out = self.blocks(X)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "FMnistCNNModel                           [128, 10]                 --\n",
       "├─Sequential: 1-1                        [128, 10]                 --\n",
       "│    └─Sequential: 2-1                   [128, 32, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-1                  [128, 32, 28, 28]         320\n",
       "│    │    └─BatchNorm2d: 3-2             [128, 32, 28, 28]         64\n",
       "│    │    └─ReLU: 3-3                    [128, 32, 28, 28]         --\n",
       "│    │    └─Dropout2d: 3-4               [128, 32, 28, 28]         --\n",
       "│    │    └─MaxPool2d: 3-5               [128, 32, 14, 14]         --\n",
       "│    └─Sequential: 2-2                   [128, 64, 7, 7]           --\n",
       "│    │    └─Conv2d: 3-6                  [128, 64, 14, 14]         18,496\n",
       "│    │    └─BatchNorm2d: 3-7             [128, 64, 14, 14]         128\n",
       "│    │    └─ReLU: 3-8                    [128, 64, 14, 14]         --\n",
       "│    │    └─Dropout2d: 3-9               [128, 64, 14, 14]         --\n",
       "│    │    └─MaxPool2d: 3-10              [128, 64, 7, 7]           --\n",
       "│    └─Sequential: 2-3                   [128, 128, 3, 3]          --\n",
       "│    │    └─Conv2d: 3-11                 [128, 128, 7, 7]          73,856\n",
       "│    │    └─BatchNorm2d: 3-12            [128, 128, 7, 7]          256\n",
       "│    │    └─ReLU: 3-13                   [128, 128, 7, 7]          --\n",
       "│    │    └─Dropout2d: 3-14              [128, 128, 7, 7]          --\n",
       "│    │    └─MaxPool2d: 3-15              [128, 128, 3, 3]          --\n",
       "│    └─Sequential: 2-4                   [128, 10]                 --\n",
       "│    │    └─Flatten: 3-16                [128, 1152]               --\n",
       "│    │    └─Linear: 3-17                 [128, 512]                590,336\n",
       "│    │    └─ReLU: 3-18                   [128, 512]                --\n",
       "│    │    └─Dropout: 3-19                [128, 512]                --\n",
       "│    │    └─Linear: 3-20                 [128, 10]                 5,130\n",
       "==========================================================================================\n",
       "Total params: 688,586\n",
       "Trainable params: 688,586\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 1.04\n",
       "==========================================================================================\n",
       "Input size (MB): 0.40\n",
       "Forward/backward pass size (MB): 90.45\n",
       "Params size (MB): 2.75\n",
       "Estimated Total Size (MB): 93.61\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FMnistCNNModel().to(DEVICE)\n",
    "summary(model, input_size=(BATCH_SIZE, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (10) must match the size of tensor b (128) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m loss_fn \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m     14\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mLR)\n\u001b[0;32m---> 16\u001b[0m rseult \u001b[39m=\u001b[39m fit(train_loader\u001b[39m=\u001b[39;49mtrain_loader, val_loader\u001b[39m=\u001b[39;49mtest_loader, model\u001b[39m=\u001b[39;49mmodel, loss_fn\u001b[39m=\u001b[39;49mloss_fn, optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m     17\u001b[0m             epochs\u001b[39m=\u001b[39;49mN_EPOCH, device\u001b[39m=\u001b[39;49mDEVICE, save_best_model\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, save_model_path\u001b[39m=\u001b[39;49mSAVE_MODEL_PATH \u001b[39m+\u001b[39;49m model_name,\n\u001b[1;32m     18\u001b[0m             early_stopping\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, patience\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, lr_scheduler\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/ml/ml_colab_project/DL_learning/module/train.py:150\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(train_loader, val_loader, model, loss_fn, optimizer, epochs, save_best_model, save_model_path, early_stopping, patience, device, mode, lr_scheduler)\u001b[0m\n\u001b[1;32m    147\u001b[0m s \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    148\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m    149\u001b[0m     \u001b[39m### 학습\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m     train_loss, train_accuracy \u001b[39m=\u001b[39m train(train_loader, model, loss_fn, optimizer, \n\u001b[1;32m    151\u001b[0m                                         device\u001b[39m=\u001b[39;49mdevice, mode\u001b[39m=\u001b[39;49mmode)\n\u001b[1;32m    153\u001b[0m     \u001b[39m### 학습률 업데이트\u001b[39;00m\n\u001b[1;32m    154\u001b[0m     \u001b[39mif\u001b[39;00m lr_scheduler:\n",
      "File \u001b[0;32m~/ml/ml_colab_project/DL_learning/module/train.py:96\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer, device, mode)\u001b[0m\n\u001b[1;32m     93\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     95\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 96\u001b[0m     train_loss, train_accuracy \u001b[39m=\u001b[39m test_binary_classification(dataloader, model, loss_fn, device)\n\u001b[1;32m     97\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     98\u001b[0m     train_loss, train_accuracy \u001b[39m=\u001b[39m test_multi_classification(dataloader, model, loss_fn, device)\n",
      "File \u001b[0;32m~/ml/ml_colab_project/DL_learning/module/train.py:63\u001b[0m, in \u001b[0;36mtest_binary_classification\u001b[0;34m(dataloader, model, loss_fn, device)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[39m## 정확도 계산\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     pred_label \u001b[39m=\u001b[39m (pred \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m)\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mint32)\n\u001b[0;32m---> 63\u001b[0m     test_accuracy \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (pred_label \u001b[39m==\u001b[39;49m y)\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mitem() \n\u001b[1;32m     65\u001b[0m test_loss \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m num_batches\n\u001b[1;32m     66\u001b[0m test_accuracy \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m size   \u001b[39m#전체 개수로 나눈다.\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (10) must match the size of tensor b (128) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "DATASET_ROOT_PATH =  './datasets'\n",
    "SAVE_MODEL_PATH = './models/FashionMNIST/'\n",
    "model_name = 'fashion_mnist_cnn_model.pth'\n",
    "\n",
    "N_EPOCH = 1\n",
    "BATCH_SIZE = 128\n",
    "LR = 0.001\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "CPU = \"cpu\"\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "rseult = fit(train_loader=train_loader, val_loader=test_loader, model=model, loss_fn=loss_fn, optimizer=optimizer,\n",
    "            epochs=N_EPOCH, device=DEVICE, save_best_model=False, save_model_path=SAVE_MODEL_PATH + model_name,\n",
    "            early_stopping=True, patience=10, lr_scheduler=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun 13 06:33:42 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:0B:00.0 Off |                  N/A |\n",
      "| 77%   39C    P8    16W / 170W |   1506MiB / 12288MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1803      C   ...conda3/envs/ml/bin/python     1504MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "2ARCyjDW66NR",
    "6bAN1wPG66NS",
    "shNUg6al66NV",
    "7xgQxAU666NZ"
   ],
   "name": "07_CNN_MNIST분류, 모델저장.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
