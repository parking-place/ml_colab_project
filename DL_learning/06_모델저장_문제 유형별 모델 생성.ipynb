{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 저장\n",
    "\n",
    "- 학습한 모델을 저장장치에 파일로 저장하고 나중에 불러와 사용(추가 학습, 예측 서비스) 할 수 있도록 한다. \n",
    "- 파이토치는 모델의 파라미터만 저장하는 방법과 모델 구조와 파라미터 모두를 저장하는 두가지 방식을 제공한다.\n",
    "- 저장 함수\n",
    "    - `torch.save(저장할 객체, 저장경로)`\n",
    "- 보통 저장파일의 확장자는 `pt`나 `pth` 를 지정한다.\n",
    "\n",
    "## 모델 전체 저장하기 및 불러오기\n",
    "\n",
    "- 저장하기\n",
    "    - `torch.save(model, 저장경로)`\n",
    "- 불러오기\n",
    "    - `load_model = torch.load(저장경로)`\n",
    "- 저장시 **pickle**을 이용해 직렬화하기 때문에 불어오는 실행환경에도 모델을 저장할 때 사용한 클래스가 있어야 한다.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 모델의 파라미터만 저장\n",
    "- 모델을 구성하는 파라미터만 저장한다.\n",
    "- 모델의 구조는 저장하지 않기 때문에 불러올 때 **모델을 먼저 생성하고 생성한 모델에 불러온 파라미터를 덮어씌운다.**\n",
    "- 모델의 파라미터는 **state_dict** 형식으로 저장한다.\n",
    "\n",
    "### state_dict\n",
    "- 모델의 파라미터 Tensor들을 레이어 단위별로 나누어 저장한 Ordered Dictionary (OrderedDict)\n",
    "- `모델객체.state_dict()` 메소드를 이용해 조회한다.\n",
    "- 모델의 state_dict을 조회 후 저장한다.\n",
    "    - `torch.save(model.state_dict(), \"저장경로\")`\n",
    "- 생성된 모델에 읽어온 state_dict를 덮어씌운다.\n",
    "    - `new_model.load_state_dict(torch.load(\"state_dict저장경로\"))`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lr = nn.Linear(28*28, 64)\n",
    "        self.lr2 = nn.Linear(64, 32)\n",
    "        self.lr3 = nn.Linear(32, 10)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = torch.flatten(X, start_dim=1)\n",
    "        X = nn.ReLU()(self.lr(X))\n",
    "        X = nn.ReLU()(self.lr2(X))\n",
    "        X = (self.lr3(X))\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (lr): Linear(in_features=784, out_features=64, bias=True)\n",
       "  (lr2): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (lr3): Linear(in_features=32, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# state_dict 조회\n",
    "sample_model = Network()\n",
    "sample_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['lr.weight', 'lr.bias', 'lr2.weight', 'lr2.bias', 'lr3.weight', 'lr3.bias'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd = sample_model.state_dict()\n",
    "sd.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 784])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd['lr.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7f29dacfedc0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path  = r'./models/{model_target}/{file_name}'\n",
    "model_file_name = r'{model_name}_{YYMMDDhhmm}.pth'\n",
    "\n",
    "def get_timestamp():\n",
    "    import datetime\n",
    "    return datetime.datetime.now().strftime('%Y%m%d%H%M')\n",
    "\n",
    "def get_path(model_name, model_target):\n",
    "    file_name = model_file_name.format(model_name=model_name, YYMMDDhhmm=get_timestamp())\n",
    "    return save_path.format(model_target=model_target, file_name=file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint를 저장 및 불러오기\n",
    "- 학습이 끝나지 않은 모델을 저장 후 나중에 이어서 학습시킬 경우에는 모델의 구조, 파라미터 뿐만 아니라 optimizer, loss 함수등 학습에 필요한 객체들을 저장해야 한다.\n",
    "- Dictionary에 필요한 요소들을 key-value 쌍으로 저장후 `torch.save()`를 이용해 저장한다.\n",
    "```python\n",
    "# 저장\n",
    "torch.save({\n",
    "    'epoch':epoch,                                  # 현재 학습 epoch\n",
    "    'model_state_dict':model.state_dict(),          # 모델 저장\n",
    "    'optimizer_state_dict':optimizer.state_dict(),  # 옵티마이저 저장\n",
    "    'loss':train_loss                               # 현재 학습 loss\n",
    "}, \"저장경로\")\n",
    "\n",
    "# 불러오기\n",
    "model = MyModel()                           # 모델 생성\n",
    "optimizer = optim.Adam(model.parameter())   # 옵티마이저 생성\n",
    "\n",
    "checkpoint = torch.load(\"저장경로\")                             # 저장된 모델 불러오기\n",
    "model.load_state_dict(checkpoint['model_state_dict'])           # 모델 불러오기\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])   # 옵티마이저 불러오기\n",
    "epoch = checkpoint['epoch']                                     # 현재 학습 epoch\n",
    "loss = checkpoint['loss']                                       # 현재 학습 loss\n",
    "\n",
    "#### 이어학습 -> train 모드로 변경\n",
    "model.train()\n",
    "#### 추론     -> eval 모드로 변경\n",
    "model.eval()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path  = r'./models/{model_target}/{file_name}'\n",
    "model_file_name = r'{model_name}_{times}.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 문제 유형별 MLP 네트워크\n",
    "- MLP(Multi Layer Perceptron)\n",
    "    - Fully Connected Layer로 구성된 네트워크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('cuda', 'cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import time\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torchinfo\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "CPU = 'cpu'\n",
    "\n",
    "DEVICE, CPU"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Regression(회귀)\n",
    "\n",
    "## Boston Housing Dataset\n",
    "보스턴 주택가격 dataset은 다음과 같은 속성을 바탕으로 해당 타운 주택 가격의 중앙값을 예측하는 문제.\n",
    "- CRIM: 범죄율\n",
    "- ZN: 25,000 평방피트당 주거지역 비율\n",
    "- INDUS: 비소매 상업지구 비율\n",
    "- CHAS: 찰스강에 인접해 있는지 여부(인접:1, 아니면:0)\n",
    "- NOX: 일산화질소 농도(단위: 0.1ppm)\n",
    "- RM: 주택당 방의 수\n",
    "- AGE: 1940년 이전에 건설된 주택의 비율\n",
    "- DIS: 5개의 보스턴 직업고용센터와의 거리(가중 평균)\n",
    "- RAD: 고속도로 접근성\n",
    "- TAX: 재산세율\n",
    "- PTRATIO: 학생/교사 비율\n",
    "- B: 흑인 비율\n",
    "- LSTAT: 하위 계층 비율\n",
    "<br><br>\n",
    "- **Target**\n",
    "    - MEDV: 타운의 주택가격 중앙값(단위: 1,000달러)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset, DataLoader 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((506, 13), (506, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston = pd.read_csv(r'./data/boston_hosing.csv')\n",
    "boston.shape\n",
    "\n",
    "X_boston = boston.drop(columns='MEDV').values\n",
    "y_boston = boston['MEDV'].values.reshape(-1,1)\n",
    "X_boston.shape, y_boston.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404, 13), (102, 13), (404, 1), (102, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train, test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_boston, y_boston, test_size=0.2, random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = torch.tensor(scaler.fit_transform(X_train), dtype=torch.float32)\n",
    "X_test_scaled = torch.tensor(scaler.transform(X_test), dtype=torch.float32)\n",
    "\n",
    "# y를 tensor로 변환\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404 102\n",
      "(tensor([-0.3726, -0.4996, -0.7049,  3.6645, -0.4249,  0.9357,  0.6937, -0.4372,\n",
      "        -0.1622, -0.5617, -0.4846,  0.3717, -0.4110]), tensor([26.7000]))\n",
      "2 1\n"
     ]
    }
   ],
   "source": [
    "# Dataset, DataLoader 생성\n",
    "\n",
    "# Dataset\n",
    "boston_train_dataset = TensorDataset(X_train_scaled, y_train_tensor)\n",
    "boston_test_dataset = TensorDataset(X_test_scaled, y_test_tensor)\n",
    "\n",
    "print(len(boston_train_dataset), len(boston_test_dataset))\n",
    "print(boston_train_dataset[0])\n",
    "\n",
    "\n",
    "# DataLoader\n",
    "boston_train_loader = DataLoader(boston_train_dataset,\n",
    "                                batch_size=202, \n",
    "                                shuffle=True,\n",
    "                                drop_last=True\n",
    "                                )\n",
    "\n",
    "boston_test_loader = DataLoader(boston_test_dataset,\n",
    "                                batch_size=len(boston_test_dataset),\n",
    "                                )\n",
    "\n",
    "# epoch당 step 수\n",
    "print(len(boston_train_loader), len(boston_test_loader))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BostonModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 입력 layer -> in_features: input data의 feature 수\n",
    "        self.input_lr = nn.Linear(13, 32)\n",
    "        # hidden layer -> in_features: 이전 layer의 output feature 수\n",
    "        self.hidden_lr = nn.Linear(32, 16)\n",
    "        # 출력 layer -> in_features: 이전 layer의 output feature 수\n",
    "        #               out_features: output data의 feature 수\n",
    "        # regression이므로 output_feature 수는 1\n",
    "        self.output_lr = nn.Linear(16, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, X):\n",
    "        # input layer\n",
    "        X_out = self.input_lr(X)      # 입력 layer에 input data를 넣어 output을 계산\n",
    "        X_in = nn.ReLU()(X_out)       # 비선형 함수를 통과시켜줌\n",
    "        # hidden layer\n",
    "        X_out = self.hidden_lr(X_in)  # hidden layer에 input data를 넣어 output을 계산\n",
    "        X_in = nn.ReLU()(X_out)       # 비선형 함수를 통과시켜줌\n",
    "        # output layer - output layer는 activation function을 사용하지 않음\n",
    "        #   예외: 출력결과가 특정 활성함수의 출력과 매칭되어야 하는 경우\n",
    "        #       output: 0~1 -> sigmoid, logistic\n",
    "        #       output: -1~1 -> tanh(hyperbolic tangent)\n",
    "        X_out = self.output_lr(X_in)  # 출력 layer에 input data를 넣어 output을 계산\n",
    "        \n",
    "        return X_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "BostonModel                              [202, 1]                  --\n",
       "├─Linear: 1-1                            [202, 32]                 448\n",
       "├─Linear: 1-2                            [202, 16]                 528\n",
       "├─Linear: 1-3                            [202, 1]                  17\n",
       "==========================================================================================\n",
       "Total params: 993\n",
       "Trainable params: 993\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.20\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 0.08\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.09\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_model = BostonModel()\n",
    "torchinfo.summary(boston_model, input_size=(202, 13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_RPOCH = 1000\n",
    "LEARNING_RATE = 0.001\n",
    "# 결과 저장용 list\n",
    "train_loss_list = []\n",
    "val_loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델, loss function, optimizer 정의\n",
    "# 모델 정의\n",
    "boston_model = BostonModel()\n",
    "# 모델 -> GPU로 이동\n",
    "boston_model = boston_model.to(DEVICE)\n",
    "# loss function\n",
    "loss_func = nn.MSELoss()\n",
    "# optimizer\n",
    "# RMSprop : Adam보다 더 빠르게 수렴하는 경향이 있음\n",
    "optimizer = torch.optim.RMSprop(boston_model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1000] train_loss: 604.20230 val_loss: 575.63550\n",
      "[2/1000] train_loss: 595.28299 val_loss: 566.55725\n",
      "[3/1000] train_loss: 585.89227 val_loss: 556.38715\n",
      "[4/1000] train_loss: 575.19965 val_loss: 545.25415\n",
      "[5/1000] train_loss: 563.27594 val_loss: 533.39331\n",
      "[6/1000] train_loss: 550.44360 val_loss: 520.72961\n",
      "[7/1000] train_loss: 536.77644 val_loss: 507.32440\n",
      "[8/1000] train_loss: 522.01015 val_loss: 493.02017\n",
      "[9/1000] train_loss: 506.25868 val_loss: 477.93362\n",
      "[10/1000] train_loss: 489.55354 val_loss: 462.22601\n",
      "[11/1000] train_loss: 472.24699 val_loss: 446.01526\n",
      "[12/1000] train_loss: 454.39766 val_loss: 429.49060\n",
      "[13/1000] train_loss: 436.25023 val_loss: 412.87024\n",
      "[14/1000] train_loss: 418.00928 val_loss: 396.22263\n",
      "[15/1000] train_loss: 399.74998 val_loss: 379.71191\n",
      "[16/1000] train_loss: 381.65648 val_loss: 363.44388\n",
      "[17/1000] train_loss: 363.80603 val_loss: 347.48990\n",
      "[18/1000] train_loss: 346.27390 val_loss: 331.94708\n",
      "[19/1000] train_loss: 329.28313 val_loss: 316.87839\n",
      "[20/1000] train_loss: 312.70425 val_loss: 302.36945\n",
      "[21/1000] train_loss: 296.72462 val_loss: 288.43668\n",
      "[22/1000] train_loss: 281.40291 val_loss: 275.11847\n",
      "[23/1000] train_loss: 266.69275 val_loss: 262.37234\n",
      "[24/1000] train_loss: 252.67387 val_loss: 250.20665\n",
      "[25/1000] train_loss: 239.26678 val_loss: 238.46732\n",
      "[26/1000] train_loss: 226.22582 val_loss: 227.06625\n",
      "[27/1000] train_loss: 213.64764 val_loss: 216.33514\n",
      "[28/1000] train_loss: 201.83558 val_loss: 206.33824\n",
      "[29/1000] train_loss: 190.89857 val_loss: 197.04192\n",
      "[30/1000] train_loss: 180.61804 val_loss: 188.43221\n",
      "[31/1000] train_loss: 171.17107 val_loss: 180.47777\n",
      "[32/1000] train_loss: 162.49735 val_loss: 173.11778\n",
      "[33/1000] train_loss: 154.42728 val_loss: 166.31396\n",
      "[34/1000] train_loss: 147.01533 val_loss: 160.03873\n",
      "[35/1000] train_loss: 140.20141 val_loss: 154.21321\n",
      "[36/1000] train_loss: 133.89466 val_loss: 148.81898\n",
      "[37/1000] train_loss: 128.10092 val_loss: 143.80986\n",
      "[38/1000] train_loss: 122.70117 val_loss: 139.15599\n",
      "[39/1000] train_loss: 117.71251 val_loss: 134.83339\n",
      "[40/1000] train_loss: 113.11382 val_loss: 130.79106\n",
      "[41/1000] train_loss: 108.84484 val_loss: 127.00692\n",
      "[42/1000] train_loss: 104.85135 val_loss: 123.47376\n",
      "[43/1000] train_loss: 101.12313 val_loss: 120.15086\n",
      "[44/1000] train_loss: 97.65853 val_loss: 117.02951\n",
      "[45/1000] train_loss: 94.38990 val_loss: 114.08085\n",
      "[46/1000] train_loss: 91.37280 val_loss: 111.29934\n",
      "[47/1000] train_loss: 88.47110 val_loss: 108.65213\n",
      "[48/1000] train_loss: 85.70586 val_loss: 106.13757\n",
      "[49/1000] train_loss: 83.15115 val_loss: 103.74612\n",
      "[50/1000] train_loss: 80.70084 val_loss: 101.47028\n",
      "[51/1000] train_loss: 78.40759 val_loss: 99.29592\n",
      "[52/1000] train_loss: 76.15797 val_loss: 97.21671\n",
      "[53/1000] train_loss: 74.08767 val_loss: 95.23332\n",
      "[54/1000] train_loss: 72.09289 val_loss: 93.33521\n",
      "[55/1000] train_loss: 70.14724 val_loss: 91.52448\n",
      "[56/1000] train_loss: 68.37259 val_loss: 89.79431\n",
      "[57/1000] train_loss: 66.57012 val_loss: 88.13448\n",
      "[58/1000] train_loss: 64.89141 val_loss: 86.54221\n",
      "[59/1000] train_loss: 63.27873 val_loss: 85.02496\n",
      "[60/1000] train_loss: 61.76386 val_loss: 83.57095\n",
      "[61/1000] train_loss: 60.27558 val_loss: 82.16661\n",
      "[62/1000] train_loss: 58.92112 val_loss: 80.81908\n",
      "[63/1000] train_loss: 57.47214 val_loss: 79.53075\n",
      "[64/1000] train_loss: 56.16260 val_loss: 78.29007\n",
      "[65/1000] train_loss: 54.94408 val_loss: 77.10285\n",
      "[66/1000] train_loss: 53.69515 val_loss: 75.95751\n",
      "[67/1000] train_loss: 52.54393 val_loss: 74.85472\n",
      "[68/1000] train_loss: 51.42598 val_loss: 73.79633\n",
      "[69/1000] train_loss: 50.37933 val_loss: 72.77225\n",
      "[70/1000] train_loss: 49.32746 val_loss: 71.79630\n",
      "[71/1000] train_loss: 48.33545 val_loss: 70.85076\n",
      "[72/1000] train_loss: 47.38924 val_loss: 69.94308\n",
      "[73/1000] train_loss: 46.46533 val_loss: 69.07458\n",
      "[74/1000] train_loss: 45.57934 val_loss: 68.24216\n",
      "[75/1000] train_loss: 44.75373 val_loss: 67.43568\n",
      "[76/1000] train_loss: 43.92462 val_loss: 66.66856\n",
      "[77/1000] train_loss: 43.14892 val_loss: 65.93481\n",
      "[78/1000] train_loss: 42.39162 val_loss: 65.22543\n",
      "[79/1000] train_loss: 41.68271 val_loss: 64.54034\n",
      "[80/1000] train_loss: 40.97775 val_loss: 63.88523\n",
      "[81/1000] train_loss: 40.33376 val_loss: 63.25301\n",
      "[82/1000] train_loss: 39.69237 val_loss: 62.64631\n",
      "[83/1000] train_loss: 39.07366 val_loss: 62.06172\n",
      "[84/1000] train_loss: 38.48709 val_loss: 61.49690\n",
      "[85/1000] train_loss: 37.93164 val_loss: 60.95717\n",
      "[86/1000] train_loss: 37.36684 val_loss: 60.44205\n",
      "[87/1000] train_loss: 36.85030 val_loss: 59.95131\n",
      "[88/1000] train_loss: 36.35845 val_loss: 59.48002\n",
      "[89/1000] train_loss: 35.87609 val_loss: 59.02230\n",
      "[90/1000] train_loss: 35.42070 val_loss: 58.57532\n",
      "[91/1000] train_loss: 34.97522 val_loss: 58.15055\n",
      "[92/1000] train_loss: 34.55296 val_loss: 57.73805\n",
      "[93/1000] train_loss: 34.15352 val_loss: 57.33597\n",
      "[94/1000] train_loss: 33.75561 val_loss: 56.94508\n",
      "[95/1000] train_loss: 33.40041 val_loss: 56.56007\n",
      "[96/1000] train_loss: 33.01505 val_loss: 56.19634\n",
      "[97/1000] train_loss: 32.66949 val_loss: 55.84089\n",
      "[98/1000] train_loss: 32.32492 val_loss: 55.49877\n",
      "[99/1000] train_loss: 32.00079 val_loss: 55.17480\n",
      "[100/1000] train_loss: 31.70010 val_loss: 54.85171\n",
      "[101/1000] train_loss: 31.40500 val_loss: 54.55198\n",
      "[102/1000] train_loss: 31.08587 val_loss: 54.25355\n",
      "[103/1000] train_loss: 30.82261 val_loss: 53.96063\n",
      "[104/1000] train_loss: 30.56084 val_loss: 53.68270\n",
      "[105/1000] train_loss: 30.30124 val_loss: 53.41315\n",
      "[106/1000] train_loss: 30.02705 val_loss: 53.14903\n",
      "[107/1000] train_loss: 29.77895 val_loss: 52.89000\n",
      "[108/1000] train_loss: 29.55541 val_loss: 52.64117\n",
      "[109/1000] train_loss: 29.33731 val_loss: 52.39214\n",
      "[110/1000] train_loss: 29.09272 val_loss: 52.14313\n",
      "[111/1000] train_loss: 28.93537 val_loss: 51.90696\n",
      "[112/1000] train_loss: 28.66987 val_loss: 51.67129\n",
      "[113/1000] train_loss: 28.48606 val_loss: 51.44481\n",
      "[114/1000] train_loss: 28.29299 val_loss: 51.21495\n",
      "[115/1000] train_loss: 28.09992 val_loss: 50.98447\n",
      "[116/1000] train_loss: 27.90281 val_loss: 50.76431\n",
      "[117/1000] train_loss: 27.71317 val_loss: 50.54782\n",
      "[118/1000] train_loss: 27.52929 val_loss: 50.32872\n",
      "[119/1000] train_loss: 27.35873 val_loss: 50.11368\n",
      "[120/1000] train_loss: 27.20570 val_loss: 49.90058\n",
      "[121/1000] train_loss: 27.02493 val_loss: 49.69191\n",
      "[122/1000] train_loss: 26.86123 val_loss: 49.48373\n",
      "[123/1000] train_loss: 26.71849 val_loss: 49.27223\n",
      "[124/1000] train_loss: 26.54993 val_loss: 49.08179\n",
      "[125/1000] train_loss: 26.38961 val_loss: 48.88751\n",
      "[126/1000] train_loss: 26.24728 val_loss: 48.69812\n",
      "[127/1000] train_loss: 26.08233 val_loss: 48.50249\n",
      "[128/1000] train_loss: 25.94315 val_loss: 48.30470\n",
      "[129/1000] train_loss: 25.80555 val_loss: 48.11966\n",
      "[130/1000] train_loss: 25.68841 val_loss: 47.93954\n",
      "[131/1000] train_loss: 25.51807 val_loss: 47.74554\n",
      "[132/1000] train_loss: 25.38134 val_loss: 47.55004\n",
      "[133/1000] train_loss: 25.24707 val_loss: 47.36020\n",
      "[134/1000] train_loss: 25.13987 val_loss: 47.16111\n",
      "[135/1000] train_loss: 24.97408 val_loss: 46.97091\n",
      "[136/1000] train_loss: 24.84275 val_loss: 46.79237\n",
      "[137/1000] train_loss: 24.70568 val_loss: 46.61215\n",
      "[138/1000] train_loss: 24.57852 val_loss: 46.42577\n",
      "[139/1000] train_loss: 24.45786 val_loss: 46.23553\n",
      "[140/1000] train_loss: 24.30024 val_loss: 46.04760\n",
      "[141/1000] train_loss: 24.20301 val_loss: 45.87685\n",
      "[142/1000] train_loss: 24.06258 val_loss: 45.68375\n",
      "[143/1000] train_loss: 23.92559 val_loss: 45.50830\n",
      "[144/1000] train_loss: 23.81876 val_loss: 45.33504\n",
      "[145/1000] train_loss: 23.68723 val_loss: 45.15237\n",
      "[146/1000] train_loss: 23.55834 val_loss: 44.97249\n",
      "[147/1000] train_loss: 23.43653 val_loss: 44.78625\n",
      "[148/1000] train_loss: 23.30635 val_loss: 44.61463\n",
      "[149/1000] train_loss: 23.19003 val_loss: 44.43863\n",
      "[150/1000] train_loss: 23.06692 val_loss: 44.25684\n",
      "[151/1000] train_loss: 22.94288 val_loss: 44.08783\n",
      "[152/1000] train_loss: 22.83154 val_loss: 43.90601\n",
      "[153/1000] train_loss: 22.71559 val_loss: 43.72426\n",
      "[154/1000] train_loss: 22.60743 val_loss: 43.56186\n",
      "[155/1000] train_loss: 22.46808 val_loss: 43.38195\n",
      "[156/1000] train_loss: 22.38519 val_loss: 43.22590\n",
      "[157/1000] train_loss: 22.23580 val_loss: 43.04257\n",
      "[158/1000] train_loss: 22.10822 val_loss: 42.86798\n",
      "[159/1000] train_loss: 21.99631 val_loss: 42.70544\n",
      "[160/1000] train_loss: 21.92974 val_loss: 42.55012\n",
      "[161/1000] train_loss: 21.76495 val_loss: 42.37985\n",
      "[162/1000] train_loss: 21.63581 val_loss: 42.20327\n",
      "[163/1000] train_loss: 21.51995 val_loss: 42.02661\n",
      "[164/1000] train_loss: 21.42230 val_loss: 41.83912\n",
      "[165/1000] train_loss: 21.31766 val_loss: 41.67955\n",
      "[166/1000] train_loss: 21.17718 val_loss: 41.49613\n",
      "[167/1000] train_loss: 21.06112 val_loss: 41.31738\n",
      "[168/1000] train_loss: 20.96969 val_loss: 41.13247\n",
      "[169/1000] train_loss: 20.85384 val_loss: 40.97574\n",
      "[170/1000] train_loss: 20.72728 val_loss: 40.81093\n",
      "[171/1000] train_loss: 20.67597 val_loss: 40.62371\n",
      "[172/1000] train_loss: 20.52062 val_loss: 40.46570\n",
      "[173/1000] train_loss: 20.41377 val_loss: 40.28592\n",
      "[174/1000] train_loss: 20.28269 val_loss: 40.12759\n",
      "[175/1000] train_loss: 20.16565 val_loss: 39.96504\n",
      "[176/1000] train_loss: 20.06066 val_loss: 39.81483\n",
      "[177/1000] train_loss: 19.93837 val_loss: 39.64298\n",
      "[178/1000] train_loss: 19.83513 val_loss: 39.47930\n",
      "[179/1000] train_loss: 19.76971 val_loss: 39.28812\n",
      "[180/1000] train_loss: 19.61325 val_loss: 39.12916\n",
      "[181/1000] train_loss: 19.54656 val_loss: 38.97164\n",
      "[182/1000] train_loss: 19.42443 val_loss: 38.80803\n",
      "[183/1000] train_loss: 19.31950 val_loss: 38.68115\n",
      "[184/1000] train_loss: 19.26620 val_loss: 38.54191\n",
      "[185/1000] train_loss: 19.11557 val_loss: 38.40144\n",
      "[186/1000] train_loss: 18.98957 val_loss: 38.24151\n",
      "[187/1000] train_loss: 18.91127 val_loss: 38.09067\n",
      "[188/1000] train_loss: 18.81735 val_loss: 37.95574\n",
      "[189/1000] train_loss: 18.67441 val_loss: 37.78290\n",
      "[190/1000] train_loss: 18.56596 val_loss: 37.63128\n",
      "[191/1000] train_loss: 18.47025 val_loss: 37.46581\n",
      "[192/1000] train_loss: 18.36157 val_loss: 37.30357\n",
      "[193/1000] train_loss: 18.27549 val_loss: 37.18238\n",
      "[194/1000] train_loss: 18.17841 val_loss: 37.03344\n",
      "[195/1000] train_loss: 18.04244 val_loss: 36.87869\n",
      "[196/1000] train_loss: 17.95025 val_loss: 36.73074\n",
      "[197/1000] train_loss: 17.84485 val_loss: 36.57210\n",
      "[198/1000] train_loss: 17.74106 val_loss: 36.42177\n",
      "[199/1000] train_loss: 17.64278 val_loss: 36.28094\n",
      "[200/1000] train_loss: 17.55244 val_loss: 36.14187\n",
      "[201/1000] train_loss: 17.48643 val_loss: 35.97164\n",
      "[202/1000] train_loss: 17.42130 val_loss: 35.84402\n",
      "[203/1000] train_loss: 17.25934 val_loss: 35.71482\n",
      "[204/1000] train_loss: 17.14096 val_loss: 35.56270\n",
      "[205/1000] train_loss: 17.06326 val_loss: 35.42699\n",
      "[206/1000] train_loss: 16.94752 val_loss: 35.27386\n",
      "[207/1000] train_loss: 16.87723 val_loss: 35.13931\n",
      "[208/1000] train_loss: 16.79484 val_loss: 34.99371\n",
      "[209/1000] train_loss: 16.67287 val_loss: 34.84009\n",
      "[210/1000] train_loss: 16.61353 val_loss: 34.73157\n",
      "[211/1000] train_loss: 16.52754 val_loss: 34.59520\n",
      "[212/1000] train_loss: 16.39114 val_loss: 34.46090\n",
      "[213/1000] train_loss: 16.29519 val_loss: 34.33673\n",
      "[214/1000] train_loss: 16.22140 val_loss: 34.16542\n",
      "[215/1000] train_loss: 16.12937 val_loss: 34.04178\n",
      "[216/1000] train_loss: 16.04143 val_loss: 33.90680\n",
      "[217/1000] train_loss: 15.94835 val_loss: 33.76076\n",
      "[218/1000] train_loss: 15.86833 val_loss: 33.66525\n",
      "[219/1000] train_loss: 15.80258 val_loss: 33.54311\n",
      "[220/1000] train_loss: 15.68247 val_loss: 33.40034\n",
      "[221/1000] train_loss: 15.59843 val_loss: 33.25804\n",
      "[222/1000] train_loss: 15.51418 val_loss: 33.15751\n",
      "[223/1000] train_loss: 15.50190 val_loss: 33.09233\n",
      "[224/1000] train_loss: 15.35346 val_loss: 32.94364\n",
      "[225/1000] train_loss: 15.25910 val_loss: 32.81804\n",
      "[226/1000] train_loss: 15.18685 val_loss: 32.69896\n",
      "[227/1000] train_loss: 15.11494 val_loss: 32.59179\n",
      "[228/1000] train_loss: 15.00420 val_loss: 32.45452\n",
      "[229/1000] train_loss: 14.93536 val_loss: 32.34453\n",
      "[230/1000] train_loss: 14.89486 val_loss: 32.21688\n",
      "[231/1000] train_loss: 14.78212 val_loss: 32.09747\n",
      "[232/1000] train_loss: 14.71071 val_loss: 31.95266\n",
      "[233/1000] train_loss: 14.65583 val_loss: 31.81069\n",
      "[234/1000] train_loss: 14.57717 val_loss: 31.73838\n",
      "[235/1000] train_loss: 14.49071 val_loss: 31.66620\n",
      "[236/1000] train_loss: 14.43400 val_loss: 31.54989\n",
      "[237/1000] train_loss: 14.31421 val_loss: 31.44796\n",
      "[238/1000] train_loss: 14.23799 val_loss: 31.30632\n",
      "[239/1000] train_loss: 14.19691 val_loss: 31.24350\n",
      "[240/1000] train_loss: 14.06412 val_loss: 31.12597\n",
      "[241/1000] train_loss: 13.99363 val_loss: 31.00852\n",
      "[242/1000] train_loss: 13.98398 val_loss: 30.92247\n",
      "[243/1000] train_loss: 13.86529 val_loss: 30.76323\n",
      "[244/1000] train_loss: 13.78261 val_loss: 30.62914\n",
      "[245/1000] train_loss: 13.72639 val_loss: 30.54015\n",
      "[246/1000] train_loss: 13.63957 val_loss: 30.39372\n",
      "[247/1000] train_loss: 13.56730 val_loss: 30.34607\n",
      "[248/1000] train_loss: 13.46779 val_loss: 30.22555\n",
      "[249/1000] train_loss: 13.40262 val_loss: 30.12086\n",
      "[250/1000] train_loss: 13.33375 val_loss: 30.02230\n",
      "[251/1000] train_loss: 13.28114 val_loss: 29.91653\n",
      "[252/1000] train_loss: 13.17513 val_loss: 29.80566\n",
      "[253/1000] train_loss: 13.11683 val_loss: 29.72696\n",
      "[254/1000] train_loss: 13.04749 val_loss: 29.63597\n",
      "[255/1000] train_loss: 12.97780 val_loss: 29.52487\n",
      "[256/1000] train_loss: 12.89518 val_loss: 29.43207\n",
      "[257/1000] train_loss: 12.80832 val_loss: 29.34989\n",
      "[258/1000] train_loss: 12.82675 val_loss: 29.19950\n",
      "[259/1000] train_loss: 12.72327 val_loss: 29.15651\n",
      "[260/1000] train_loss: 12.62156 val_loss: 29.06819\n",
      "[261/1000] train_loss: 12.55545 val_loss: 28.94232\n",
      "[262/1000] train_loss: 12.50374 val_loss: 28.86096\n",
      "[263/1000] train_loss: 12.41539 val_loss: 28.77924\n",
      "[264/1000] train_loss: 12.37365 val_loss: 28.65810\n",
      "[265/1000] train_loss: 12.28556 val_loss: 28.61381\n",
      "[266/1000] train_loss: 12.22331 val_loss: 28.52489\n",
      "[267/1000] train_loss: 12.16258 val_loss: 28.40390\n",
      "[268/1000] train_loss: 12.11391 val_loss: 28.25311\n",
      "[269/1000] train_loss: 12.08412 val_loss: 28.27250\n",
      "[270/1000] train_loss: 11.96375 val_loss: 28.16307\n",
      "[271/1000] train_loss: 11.91975 val_loss: 27.99851\n",
      "[272/1000] train_loss: 11.85420 val_loss: 27.93893\n",
      "[273/1000] train_loss: 11.85956 val_loss: 27.87679\n",
      "[274/1000] train_loss: 11.74457 val_loss: 27.79679\n",
      "[275/1000] train_loss: 11.66081 val_loss: 27.74098\n",
      "[276/1000] train_loss: 11.68644 val_loss: 27.64315\n",
      "[277/1000] train_loss: 11.54458 val_loss: 27.55664\n",
      "[278/1000] train_loss: 11.52925 val_loss: 27.45942\n",
      "[279/1000] train_loss: 11.43574 val_loss: 27.39284\n",
      "[280/1000] train_loss: 11.38299 val_loss: 27.32647\n",
      "[281/1000] train_loss: 11.32500 val_loss: 27.23059\n",
      "[282/1000] train_loss: 11.32092 val_loss: 27.22482\n",
      "[283/1000] train_loss: 11.21615 val_loss: 27.10469\n",
      "[284/1000] train_loss: 11.25363 val_loss: 27.06130\n",
      "[285/1000] train_loss: 11.11349 val_loss: 26.94613\n",
      "[286/1000] train_loss: 11.04682 val_loss: 26.86015\n",
      "[287/1000] train_loss: 10.97986 val_loss: 26.73449\n",
      "[288/1000] train_loss: 10.93653 val_loss: 26.62531\n",
      "[289/1000] train_loss: 10.95365 val_loss: 26.49284\n",
      "[290/1000] train_loss: 10.83350 val_loss: 26.46671\n",
      "[291/1000] train_loss: 10.78963 val_loss: 26.37492\n",
      "[292/1000] train_loss: 10.70331 val_loss: 26.30991\n",
      "[293/1000] train_loss: 10.67356 val_loss: 26.22638\n",
      "[294/1000] train_loss: 10.61871 val_loss: 26.14962\n",
      "[295/1000] train_loss: 10.61858 val_loss: 26.11834\n",
      "[296/1000] train_loss: 10.52163 val_loss: 26.02744\n",
      "[297/1000] train_loss: 10.48541 val_loss: 25.97914\n",
      "[298/1000] train_loss: 10.43563 val_loss: 25.94238\n",
      "[299/1000] train_loss: 10.40277 val_loss: 25.80030\n",
      "[300/1000] train_loss: 10.33978 val_loss: 25.73501\n",
      "[301/1000] train_loss: 10.30728 val_loss: 25.64523\n",
      "[302/1000] train_loss: 10.24895 val_loss: 25.63366\n",
      "[303/1000] train_loss: 10.29053 val_loss: 25.52885\n",
      "[304/1000] train_loss: 10.14381 val_loss: 25.41832\n",
      "[305/1000] train_loss: 10.08612 val_loss: 25.37161\n",
      "[306/1000] train_loss: 10.11438 val_loss: 25.38187\n",
      "[307/1000] train_loss: 10.03735 val_loss: 25.29182\n",
      "[308/1000] train_loss: 10.01497 val_loss: 25.30561\n",
      "[309/1000] train_loss: 9.99062 val_loss: 25.24681\n",
      "[310/1000] train_loss: 9.87815 val_loss: 25.07034\n",
      "[311/1000] train_loss: 9.82847 val_loss: 25.01047\n",
      "[312/1000] train_loss: 9.79824 val_loss: 24.95675\n",
      "[313/1000] train_loss: 9.73999 val_loss: 24.90260\n",
      "[314/1000] train_loss: 9.87268 val_loss: 24.91148\n",
      "[315/1000] train_loss: 9.65879 val_loss: 24.76468\n",
      "[316/1000] train_loss: 9.61845 val_loss: 24.68208\n",
      "[317/1000] train_loss: 9.58217 val_loss: 24.55994\n",
      "[318/1000] train_loss: 9.56729 val_loss: 24.55436\n",
      "[319/1000] train_loss: 9.55248 val_loss: 24.42716\n",
      "[320/1000] train_loss: 9.50183 val_loss: 24.43522\n",
      "[321/1000] train_loss: 9.42032 val_loss: 24.32901\n",
      "[322/1000] train_loss: 9.39270 val_loss: 24.20118\n",
      "[323/1000] train_loss: 9.42591 val_loss: 24.07141\n",
      "[324/1000] train_loss: 9.38270 val_loss: 23.99767\n",
      "[325/1000] train_loss: 9.28484 val_loss: 23.98151\n",
      "[326/1000] train_loss: 9.25956 val_loss: 24.07071\n",
      "[327/1000] train_loss: 9.19425 val_loss: 23.97709\n",
      "[328/1000] train_loss: 9.16739 val_loss: 24.00865\n",
      "[329/1000] train_loss: 9.13924 val_loss: 23.89256\n",
      "[330/1000] train_loss: 9.11990 val_loss: 23.77365\n",
      "[331/1000] train_loss: 9.12024 val_loss: 23.80571\n",
      "[332/1000] train_loss: 9.03778 val_loss: 23.66526\n",
      "[333/1000] train_loss: 9.01091 val_loss: 23.70676\n",
      "[334/1000] train_loss: 8.97783 val_loss: 23.68207\n",
      "[335/1000] train_loss: 8.91134 val_loss: 23.56359\n",
      "[336/1000] train_loss: 8.96134 val_loss: 23.35509\n",
      "[337/1000] train_loss: 8.88374 val_loss: 23.40493\n",
      "[338/1000] train_loss: 8.80692 val_loss: 23.34412\n",
      "[339/1000] train_loss: 8.87290 val_loss: 23.33563\n",
      "[340/1000] train_loss: 8.75076 val_loss: 23.31204\n",
      "[341/1000] train_loss: 8.79405 val_loss: 23.11753\n",
      "[342/1000] train_loss: 8.70064 val_loss: 23.05651\n",
      "[343/1000] train_loss: 8.64973 val_loss: 23.14289\n",
      "[344/1000] train_loss: 8.83794 val_loss: 23.31957\n",
      "[345/1000] train_loss: 8.58440 val_loss: 23.07346\n",
      "[346/1000] train_loss: 8.63722 val_loss: 22.83313\n",
      "[347/1000] train_loss: 8.54289 val_loss: 22.85869\n",
      "[348/1000] train_loss: 8.51920 val_loss: 22.78773\n",
      "[349/1000] train_loss: 8.45826 val_loss: 22.80374\n",
      "[350/1000] train_loss: 8.46037 val_loss: 22.73474\n",
      "[351/1000] train_loss: 8.39665 val_loss: 22.76924\n",
      "[352/1000] train_loss: 8.39480 val_loss: 22.60252\n",
      "[353/1000] train_loss: 8.38520 val_loss: 22.65776\n",
      "[354/1000] train_loss: 8.33279 val_loss: 22.50700\n",
      "[355/1000] train_loss: 8.31602 val_loss: 22.46246\n",
      "[356/1000] train_loss: 8.26876 val_loss: 22.42810\n",
      "[357/1000] train_loss: 8.24774 val_loss: 22.43875\n",
      "[358/1000] train_loss: 8.28889 val_loss: 22.54727\n",
      "[359/1000] train_loss: 8.20204 val_loss: 22.43107\n",
      "[360/1000] train_loss: 8.18640 val_loss: 22.32445\n",
      "[361/1000] train_loss: 8.17308 val_loss: 22.37165\n",
      "[362/1000] train_loss: 8.12941 val_loss: 22.19987\n",
      "[363/1000] train_loss: 8.20344 val_loss: 22.27617\n",
      "[364/1000] train_loss: 8.09416 val_loss: 22.22852\n",
      "[365/1000] train_loss: 8.04118 val_loss: 22.18788\n",
      "[366/1000] train_loss: 8.05704 val_loss: 22.18427\n",
      "[367/1000] train_loss: 8.00401 val_loss: 22.11705\n",
      "[368/1000] train_loss: 8.01855 val_loss: 21.99107\n",
      "[369/1000] train_loss: 7.97424 val_loss: 22.08492\n",
      "[370/1000] train_loss: 7.93689 val_loss: 21.95680\n",
      "[371/1000] train_loss: 7.91121 val_loss: 21.89702\n",
      "[372/1000] train_loss: 7.88049 val_loss: 21.89093\n",
      "[373/1000] train_loss: 7.89385 val_loss: 21.72848\n",
      "[374/1000] train_loss: 7.82915 val_loss: 21.82727\n",
      "[375/1000] train_loss: 7.82515 val_loss: 21.78826\n",
      "[376/1000] train_loss: 7.83383 val_loss: 21.62626\n",
      "[377/1000] train_loss: 7.79552 val_loss: 21.66529\n",
      "[378/1000] train_loss: 7.78595 val_loss: 21.72099\n",
      "[379/1000] train_loss: 7.75066 val_loss: 21.64020\n",
      "[380/1000] train_loss: 7.70959 val_loss: 21.64388\n",
      "[381/1000] train_loss: 7.71763 val_loss: 21.60347\n",
      "[382/1000] train_loss: 7.67358 val_loss: 21.52104\n",
      "[383/1000] train_loss: 7.67101 val_loss: 21.50465\n",
      "[384/1000] train_loss: 7.65253 val_loss: 21.46425\n",
      "[385/1000] train_loss: 7.61326 val_loss: 21.41326\n",
      "[386/1000] train_loss: 7.65569 val_loss: 21.40955\n",
      "[387/1000] train_loss: 7.61183 val_loss: 21.44175\n",
      "[388/1000] train_loss: 7.57028 val_loss: 21.30980\n",
      "[389/1000] train_loss: 7.60506 val_loss: 21.34848\n",
      "[390/1000] train_loss: 7.54789 val_loss: 21.26884\n",
      "[391/1000] train_loss: 7.50630 val_loss: 21.30264\n",
      "[392/1000] train_loss: 7.50359 val_loss: 21.38635\n",
      "[393/1000] train_loss: 7.46703 val_loss: 21.24613\n",
      "[394/1000] train_loss: 7.46068 val_loss: 21.35109\n",
      "[395/1000] train_loss: 7.48273 val_loss: 21.28293\n",
      "[396/1000] train_loss: 7.41174 val_loss: 21.21895\n",
      "[397/1000] train_loss: 7.39220 val_loss: 21.22017\n",
      "[398/1000] train_loss: 7.50172 val_loss: 21.35427\n",
      "[399/1000] train_loss: 7.44485 val_loss: 21.11835\n",
      "[400/1000] train_loss: 7.35766 val_loss: 21.11202\n",
      "[401/1000] train_loss: 7.36559 val_loss: 21.16112\n",
      "[402/1000] train_loss: 7.43499 val_loss: 20.86992\n",
      "[403/1000] train_loss: 7.35093 val_loss: 21.19249\n",
      "[404/1000] train_loss: 7.38519 val_loss: 20.99405\n",
      "[405/1000] train_loss: 7.40265 val_loss: 20.95667\n",
      "[406/1000] train_loss: 7.32277 val_loss: 20.94101\n",
      "[407/1000] train_loss: 7.26692 val_loss: 20.87594\n",
      "[408/1000] train_loss: 7.25798 val_loss: 20.80160\n",
      "[409/1000] train_loss: 7.25914 val_loss: 20.78271\n",
      "[410/1000] train_loss: 7.22120 val_loss: 20.79648\n",
      "[411/1000] train_loss: 7.22750 val_loss: 20.81912\n",
      "[412/1000] train_loss: 7.16641 val_loss: 20.81995\n",
      "[413/1000] train_loss: 7.20608 val_loss: 20.98295\n",
      "[414/1000] train_loss: 7.23493 val_loss: 20.90326\n",
      "[415/1000] train_loss: 7.15194 val_loss: 20.65810\n",
      "[416/1000] train_loss: 7.11229 val_loss: 20.64790\n",
      "[417/1000] train_loss: 7.07796 val_loss: 20.72118\n",
      "[418/1000] train_loss: 7.08356 val_loss: 20.69294\n",
      "[419/1000] train_loss: 7.07925 val_loss: 20.68233\n",
      "[420/1000] train_loss: 7.05273 val_loss: 20.68662\n",
      "[421/1000] train_loss: 7.07582 val_loss: 20.74960\n",
      "[422/1000] train_loss: 7.03574 val_loss: 20.57812\n",
      "[423/1000] train_loss: 7.03062 val_loss: 20.53659\n",
      "[424/1000] train_loss: 7.00560 val_loss: 20.56749\n",
      "[425/1000] train_loss: 6.99546 val_loss: 20.46057\n",
      "[426/1000] train_loss: 7.04609 val_loss: 20.53811\n",
      "[427/1000] train_loss: 6.95273 val_loss: 20.45762\n",
      "[428/1000] train_loss: 6.96990 val_loss: 20.76190\n",
      "[429/1000] train_loss: 6.94384 val_loss: 20.43290\n",
      "[430/1000] train_loss: 6.98468 val_loss: 20.38826\n",
      "[431/1000] train_loss: 6.94973 val_loss: 20.36724\n",
      "[432/1000] train_loss: 6.91109 val_loss: 20.49187\n",
      "[433/1000] train_loss: 6.90411 val_loss: 20.58084\n",
      "[434/1000] train_loss: 6.90973 val_loss: 20.65064\n",
      "[435/1000] train_loss: 6.91870 val_loss: 20.44411\n",
      "[436/1000] train_loss: 6.87327 val_loss: 20.50973\n",
      "[437/1000] train_loss: 6.86430 val_loss: 20.43421\n",
      "[438/1000] train_loss: 6.83560 val_loss: 20.29920\n",
      "[439/1000] train_loss: 6.84767 val_loss: 20.27378\n",
      "[440/1000] train_loss: 6.83543 val_loss: 20.40250\n",
      "[441/1000] train_loss: 6.78493 val_loss: 20.42911\n",
      "[442/1000] train_loss: 6.76788 val_loss: 20.33595\n",
      "[443/1000] train_loss: 6.75880 val_loss: 20.35978\n",
      "[444/1000] train_loss: 6.75098 val_loss: 20.27356\n",
      "[445/1000] train_loss: 6.74608 val_loss: 20.23777\n",
      "[446/1000] train_loss: 6.74918 val_loss: 20.36711\n",
      "[447/1000] train_loss: 6.72405 val_loss: 20.19964\n",
      "[448/1000] train_loss: 6.70546 val_loss: 20.38840\n",
      "[449/1000] train_loss: 6.70595 val_loss: 20.37370\n",
      "[450/1000] train_loss: 6.71781 val_loss: 20.20603\n",
      "[451/1000] train_loss: 6.68174 val_loss: 20.28605\n",
      "[452/1000] train_loss: 6.67761 val_loss: 20.17329\n",
      "[453/1000] train_loss: 6.70879 val_loss: 20.07790\n",
      "[454/1000] train_loss: 6.65171 val_loss: 20.29206\n",
      "[455/1000] train_loss: 6.62919 val_loss: 20.03844\n",
      "[456/1000] train_loss: 6.62573 val_loss: 20.15920\n",
      "[457/1000] train_loss: 6.59765 val_loss: 20.17390\n",
      "[458/1000] train_loss: 6.58838 val_loss: 20.19676\n",
      "[459/1000] train_loss: 6.61468 val_loss: 20.11303\n",
      "[460/1000] train_loss: 6.58163 val_loss: 19.99278\n",
      "[461/1000] train_loss: 6.57090 val_loss: 20.12384\n",
      "[462/1000] train_loss: 6.58977 val_loss: 20.21689\n",
      "[463/1000] train_loss: 6.57588 val_loss: 20.03247\n",
      "[464/1000] train_loss: 6.53061 val_loss: 19.98710\n",
      "[465/1000] train_loss: 6.52681 val_loss: 19.89187\n",
      "[466/1000] train_loss: 6.54394 val_loss: 20.00321\n",
      "[467/1000] train_loss: 6.51834 val_loss: 20.03981\n",
      "[468/1000] train_loss: 6.52364 val_loss: 20.02449\n",
      "[469/1000] train_loss: 6.51064 val_loss: 20.10404\n",
      "[470/1000] train_loss: 6.51212 val_loss: 19.96047\n",
      "[471/1000] train_loss: 6.55808 val_loss: 19.96656\n",
      "[472/1000] train_loss: 6.46111 val_loss: 19.90371\n",
      "[473/1000] train_loss: 6.43633 val_loss: 19.87432\n",
      "[474/1000] train_loss: 6.48501 val_loss: 19.75163\n",
      "[475/1000] train_loss: 6.46133 val_loss: 19.66662\n",
      "[476/1000] train_loss: 6.45299 val_loss: 19.66998\n",
      "[477/1000] train_loss: 6.41293 val_loss: 19.74676\n",
      "[478/1000] train_loss: 6.40626 val_loss: 19.93459\n",
      "[479/1000] train_loss: 6.39371 val_loss: 19.67978\n",
      "[480/1000] train_loss: 6.36998 val_loss: 19.77511\n",
      "[481/1000] train_loss: 6.34515 val_loss: 19.79258\n",
      "[482/1000] train_loss: 6.34668 val_loss: 19.70794\n",
      "[483/1000] train_loss: 6.48221 val_loss: 20.03827\n",
      "[484/1000] train_loss: 6.37450 val_loss: 19.89298\n",
      "[485/1000] train_loss: 6.33075 val_loss: 19.70465\n",
      "[486/1000] train_loss: 6.34973 val_loss: 19.72273\n",
      "[487/1000] train_loss: 6.31118 val_loss: 19.88514\n",
      "[488/1000] train_loss: 6.35075 val_loss: 19.96915\n",
      "[489/1000] train_loss: 6.32261 val_loss: 19.81447\n",
      "[490/1000] train_loss: 6.28007 val_loss: 19.62667\n",
      "[491/1000] train_loss: 6.28067 val_loss: 19.55609\n",
      "[492/1000] train_loss: 6.29137 val_loss: 19.61905\n",
      "[493/1000] train_loss: 6.29906 val_loss: 19.68180\n",
      "[494/1000] train_loss: 6.24854 val_loss: 19.64693\n",
      "[495/1000] train_loss: 6.26618 val_loss: 19.65136\n",
      "[496/1000] train_loss: 6.27255 val_loss: 19.55610\n",
      "[497/1000] train_loss: 6.29713 val_loss: 19.70929\n",
      "[498/1000] train_loss: 6.25269 val_loss: 19.63416\n",
      "[499/1000] train_loss: 6.29658 val_loss: 19.76815\n",
      "[500/1000] train_loss: 6.19641 val_loss: 19.52700\n",
      "[501/1000] train_loss: 6.19912 val_loss: 19.61295\n",
      "[502/1000] train_loss: 6.18247 val_loss: 19.58051\n",
      "[503/1000] train_loss: 6.18106 val_loss: 19.41874\n",
      "[504/1000] train_loss: 6.27224 val_loss: 19.95329\n",
      "[505/1000] train_loss: 6.18747 val_loss: 19.45018\n",
      "[506/1000] train_loss: 6.16139 val_loss: 19.59097\n",
      "[507/1000] train_loss: 6.14275 val_loss: 19.56539\n",
      "[508/1000] train_loss: 6.15806 val_loss: 19.44451\n",
      "[509/1000] train_loss: 6.12166 val_loss: 19.38108\n",
      "[510/1000] train_loss: 6.18232 val_loss: 19.76231\n",
      "[511/1000] train_loss: 6.17965 val_loss: 19.55358\n",
      "[512/1000] train_loss: 6.16209 val_loss: 19.19945\n",
      "[513/1000] train_loss: 6.16800 val_loss: 19.40512\n",
      "[514/1000] train_loss: 6.08019 val_loss: 19.43338\n",
      "[515/1000] train_loss: 6.15982 val_loss: 19.31908\n",
      "[516/1000] train_loss: 6.09032 val_loss: 19.49062\n",
      "[517/1000] train_loss: 6.21728 val_loss: 19.60492\n",
      "[518/1000] train_loss: 6.09931 val_loss: 19.28240\n",
      "[519/1000] train_loss: 6.05681 val_loss: 19.26225\n",
      "[520/1000] train_loss: 6.05891 val_loss: 19.17292\n",
      "[521/1000] train_loss: 6.15092 val_loss: 19.26227\n",
      "[522/1000] train_loss: 6.09031 val_loss: 19.39106\n",
      "[523/1000] train_loss: 6.03201 val_loss: 19.17503\n",
      "[524/1000] train_loss: 5.99923 val_loss: 19.34743\n",
      "[525/1000] train_loss: 6.04549 val_loss: 19.41987\n",
      "[526/1000] train_loss: 6.01668 val_loss: 19.25792\n",
      "[527/1000] train_loss: 5.99737 val_loss: 19.42689\n",
      "[528/1000] train_loss: 5.98366 val_loss: 19.29563\n",
      "[529/1000] train_loss: 5.99025 val_loss: 19.19893\n",
      "[530/1000] train_loss: 5.99529 val_loss: 19.20514\n",
      "[531/1000] train_loss: 6.01196 val_loss: 19.05387\n",
      "[532/1000] train_loss: 5.96615 val_loss: 19.25223\n",
      "[533/1000] train_loss: 5.93395 val_loss: 19.17308\n",
      "[534/1000] train_loss: 5.92834 val_loss: 19.17249\n",
      "[535/1000] train_loss: 5.96166 val_loss: 19.20311\n",
      "[536/1000] train_loss: 5.93882 val_loss: 19.02670\n",
      "[537/1000] train_loss: 5.93679 val_loss: 19.40954\n",
      "[538/1000] train_loss: 5.97975 val_loss: 19.03790\n",
      "[539/1000] train_loss: 6.01024 val_loss: 19.15578\n",
      "[540/1000] train_loss: 5.89434 val_loss: 18.96019\n",
      "[541/1000] train_loss: 5.89525 val_loss: 19.13985\n",
      "[542/1000] train_loss: 5.91940 val_loss: 19.09951\n",
      "[543/1000] train_loss: 5.89069 val_loss: 19.37239\n",
      "[544/1000] train_loss: 5.89539 val_loss: 19.11588\n",
      "[545/1000] train_loss: 5.84746 val_loss: 18.97954\n",
      "[546/1000] train_loss: 5.83282 val_loss: 19.15733\n",
      "[547/1000] train_loss: 5.82809 val_loss: 19.13515\n",
      "[548/1000] train_loss: 5.82647 val_loss: 18.95549\n",
      "[549/1000] train_loss: 5.84798 val_loss: 19.11141\n",
      "[550/1000] train_loss: 5.86571 val_loss: 18.98098\n",
      "[551/1000] train_loss: 5.81427 val_loss: 19.09278\n",
      "[552/1000] train_loss: 6.02446 val_loss: 19.47066\n",
      "[553/1000] train_loss: 5.87193 val_loss: 19.01516\n",
      "[554/1000] train_loss: 5.78588 val_loss: 18.97750\n",
      "[555/1000] train_loss: 5.87569 val_loss: 19.37207\n",
      "[556/1000] train_loss: 5.80726 val_loss: 18.99096\n",
      "[557/1000] train_loss: 5.79854 val_loss: 19.27065\n",
      "[558/1000] train_loss: 5.76122 val_loss: 18.89367\n",
      "[559/1000] train_loss: 5.74645 val_loss: 18.89833\n",
      "[560/1000] train_loss: 5.76673 val_loss: 18.96710\n",
      "[561/1000] train_loss: 5.73346 val_loss: 18.98575\n",
      "[562/1000] train_loss: 5.71549 val_loss: 18.87399\n",
      "[563/1000] train_loss: 5.73982 val_loss: 18.82557\n",
      "[564/1000] train_loss: 5.74144 val_loss: 18.86637\n",
      "[565/1000] train_loss: 5.74952 val_loss: 18.81221\n",
      "[566/1000] train_loss: 5.69478 val_loss: 18.89870\n",
      "[567/1000] train_loss: 5.77286 val_loss: 19.13499\n",
      "[568/1000] train_loss: 5.71318 val_loss: 18.92211\n",
      "[569/1000] train_loss: 5.69422 val_loss: 18.83707\n",
      "[570/1000] train_loss: 5.71903 val_loss: 19.15287\n",
      "[571/1000] train_loss: 5.85096 val_loss: 19.26088\n",
      "[572/1000] train_loss: 5.74994 val_loss: 19.04215\n",
      "[573/1000] train_loss: 5.73787 val_loss: 19.01109\n",
      "[574/1000] train_loss: 5.65663 val_loss: 18.74307\n",
      "[575/1000] train_loss: 5.66910 val_loss: 18.88108\n",
      "[576/1000] train_loss: 5.62916 val_loss: 18.78649\n",
      "[577/1000] train_loss: 5.70742 val_loss: 18.59883\n",
      "[578/1000] train_loss: 5.63880 val_loss: 18.87544\n",
      "[579/1000] train_loss: 5.63671 val_loss: 18.69188\n",
      "[580/1000] train_loss: 5.64842 val_loss: 18.64285\n",
      "[581/1000] train_loss: 5.63333 val_loss: 18.81142\n",
      "[582/1000] train_loss: 5.65940 val_loss: 18.74945\n",
      "[583/1000] train_loss: 5.63604 val_loss: 18.85513\n",
      "[584/1000] train_loss: 5.62270 val_loss: 18.98038\n",
      "[585/1000] train_loss: 5.59517 val_loss: 18.83714\n",
      "[586/1000] train_loss: 5.61597 val_loss: 18.92258\n",
      "[587/1000] train_loss: 5.58390 val_loss: 18.70055\n",
      "[588/1000] train_loss: 5.58420 val_loss: 18.91007\n",
      "[589/1000] train_loss: 5.58721 val_loss: 18.91322\n",
      "[590/1000] train_loss: 5.56635 val_loss: 18.87737\n",
      "[591/1000] train_loss: 5.54348 val_loss: 18.76763\n",
      "[592/1000] train_loss: 5.54842 val_loss: 18.74267\n",
      "[593/1000] train_loss: 5.60225 val_loss: 18.61257\n",
      "[594/1000] train_loss: 5.53262 val_loss: 18.56668\n",
      "[595/1000] train_loss: 5.52270 val_loss: 18.73979\n",
      "[596/1000] train_loss: 5.54637 val_loss: 18.90135\n",
      "[597/1000] train_loss: 5.53634 val_loss: 18.53751\n",
      "[598/1000] train_loss: 5.57221 val_loss: 18.44141\n",
      "[599/1000] train_loss: 5.80793 val_loss: 18.34276\n",
      "[600/1000] train_loss: 5.69999 val_loss: 18.59522\n",
      "[601/1000] train_loss: 5.49233 val_loss: 18.72801\n",
      "[602/1000] train_loss: 5.57754 val_loss: 18.57191\n",
      "[603/1000] train_loss: 5.53929 val_loss: 18.59573\n",
      "[604/1000] train_loss: 5.50020 val_loss: 18.86421\n",
      "[605/1000] train_loss: 5.47737 val_loss: 18.58245\n",
      "[606/1000] train_loss: 5.52751 val_loss: 18.49966\n",
      "[607/1000] train_loss: 5.47605 val_loss: 18.62680\n",
      "[608/1000] train_loss: 5.47038 val_loss: 18.48517\n",
      "[609/1000] train_loss: 5.45783 val_loss: 18.64203\n",
      "[610/1000] train_loss: 5.49442 val_loss: 18.45904\n",
      "[611/1000] train_loss: 5.43419 val_loss: 18.58725\n",
      "[612/1000] train_loss: 5.45430 val_loss: 18.47025\n",
      "[613/1000] train_loss: 5.45294 val_loss: 18.73854\n",
      "[614/1000] train_loss: 5.54575 val_loss: 18.86372\n",
      "[615/1000] train_loss: 5.43801 val_loss: 18.39064\n",
      "[616/1000] train_loss: 5.47436 val_loss: 18.48946\n",
      "[617/1000] train_loss: 5.42351 val_loss: 18.57599\n",
      "[618/1000] train_loss: 5.39694 val_loss: 18.46477\n",
      "[619/1000] train_loss: 5.40815 val_loss: 18.60785\n",
      "[620/1000] train_loss: 5.38949 val_loss: 18.56796\n",
      "[621/1000] train_loss: 5.44109 val_loss: 18.83874\n",
      "[622/1000] train_loss: 5.37491 val_loss: 18.46309\n",
      "[623/1000] train_loss: 5.43378 val_loss: 18.45401\n",
      "[624/1000] train_loss: 5.42356 val_loss: 18.36438\n",
      "[625/1000] train_loss: 5.38044 val_loss: 18.70700\n",
      "[626/1000] train_loss: 5.39270 val_loss: 18.55821\n",
      "[627/1000] train_loss: 5.39332 val_loss: 18.51001\n",
      "[628/1000] train_loss: 5.37959 val_loss: 18.41980\n",
      "[629/1000] train_loss: 5.37651 val_loss: 18.38908\n",
      "[630/1000] train_loss: 5.43250 val_loss: 18.41655\n",
      "[631/1000] train_loss: 5.37700 val_loss: 18.63648\n",
      "[632/1000] train_loss: 5.31708 val_loss: 18.40509\n",
      "[633/1000] train_loss: 5.33311 val_loss: 18.42544\n",
      "[634/1000] train_loss: 5.36709 val_loss: 18.41863\n",
      "[635/1000] train_loss: 5.30173 val_loss: 18.46100\n",
      "[636/1000] train_loss: 5.31937 val_loss: 18.37475\n",
      "[637/1000] train_loss: 5.34578 val_loss: 18.49565\n",
      "[638/1000] train_loss: 5.28691 val_loss: 18.34980\n",
      "[639/1000] train_loss: 5.36207 val_loss: 18.53685\n",
      "[640/1000] train_loss: 5.32971 val_loss: 18.54936\n",
      "[641/1000] train_loss: 5.27013 val_loss: 18.37594\n",
      "[642/1000] train_loss: 5.28190 val_loss: 18.59574\n",
      "[643/1000] train_loss: 5.26578 val_loss: 18.41895\n",
      "[644/1000] train_loss: 5.26946 val_loss: 18.29499\n",
      "[645/1000] train_loss: 5.29060 val_loss: 18.23007\n",
      "[646/1000] train_loss: 5.25753 val_loss: 18.51082\n",
      "[647/1000] train_loss: 5.33925 val_loss: 18.70087\n",
      "[648/1000] train_loss: 5.26052 val_loss: 18.43131\n",
      "[649/1000] train_loss: 5.23363 val_loss: 18.34749\n",
      "[650/1000] train_loss: 5.21544 val_loss: 18.38760\n",
      "[651/1000] train_loss: 5.26709 val_loss: 18.21989\n",
      "[652/1000] train_loss: 5.26430 val_loss: 18.42538\n",
      "[653/1000] train_loss: 5.25688 val_loss: 18.29441\n",
      "[654/1000] train_loss: 5.22734 val_loss: 18.45310\n",
      "[655/1000] train_loss: 5.21325 val_loss: 18.33138\n",
      "[656/1000] train_loss: 5.20775 val_loss: 18.29549\n",
      "[657/1000] train_loss: 5.21666 val_loss: 18.41145\n",
      "[658/1000] train_loss: 5.18810 val_loss: 18.27077\n",
      "[659/1000] train_loss: 5.35762 val_loss: 18.38802\n",
      "[660/1000] train_loss: 5.28617 val_loss: 18.29047\n",
      "[661/1000] train_loss: 5.16901 val_loss: 18.33081\n",
      "[662/1000] train_loss: 5.19960 val_loss: 18.20403\n",
      "[663/1000] train_loss: 5.45180 val_loss: 18.04988\n",
      "[664/1000] train_loss: 5.24414 val_loss: 18.27241\n",
      "[665/1000] train_loss: 5.20654 val_loss: 18.29713\n",
      "[666/1000] train_loss: 5.16473 val_loss: 18.17739\n",
      "[667/1000] train_loss: 5.16076 val_loss: 18.39246\n",
      "[668/1000] train_loss: 5.12046 val_loss: 18.40352\n",
      "[669/1000] train_loss: 5.14579 val_loss: 18.22012\n",
      "[670/1000] train_loss: 5.23969 val_loss: 18.10958\n",
      "[671/1000] train_loss: 5.18672 val_loss: 18.12524\n",
      "[672/1000] train_loss: 5.15790 val_loss: 18.26858\n",
      "[673/1000] train_loss: 5.14331 val_loss: 18.23559\n",
      "[674/1000] train_loss: 5.09719 val_loss: 18.23885\n",
      "[675/1000] train_loss: 5.11563 val_loss: 18.22109\n",
      "[676/1000] train_loss: 5.23569 val_loss: 18.10127\n",
      "[677/1000] train_loss: 5.15260 val_loss: 18.20663\n",
      "[678/1000] train_loss: 5.08352 val_loss: 18.25422\n",
      "[679/1000] train_loss: 5.07665 val_loss: 18.29786\n",
      "[680/1000] train_loss: 5.08984 val_loss: 18.31358\n",
      "[681/1000] train_loss: 5.06239 val_loss: 18.24759\n",
      "[682/1000] train_loss: 5.09577 val_loss: 18.40910\n",
      "[683/1000] train_loss: 5.19277 val_loss: 18.57064\n",
      "[684/1000] train_loss: 5.08625 val_loss: 18.24883\n",
      "[685/1000] train_loss: 5.11593 val_loss: 18.24142\n",
      "[686/1000] train_loss: 5.06308 val_loss: 18.06997\n",
      "[687/1000] train_loss: 5.03506 val_loss: 18.25499\n",
      "[688/1000] train_loss: 5.03835 val_loss: 18.31983\n",
      "[689/1000] train_loss: 5.03647 val_loss: 18.33189\n",
      "[690/1000] train_loss: 5.07616 val_loss: 18.19063\n",
      "[691/1000] train_loss: 5.13678 val_loss: 18.10258\n",
      "[692/1000] train_loss: 5.03486 val_loss: 18.30414\n",
      "[693/1000] train_loss: 5.06496 val_loss: 18.43334\n",
      "[694/1000] train_loss: 5.05401 val_loss: 18.42506\n",
      "[695/1000] train_loss: 5.00641 val_loss: 18.26363\n",
      "[696/1000] train_loss: 4.98571 val_loss: 18.18180\n",
      "[697/1000] train_loss: 5.01281 val_loss: 18.22504\n",
      "[698/1000] train_loss: 5.00017 val_loss: 18.42047\n",
      "[699/1000] train_loss: 5.03782 val_loss: 18.36190\n",
      "[700/1000] train_loss: 5.04992 val_loss: 18.15109\n",
      "[701/1000] train_loss: 4.99320 val_loss: 18.32335\n",
      "[702/1000] train_loss: 4.99448 val_loss: 18.12524\n",
      "[703/1000] train_loss: 4.97391 val_loss: 18.18338\n",
      "[704/1000] train_loss: 4.95245 val_loss: 18.30631\n",
      "[705/1000] train_loss: 4.96318 val_loss: 18.24450\n",
      "[706/1000] train_loss: 4.93962 val_loss: 18.34617\n",
      "[707/1000] train_loss: 4.94642 val_loss: 18.20874\n",
      "[708/1000] train_loss: 4.93159 val_loss: 18.31097\n",
      "[709/1000] train_loss: 4.92733 val_loss: 18.19156\n",
      "[710/1000] train_loss: 5.04318 val_loss: 18.12491\n",
      "[711/1000] train_loss: 4.99789 val_loss: 18.11113\n",
      "[712/1000] train_loss: 4.96894 val_loss: 18.14403\n",
      "[713/1000] train_loss: 4.90505 val_loss: 18.33090\n",
      "[714/1000] train_loss: 4.89015 val_loss: 18.17812\n",
      "[715/1000] train_loss: 4.95280 val_loss: 18.36855\n",
      "[716/1000] train_loss: 4.95549 val_loss: 18.36379\n",
      "[717/1000] train_loss: 4.91009 val_loss: 18.18741\n",
      "[718/1000] train_loss: 4.89113 val_loss: 18.30901\n",
      "[719/1000] train_loss: 4.87420 val_loss: 18.20245\n",
      "[720/1000] train_loss: 4.89551 val_loss: 18.34861\n",
      "[721/1000] train_loss: 4.87093 val_loss: 18.08213\n",
      "[722/1000] train_loss: 4.86538 val_loss: 18.25684\n",
      "[723/1000] train_loss: 4.85639 val_loss: 18.18430\n",
      "[724/1000] train_loss: 4.84361 val_loss: 18.17814\n",
      "[725/1000] train_loss: 4.88799 val_loss: 18.35006\n",
      "[726/1000] train_loss: 4.85700 val_loss: 18.07557\n",
      "[727/1000] train_loss: 4.86885 val_loss: 18.46416\n",
      "[728/1000] train_loss: 4.84519 val_loss: 17.99232\n",
      "[729/1000] train_loss: 4.82446 val_loss: 18.19794\n",
      "[730/1000] train_loss: 4.80895 val_loss: 18.15513\n",
      "[731/1000] train_loss: 4.89584 val_loss: 18.51294\n",
      "[732/1000] train_loss: 4.82395 val_loss: 18.06252\n",
      "[733/1000] train_loss: 4.86243 val_loss: 18.52890\n",
      "[734/1000] train_loss: 4.85780 val_loss: 18.22631\n",
      "[735/1000] train_loss: 4.80847 val_loss: 18.13541\n",
      "[736/1000] train_loss: 4.89316 val_loss: 18.00015\n",
      "[737/1000] train_loss: 4.89594 val_loss: 18.00159\n",
      "[738/1000] train_loss: 4.80296 val_loss: 18.21693\n",
      "[739/1000] train_loss: 4.82440 val_loss: 18.00275\n",
      "[740/1000] train_loss: 4.76713 val_loss: 18.10533\n",
      "[741/1000] train_loss: 4.80437 val_loss: 18.07877\n",
      "[742/1000] train_loss: 4.78089 val_loss: 18.29728\n",
      "[743/1000] train_loss: 4.77957 val_loss: 17.92733\n",
      "[744/1000] train_loss: 4.75205 val_loss: 18.21033\n",
      "[745/1000] train_loss: 4.74862 val_loss: 18.02676\n",
      "[746/1000] train_loss: 4.75064 val_loss: 18.22604\n",
      "[747/1000] train_loss: 4.80707 val_loss: 18.13336\n",
      "[748/1000] train_loss: 4.74656 val_loss: 18.27803\n",
      "[749/1000] train_loss: 4.74335 val_loss: 18.24745\n",
      "[750/1000] train_loss: 4.69824 val_loss: 18.11373\n",
      "[751/1000] train_loss: 4.72750 val_loss: 18.20806\n",
      "[752/1000] train_loss: 4.70694 val_loss: 18.17389\n",
      "[753/1000] train_loss: 4.71020 val_loss: 18.25858\n",
      "[754/1000] train_loss: 4.69748 val_loss: 18.14425\n",
      "[755/1000] train_loss: 4.69044 val_loss: 18.25681\n",
      "[756/1000] train_loss: 4.72889 val_loss: 18.33684\n",
      "[757/1000] train_loss: 4.69324 val_loss: 18.22762\n",
      "[758/1000] train_loss: 4.76131 val_loss: 18.51613\n",
      "[759/1000] train_loss: 4.69887 val_loss: 17.98022\n",
      "[760/1000] train_loss: 4.76358 val_loss: 18.29551\n",
      "[761/1000] train_loss: 4.66383 val_loss: 18.05260\n",
      "[762/1000] train_loss: 4.67714 val_loss: 18.24208\n",
      "[763/1000] train_loss: 4.68002 val_loss: 18.12846\n",
      "[764/1000] train_loss: 4.65645 val_loss: 17.99574\n",
      "[765/1000] train_loss: 4.64932 val_loss: 18.06440\n",
      "[766/1000] train_loss: 4.64372 val_loss: 18.08301\n",
      "[767/1000] train_loss: 4.64694 val_loss: 18.24364\n",
      "[768/1000] train_loss: 4.70118 val_loss: 18.05118\n",
      "[769/1000] train_loss: 4.72596 val_loss: 17.87759\n",
      "[770/1000] train_loss: 4.62533 val_loss: 18.16853\n",
      "[771/1000] train_loss: 4.62008 val_loss: 18.03833\n",
      "[772/1000] train_loss: 4.61257 val_loss: 17.90167\n",
      "[773/1000] train_loss: 4.65604 val_loss: 18.33344\n",
      "[774/1000] train_loss: 4.68813 val_loss: 18.20956\n",
      "[775/1000] train_loss: 4.62810 val_loss: 17.96285\n",
      "[776/1000] train_loss: 4.63417 val_loss: 18.24035\n",
      "[777/1000] train_loss: 4.59899 val_loss: 18.17740\n",
      "[778/1000] train_loss: 4.61065 val_loss: 18.13634\n",
      "[779/1000] train_loss: 4.69481 val_loss: 18.39319\n",
      "[780/1000] train_loss: 4.57718 val_loss: 17.96871\n",
      "[781/1000] train_loss: 4.63405 val_loss: 17.79105\n",
      "[782/1000] train_loss: 4.58421 val_loss: 18.13933\n",
      "[783/1000] train_loss: 4.60526 val_loss: 18.28061\n",
      "[784/1000] train_loss: 4.72467 val_loss: 18.25818\n",
      "[785/1000] train_loss: 4.56153 val_loss: 17.99563\n",
      "[786/1000] train_loss: 4.56973 val_loss: 17.94856\n",
      "[787/1000] train_loss: 4.59231 val_loss: 18.26135\n",
      "[788/1000] train_loss: 4.58231 val_loss: 17.89798\n",
      "[789/1000] train_loss: 4.52528 val_loss: 18.06833\n",
      "[790/1000] train_loss: 4.53224 val_loss: 18.00031\n",
      "[791/1000] train_loss: 4.52771 val_loss: 18.15358\n",
      "[792/1000] train_loss: 4.58790 val_loss: 18.21797\n",
      "[793/1000] train_loss: 4.56458 val_loss: 18.15345\n",
      "[794/1000] train_loss: 4.50659 val_loss: 18.07600\n",
      "[795/1000] train_loss: 4.51525 val_loss: 17.87808\n",
      "[796/1000] train_loss: 4.61318 val_loss: 18.07964\n",
      "[797/1000] train_loss: 4.53585 val_loss: 18.01653\n",
      "[798/1000] train_loss: 4.49467 val_loss: 18.19443\n",
      "[799/1000] train_loss: 4.56126 val_loss: 18.27211\n",
      "[800/1000] train_loss: 4.53395 val_loss: 17.83959\n",
      "[801/1000] train_loss: 4.55157 val_loss: 17.98803\n",
      "[802/1000] train_loss: 4.47130 val_loss: 18.12983\n",
      "[803/1000] train_loss: 4.47668 val_loss: 17.88725\n",
      "[804/1000] train_loss: 4.48656 val_loss: 17.93986\n",
      "[805/1000] train_loss: 4.47207 val_loss: 17.82733\n",
      "[806/1000] train_loss: 4.47107 val_loss: 18.07096\n",
      "[807/1000] train_loss: 4.49163 val_loss: 18.08305\n",
      "[808/1000] train_loss: 4.45521 val_loss: 18.08015\n",
      "[809/1000] train_loss: 4.46642 val_loss: 18.21889\n",
      "[810/1000] train_loss: 4.48192 val_loss: 18.20075\n",
      "[811/1000] train_loss: 4.44707 val_loss: 18.15767\n",
      "[812/1000] train_loss: 4.43528 val_loss: 18.04390\n",
      "[813/1000] train_loss: 4.43650 val_loss: 18.10910\n",
      "[814/1000] train_loss: 4.43340 val_loss: 17.89939\n",
      "[815/1000] train_loss: 4.46569 val_loss: 18.19576\n",
      "[816/1000] train_loss: 4.52533 val_loss: 18.14915\n",
      "[817/1000] train_loss: 4.64684 val_loss: 18.53163\n",
      "[818/1000] train_loss: 4.48369 val_loss: 18.00919\n",
      "[819/1000] train_loss: 4.43314 val_loss: 18.14661\n",
      "[820/1000] train_loss: 4.41616 val_loss: 18.13396\n",
      "[821/1000] train_loss: 4.38797 val_loss: 18.01363\n",
      "[822/1000] train_loss: 4.42537 val_loss: 18.17597\n",
      "[823/1000] train_loss: 4.41455 val_loss: 17.98185\n",
      "[824/1000] train_loss: 4.49534 val_loss: 17.89791\n",
      "[825/1000] train_loss: 4.38385 val_loss: 18.07172\n",
      "[826/1000] train_loss: 4.42975 val_loss: 18.15215\n",
      "[827/1000] train_loss: 4.39150 val_loss: 18.04386\n",
      "[828/1000] train_loss: 4.42925 val_loss: 17.74076\n",
      "[829/1000] train_loss: 4.36401 val_loss: 17.99773\n",
      "[830/1000] train_loss: 4.41418 val_loss: 17.76219\n",
      "[831/1000] train_loss: 4.39395 val_loss: 18.03551\n",
      "[832/1000] train_loss: 4.39368 val_loss: 17.92234\n",
      "[833/1000] train_loss: 4.40426 val_loss: 18.24962\n",
      "[834/1000] train_loss: 4.33651 val_loss: 17.97322\n",
      "[835/1000] train_loss: 4.35161 val_loss: 18.18098\n",
      "[836/1000] train_loss: 4.34712 val_loss: 18.02256\n",
      "[837/1000] train_loss: 4.47375 val_loss: 18.11016\n",
      "[838/1000] train_loss: 4.39555 val_loss: 18.10483\n",
      "[839/1000] train_loss: 4.33029 val_loss: 17.80571\n",
      "[840/1000] train_loss: 4.36264 val_loss: 18.01797\n",
      "[841/1000] train_loss: 4.36704 val_loss: 18.04532\n",
      "[842/1000] train_loss: 4.34226 val_loss: 18.14618\n",
      "[843/1000] train_loss: 4.30425 val_loss: 17.89371\n",
      "[844/1000] train_loss: 4.32670 val_loss: 17.81725\n",
      "[845/1000] train_loss: 4.30341 val_loss: 18.05103\n",
      "[846/1000] train_loss: 4.30781 val_loss: 17.89672\n",
      "[847/1000] train_loss: 4.37595 val_loss: 18.19897\n",
      "[848/1000] train_loss: 4.29659 val_loss: 17.89605\n",
      "[849/1000] train_loss: 4.27516 val_loss: 18.01677\n",
      "[850/1000] train_loss: 4.27958 val_loss: 18.11512\n",
      "[851/1000] train_loss: 4.27997 val_loss: 17.98270\n",
      "[852/1000] train_loss: 4.27724 val_loss: 18.02484\n",
      "[853/1000] train_loss: 4.28596 val_loss: 17.76293\n",
      "[854/1000] train_loss: 4.25893 val_loss: 18.05371\n",
      "[855/1000] train_loss: 4.28865 val_loss: 17.98130\n",
      "[856/1000] train_loss: 4.27757 val_loss: 17.87569\n",
      "[857/1000] train_loss: 4.24113 val_loss: 18.04280\n",
      "[858/1000] train_loss: 4.25703 val_loss: 17.88303\n",
      "[859/1000] train_loss: 4.24651 val_loss: 17.97998\n",
      "[860/1000] train_loss: 4.24094 val_loss: 17.88966\n",
      "[861/1000] train_loss: 4.24343 val_loss: 18.00975\n",
      "[862/1000] train_loss: 4.23689 val_loss: 18.06125\n",
      "[863/1000] train_loss: 4.23638 val_loss: 17.87124\n",
      "[864/1000] train_loss: 4.23408 val_loss: 17.92669\n",
      "[865/1000] train_loss: 4.24454 val_loss: 17.79735\n",
      "[866/1000] train_loss: 4.23122 val_loss: 18.23496\n",
      "[867/1000] train_loss: 4.23665 val_loss: 17.90837\n",
      "[868/1000] train_loss: 4.25040 val_loss: 17.76724\n",
      "[869/1000] train_loss: 4.21941 val_loss: 18.02341\n",
      "[870/1000] train_loss: 4.21907 val_loss: 18.21975\n",
      "[871/1000] train_loss: 4.21310 val_loss: 17.99125\n",
      "[872/1000] train_loss: 4.21362 val_loss: 18.16512\n",
      "[873/1000] train_loss: 4.30117 val_loss: 18.27505\n",
      "[874/1000] train_loss: 4.23439 val_loss: 17.94026\n",
      "[875/1000] train_loss: 4.22396 val_loss: 18.01387\n",
      "[876/1000] train_loss: 4.18001 val_loss: 18.15650\n",
      "[877/1000] train_loss: 4.22094 val_loss: 17.87344\n",
      "[878/1000] train_loss: 4.25681 val_loss: 18.00655\n",
      "[879/1000] train_loss: 4.17252 val_loss: 18.07467\n",
      "[880/1000] train_loss: 4.17188 val_loss: 17.82673\n",
      "[881/1000] train_loss: 4.18312 val_loss: 18.19636\n",
      "[882/1000] train_loss: 4.21639 val_loss: 18.13845\n",
      "[883/1000] train_loss: 4.15078 val_loss: 17.95212\n",
      "[884/1000] train_loss: 4.15476 val_loss: 17.74240\n",
      "[885/1000] train_loss: 4.15497 val_loss: 17.86975\n",
      "[886/1000] train_loss: 4.13779 val_loss: 17.89374\n",
      "[887/1000] train_loss: 4.15419 val_loss: 17.97757\n",
      "[888/1000] train_loss: 4.15630 val_loss: 17.97216\n",
      "[889/1000] train_loss: 4.11849 val_loss: 17.96799\n",
      "[890/1000] train_loss: 4.15389 val_loss: 17.67029\n",
      "[891/1000] train_loss: 4.12769 val_loss: 17.91458\n",
      "[892/1000] train_loss: 4.15241 val_loss: 17.84605\n",
      "[893/1000] train_loss: 4.17205 val_loss: 18.41507\n",
      "[894/1000] train_loss: 4.15490 val_loss: 17.74735\n",
      "[895/1000] train_loss: 4.22149 val_loss: 17.91322\n",
      "[896/1000] train_loss: 4.11213 val_loss: 17.94949\n",
      "[897/1000] train_loss: 4.15772 val_loss: 18.17082\n",
      "[898/1000] train_loss: 4.42355 val_loss: 18.36640\n",
      "[899/1000] train_loss: 4.09268 val_loss: 17.79091\n",
      "[900/1000] train_loss: 4.18983 val_loss: 18.13943\n",
      "[901/1000] train_loss: 4.12033 val_loss: 18.02940\n",
      "[902/1000] train_loss: 4.08332 val_loss: 18.10621\n",
      "[903/1000] train_loss: 4.05812 val_loss: 17.83068\n",
      "[904/1000] train_loss: 4.07806 val_loss: 18.11628\n",
      "[905/1000] train_loss: 4.10422 val_loss: 18.04487\n",
      "[906/1000] train_loss: 4.05493 val_loss: 17.87856\n",
      "[907/1000] train_loss: 4.05450 val_loss: 17.93243\n",
      "[908/1000] train_loss: 4.08494 val_loss: 18.19064\n",
      "[909/1000] train_loss: 4.05307 val_loss: 17.94480\n",
      "[910/1000] train_loss: 4.05263 val_loss: 18.08597\n",
      "[911/1000] train_loss: 4.03111 val_loss: 17.91483\n",
      "[912/1000] train_loss: 4.02606 val_loss: 18.01872\n",
      "[913/1000] train_loss: 4.06898 val_loss: 17.67109\n",
      "[914/1000] train_loss: 4.08770 val_loss: 18.02458\n",
      "[915/1000] train_loss: 4.03951 val_loss: 17.88450\n",
      "[916/1000] train_loss: 4.06494 val_loss: 18.01607\n",
      "[917/1000] train_loss: 4.03419 val_loss: 17.82228\n",
      "[918/1000] train_loss: 4.00951 val_loss: 18.02733\n",
      "[919/1000] train_loss: 4.00284 val_loss: 17.79079\n",
      "[920/1000] train_loss: 4.07806 val_loss: 17.73155\n",
      "[921/1000] train_loss: 4.06832 val_loss: 17.80472\n",
      "[922/1000] train_loss: 4.05037 val_loss: 17.69744\n",
      "[923/1000] train_loss: 3.99422 val_loss: 17.94172\n",
      "[924/1000] train_loss: 3.99374 val_loss: 17.96465\n",
      "[925/1000] train_loss: 4.14355 val_loss: 18.54272\n",
      "[926/1000] train_loss: 4.09979 val_loss: 18.12455\n",
      "[927/1000] train_loss: 4.03372 val_loss: 18.07066\n",
      "[928/1000] train_loss: 3.99559 val_loss: 17.93887\n",
      "[929/1000] train_loss: 3.98969 val_loss: 18.00123\n",
      "[930/1000] train_loss: 4.02795 val_loss: 18.15027\n",
      "[931/1000] train_loss: 3.98262 val_loss: 17.91876\n",
      "[932/1000] train_loss: 3.99495 val_loss: 18.26129\n",
      "[933/1000] train_loss: 3.98899 val_loss: 18.04657\n",
      "[934/1000] train_loss: 3.96614 val_loss: 17.97141\n",
      "[935/1000] train_loss: 3.95070 val_loss: 17.94377\n",
      "[936/1000] train_loss: 3.95994 val_loss: 17.92241\n",
      "[937/1000] train_loss: 3.96273 val_loss: 17.77833\n",
      "[938/1000] train_loss: 3.95861 val_loss: 17.82921\n",
      "[939/1000] train_loss: 3.94172 val_loss: 17.87053\n",
      "[940/1000] train_loss: 3.92388 val_loss: 17.92354\n",
      "[941/1000] train_loss: 3.97799 val_loss: 18.27435\n",
      "[942/1000] train_loss: 3.93952 val_loss: 17.80515\n",
      "[943/1000] train_loss: 3.99422 val_loss: 17.81721\n",
      "[944/1000] train_loss: 3.91698 val_loss: 18.15244\n",
      "[945/1000] train_loss: 3.94336 val_loss: 18.02852\n",
      "[946/1000] train_loss: 3.91293 val_loss: 17.76992\n",
      "[947/1000] train_loss: 3.91057 val_loss: 17.89388\n",
      "[948/1000] train_loss: 3.91110 val_loss: 17.81117\n",
      "[949/1000] train_loss: 3.92855 val_loss: 17.81429\n",
      "[950/1000] train_loss: 3.93538 val_loss: 18.04049\n",
      "[951/1000] train_loss: 3.93334 val_loss: 17.71442\n",
      "[952/1000] train_loss: 3.91876 val_loss: 17.92244\n",
      "[953/1000] train_loss: 3.90850 val_loss: 18.20223\n",
      "[954/1000] train_loss: 3.94464 val_loss: 18.18628\n",
      "[955/1000] train_loss: 3.88602 val_loss: 17.88943\n",
      "[956/1000] train_loss: 3.89509 val_loss: 17.78535\n",
      "[957/1000] train_loss: 3.88659 val_loss: 17.79808\n",
      "[958/1000] train_loss: 3.88172 val_loss: 17.72164\n",
      "[959/1000] train_loss: 3.96387 val_loss: 18.47255\n",
      "[960/1000] train_loss: 3.99438 val_loss: 17.91348\n",
      "[961/1000] train_loss: 3.90293 val_loss: 18.20557\n",
      "[962/1000] train_loss: 3.85855 val_loss: 17.88684\n",
      "[963/1000] train_loss: 3.84699 val_loss: 17.85252\n",
      "[964/1000] train_loss: 3.87699 val_loss: 18.10947\n",
      "[965/1000] train_loss: 3.85824 val_loss: 17.84419\n",
      "[966/1000] train_loss: 3.86822 val_loss: 17.79286\n",
      "[967/1000] train_loss: 3.85665 val_loss: 17.94456\n",
      "[968/1000] train_loss: 3.84352 val_loss: 17.89453\n",
      "[969/1000] train_loss: 3.91276 val_loss: 17.70267\n",
      "[970/1000] train_loss: 3.87963 val_loss: 17.86669\n",
      "[971/1000] train_loss: 3.82830 val_loss: 18.02970\n",
      "[972/1000] train_loss: 3.82400 val_loss: 17.81632\n",
      "[973/1000] train_loss: 3.82833 val_loss: 18.16129\n",
      "[974/1000] train_loss: 3.85930 val_loss: 18.07008\n",
      "[975/1000] train_loss: 3.82971 val_loss: 17.89207\n",
      "[976/1000] train_loss: 3.89826 val_loss: 17.82378\n",
      "[977/1000] train_loss: 3.90786 val_loss: 17.92554\n",
      "[978/1000] train_loss: 3.83702 val_loss: 18.20929\n",
      "[979/1000] train_loss: 3.81410 val_loss: 18.03937\n",
      "[980/1000] train_loss: 3.84193 val_loss: 17.76861\n",
      "[981/1000] train_loss: 3.93765 val_loss: 17.82253\n",
      "[982/1000] train_loss: 3.83562 val_loss: 18.30991\n",
      "[983/1000] train_loss: 3.81966 val_loss: 18.14653\n",
      "[984/1000] train_loss: 3.84997 val_loss: 17.71481\n",
      "[985/1000] train_loss: 3.80007 val_loss: 17.98814\n",
      "[986/1000] train_loss: 3.78184 val_loss: 17.80739\n",
      "[987/1000] train_loss: 3.78300 val_loss: 18.01287\n",
      "[988/1000] train_loss: 3.81627 val_loss: 17.61187\n",
      "[989/1000] train_loss: 3.80228 val_loss: 18.32644\n",
      "[990/1000] train_loss: 3.79009 val_loss: 17.83712\n",
      "[991/1000] train_loss: 3.92467 val_loss: 17.82830\n",
      "[992/1000] train_loss: 3.84155 val_loss: 18.22149\n",
      "[993/1000] train_loss: 3.96392 val_loss: 18.28743\n",
      "[994/1000] train_loss: 3.88275 val_loss: 18.10145\n",
      "[995/1000] train_loss: 3.76937 val_loss: 17.77038\n",
      "[996/1000] train_loss: 3.76933 val_loss: 17.83467\n",
      "[997/1000] train_loss: 3.77177 val_loss: 18.19818\n",
      "[998/1000] train_loss: 3.79811 val_loss: 17.82834\n",
      "[999/1000] train_loss: 3.81833 val_loss: 17.75473\n",
      "[1000/1000] train_loss: 3.80975 val_loss: 17.62517\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "# 단계 - 학습/검증\n",
    "for epoch in range(N_RPOCH):\n",
    "    ###################################\n",
    "    # 학습 단계\n",
    "    ###################################\n",
    "    # 학습 모드로 변경\n",
    "    boston_model.train()\n",
    "    # loss 계산을 위한 변수 초기화\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for X, y in boston_train_loader:\n",
    "        # DEVICE로 이동\n",
    "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "        # 1. 모델 추정\n",
    "        y_pred = boston_model(X)    # forward propagation(순전파)\n",
    "        # 2. loss 계산\n",
    "        loss = loss_func(y_pred, y) # fn(추정값, 정답)\n",
    "        # 3. gradient 계산 -> 파라미터 업데이트\n",
    "            ## 3-1. gradient를 0으로 초기화\n",
    "        optimizer.zero_grad()\n",
    "            ## 3-2. back propagation(역전파)를 통해 gradient 계산 -> grad속성에 저장\n",
    "        loss.backward()\n",
    "            ## 3-3. 파라미터 업데이트 -> 1 step\n",
    "        optimizer.step()\n",
    "        # 4. 현재 batch의 loss를 train_loss에 가산\n",
    "        train_loss += loss.item()\n",
    "    # batch에 대한 loss 평균 계산\n",
    "    train_loss /= len(boston_train_loader)\n",
    "    ######### epoch 학습 종료 #########\n",
    "    \n",
    "    ###################################\n",
    "    # 검증 단계\n",
    "    ###################################\n",
    "    # 검증 모드로 변경\n",
    "    boston_model.eval()\n",
    "    # loss 계산을 위한 변수 초기화\n",
    "    val_loss = 0.0\n",
    "    # 역전파를 통한 gradient 계산 비활성화\n",
    "    with torch.no_grad():\n",
    "        for X, y in boston_test_loader:\n",
    "            # DEVICE로 이동\n",
    "            X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "            # 1. 모델 추정\n",
    "            y_pred = boston_model(X)    # forward propagation(순전파)\n",
    "            # 2. loss 계산 및 누적\n",
    "            val_loss += loss_func(y_pred, y).item()\n",
    "    # batch에 대한 loss 평균 계산\n",
    "    val_loss /= len(boston_test_loader)\n",
    "    ######### epoch 검증 종료 #########\n",
    "    \n",
    "    #결과 출력\n",
    "    print(f'[{epoch+1}/{N_RPOCH}] train_loss: {train_loss:.5f} val_loss: {val_loss:.5f}')\n",
    "    # 결과 저장\n",
    "    train_loss_list.append(train_loss)\n",
    "    val_loss_list.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAGwCAYAAABPSaTdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABWz0lEQVR4nO3de3wU9b3/8dfsbnZz3dwgCUi4KCCg3ATFiLWtRlEQb1gvRcWj1WrBG9VaqqVWjuKh9VIVte3PSm29tFq1CmpFVFQMF6koIgIqEhSSIJB7stf5/TG7m0RQuWR3Nsv7+XjsY3dnZmc+M4HsO9/vd2YM0zRNRERERFKUw+4CREREROJJYUdERERSmsKOiIiIpDSFHREREUlpCjsiIiKS0hR2REREJKUp7IiIiEhKc9ldQDIIh8Ns2bKFnJwcDMOwuxwRERHZA6Zp0tDQQM+ePXE4vrn9RmEH2LJlC6WlpXaXISIiIvtg8+bN9OrV6xvnK+wAOTk5gHWwvF6vzdWIiIjInqivr6e0tDT2Pf5NFHYg1nXl9XoVdkRERLqY7xqCogHKIiIiktIUdkRERCSlKeyIiIhIStOYHRERSUnhcBi/3293GbIf0tLScDqd+70ehR0REUk5fr+fjRs3Eg6H7S5F9lNeXh4lJSX7dR08hR0REUkppmmydetWnE4npaWl33qxOUlepmnS3NxMTU0NAD169NjndSnsiIhISgkGgzQ3N9OzZ08yMzPtLkf2Q0ZGBgA1NTUUFRXtc5eW4q6IiKSUUCgEgNvttrkS6QzRwBoIBPZ5HQo7IiKSknSvw9TQGT9HhR0RERFJaQo7IiIiktIUdkRERFJM3759ueeeezplXW+88QaGYVBbW9sp67ODzsaKo7qWAF81+jgoL4P0tP2/KJKIiKSuH/zgB4wYMaJTQsqKFSvIysra/6JShO0tO19++SUXXHABhYWFZGRkMHToUN59993YfNM0mTlzJj169CAjI4Py8nI2bNjQYR07duxg8uTJeL1e8vLyuPTSS2lsbEz0ruzi5Hve5IQ7F7OuqsHuUkREpIszTZNgMLhHy3bv3l2n3bdja9jZuXMnY8eOJS0tjZdeeomPPvqIO++8k/z8/Ngyc+bM4d577+Whhx5i2bJlZGVlMW7cOFpbW2PLTJ48mTVr1rBw4ULmz5/Pm2++yeWXX27HLnXQLdsDwPYmn82ViIgcuEzTpNkftOVhmuYe1XjxxRezePFi/vCHP2AYBoZhMG/ePAzD4KWXXmLUqFF4PB7efvttPv30U04//XSKi4vJzs7myCOP5NVXX+2wvq93YxmGwf/7f/+PM888k8zMTAYMGMDzzz+/z8f0X//6F4cddhgej4e+ffty5513dpj/wAMPMGDAANLT0ykuLubss8+OzXv66acZOnQoGRkZFBYWUl5eTlNT0z7Xsids7cb6v//7P0pLS3nkkUdi0/r16xd7bZom99xzDzfffDOnn346AI8++ijFxcU899xznHfeeaxdu5aXX36ZFStWMHr0aADuu+8+xo8fz+9//3t69uy5y3Z9Ph8+X1sAqa+vj8v+FWZb13j4qkH3ZhERsUtLIMSQmf+xZdsf3TqOTPd3f9X+4Q9/YP369Rx++OHceuutAKxZswaAX/7yl/z+97/n4IMPJj8/n82bNzN+/Hhuu+02PB4Pjz76KBMnTmTdunX07t37G7fx29/+ljlz5vC73/2O++67j8mTJ7Np0yYKCgr2ap9WrlzJOeecwy233MK5557LO++8w89+9jMKCwu5+OKLeffdd7n66qv529/+xjHHHMOOHTt46623ANi6dSvnn38+c+bM4cwzz6ShoYG33nprj0PhvrK1Zef5559n9OjR/OhHP6KoqIiRI0fy5z//OTZ/48aNVFVVUV5eHpuWm5vLmDFjqKioAKCiooK8vLxY0AEoLy/H4XCwbNmy3W539uzZ5Obmxh6lpaVx2b9oy85XatkREZFvkZubi9vtJjMzk5KSEkpKSmJXC7711ls58cQTOeSQQygoKGD48OH89Kc/5fDDD2fAgAHMmjWLQw455Dtbai6++GLOP/98+vfvz+23305jYyPLly/f61rvuusuTjjhBH79618zcOBALr74YqZNm8bvfvc7ACorK8nKyuLUU0+lT58+jBw5kquvvhqwwk4wGOSss86ib9++DB06lJ/97GdkZ2fvdR17w9aWnc8++4wHH3yQ6dOn86tf/YoVK1Zw9dVX43a7mTJlClVVVQAUFxd3+FxxcXFsXlVVFUVFRR3mu1wuCgoKYst83YwZM5g+fXrsfX19fVwCj1p2RETsl5Hm5KNbx9m27f3V/o95gMbGRm655RYWLFgQCw8tLS1UVlZ+63qGDRsWe52VlYXX643dd2pvrF27NtbbEjV27FjuueceQqEQJ554In369OHggw/m5JNP5uSTT451nw0fPpwTTjiBoUOHMm7cOE466STOPvvsDsNX4sHWsBMOhxk9ejS33347ACNHjuTDDz/koYceYsqUKXHbrsfjwePxxG39Ud2jLTuNatkREbGLYRh71JWUrL5+VtX111/PwoUL+f3vf0///v3JyMjg7LPPxu//9j+s09LSOrw3DCMud4XPycnhv//9L2+88QavvPIKM2fO5JZbbmHFihXk5eWxcOFC3nnnHV555RXuu+8+brrpJpYtW9ZhGEtns7Ubq0ePHgwZMqTDtMGDB8fSaUlJCQDV1dUdlqmuro7NKykp2SWZBoNBduzYEVvGLtGWHQ1QFhGR7+J2u2P39fo2S5Ys4eKLL+bMM89k6NChlJSU8Pnnn8e/wIjBgwezZMmSXWoaOHBgrOvN5XJRXl7OnDlz+OCDD/j888957bXXACtkjR07lt/+9re89957uN1unn322bjWbGvUHTt2LOvWreswbf369fTp0wewBiuXlJSwaNEiRowYAVhdTsuWLePKK68EoKysjNraWlauXMmoUaMAeO211wiHw4wZMyZxO7MbsTE76sYSEZHv0LdvX5YtW8bnn39Odnb2N7a6DBgwgGeeeYaJEydiGAa//vWv49JC801+/vOfc+SRRzJr1izOPfdcKioquP/++3nggQcAmD9/Pp999hnHHXcc+fn5vPjii4TDYQ499FCWLVvGokWLOOmkkygqKmLZsmVs27aNwYMHx7VmW1t2rrvuOpYuXcrtt9/OJ598wuOPP86f/vQnpk6dCljp79prr+V///d/ef7551m9ejUXXXQRPXv25IwzzgCshHnyySdz2WWXsXz5cpYsWcK0adM477zzdnsmViIVZunUcxER2TPXX389TqeTIUOG0L17928cg3PXXXeRn5/PMcccw8SJExk3bhxHHHFEwuo84ogj+Oc//8mTTz7J4YcfzsyZM7n11lu5+OKLAcjLy+OZZ57h+OOPZ/DgwTz00EM88cQTHHbYYXi9Xt58803Gjx/PwIEDufnmm7nzzjs55ZRT4lqzYcb7fK/vMH/+fGbMmMGGDRvo168f06dP57LLLovNN02T3/zmN/zpT3+itraWY489lgceeICBAwfGltmxYwfTpk3jhRdewOFwMGnSJO699949Ht1dX19Pbm4udXV1eL3eTtu3moZWjrptEQ4DNtw2HqdDd+AVEYm31tZWNm7cSL9+/UhPT7e7HNlP3/bz3NPvb9vDTjKIV9gJhsIMuPklTBNW3FRO95z4D4oWETnQKeykls4IO7bfLiKVuZwO8jKs0e87mjRuR0REks8VV1xBdnb2bh9XXHGF3eV1iq57Ll4XkZfpZmdzgLqWgN2liIiI7OLWW2/l+uuv3+28zuztsJPCTpzlRlp2djarZUdERJJPUVHRLhfnTTXqxoqz/Ewr7NQ1q2VHRETEDgo78dS0nUHOL/Hgp7ZFLTsiIiJ2UNiJpz8ex42fXcyhxmZq1bIjIiJiC4WdeMoqBKDQqGenwo6IiIgtFHbiKas7YIWdOnVjiYiI2EJhJ54yuwFQSL26sUREJK769u3LPffcs0fLGobBc889F9d6konCTjxlWWGnwFDYERERsYvCTjxFwk43o14XFRQREbGJwk48RbqxCqjXRQVFROximuBvsuexh7ef/NOf/kTPnj0Jh8Mdpp9++ulccsklfPrpp5x++ukUFxeTnZ3NkUceyauvvtpph2j16tUcf/zxZGRkUFhYyOWXX05jY2Ns/htvvMFRRx1FVlYWeXl5jB07lk2bNgHw/vvv88Mf/pCcnBy8Xi+jRo3i3Xff7bTaOoOuoBxP7QYoN/tD+IIhPC6nzUWJiBxgAs1we097tv2rLeDO+s7FfvSjH3HVVVfx+uuvc8IJJwCwY8cOXn75ZV588UUaGxsZP348t912Gx6Ph0cffZSJEyeybt06evfuvV8lNjU1MW7cOMrKylixYgU1NTX85Cc/Ydq0acybN49gMMgZZ5zBZZddxhNPPIHf72f58uUYhgHA5MmTGTlyJA8++CBOp5NVq1aRlpa2XzV1NoWdeIqN2WkAoKE1iCdbYUdERDrKz8/nlFNO4fHHH4+Fnaeffppu3brxwx/+EIfDwfDhw2PLz5o1i2effZbnn3+eadOm7de2H3/8cVpbW3n00UfJyrKC2f3338/EiRP5v//7P9LS0qirq+PUU0/lkEMOAWDw4MGxz1dWVnLDDTcwaNAgAAYMGLBf9cSDwk48RcfsUAeYNLQG6ZbtsbcmEZEDTVqm1cJi17b30OTJk7nssst44IEH8Hg8PPbYY5x33nk4HA4aGxu55ZZbWLBgAVu3biUYDNLS0kJlZeV+l7h27VqGDx8eCzoAY8eOJRwOs27dOo477jguvvhixo0bx4knnkh5eTnnnHMOPXr0AGD69On85Cc/4W9/+xvl5eX86Ec/ioWiZKExO/EUGbOTbgTIxEdDqwYpi4gknGFYXUl2PCJdPXti4sSJmKbJggUL2Lx5M2+99RaTJ08G4Prrr+fZZ5/l9ttv56233mLVqlUMHToUvz8x40EfeeQRKioqOOaYY/jHP/7BwIEDWbp0KQC33HILa9asYcKECbz22msMGTKEZ599NiF17SmFnXhyZ4ErA4BCo46G1qDNBYmISLJKT0/nrLPO4rHHHuOJJ57g0EMP5YgjjgBgyZIlXHzxxZx55pkMHTqUkpISPv/8807Z7uDBg3n//fdpamqKTVuyZAkOh4NDDz00Nm3kyJHMmDGDd955h8MPP5zHH388Nm/gwIFcd911vPLKK5x11lk88sgjnVJbZ1HYiSfDgIx8AHJpUsuOiIh8q8mTJ7NgwQL+8pe/xFp1wBoH88wzz7Bq1Sref/99fvzjH+9y5tb+bDM9PZ0pU6bw4Ycf8vrrr3PVVVdx4YUXUlxczMaNG5kxYwYVFRVs2rSJV155hQ0bNjB48GBaWlqYNm0ab7zxBps2bWLJkiWsWLGiw5ieZKAxO/GWkQcNW8gzmqhXy46IiHyL448/noKCAtatW8ePf/zj2PS77rqLSy65hGOOOYZu3bpx4403Ul9f3ynbzMzM5D//+Q/XXHMNRx55JJmZmUyaNIm77rorNv/jjz/mr3/9K9u3b6dHjx5MnTqVn/70pwSDQbZv385FF11EdXU13bp146yzzuK3v/1tp9TWWQzT3MOLAKSw+vp6cnNzqaurw+v1du7KHxkPm5Yw1X81R4y/hEuP7de56xcRkQ5aW1vZuHEj/fr1Iz093e5yZD99289zT7+/1Y0Vb+l5AOQZjerGEhERsYHCTrxl5AHRMTvqxhIRkfh67LHHyM7O3u3jsMMOs7s8W2jMTrxFBih7jSY+U8uOiIjE2WmnncaYMWN2Oy/ZrmycKAo78RbtxqJRLTsiIhJ3OTk55OTk2F1GUlE3VrxFu7EMdWOJiCSSzr9JDZ1xir1aduJN19kREUmotLQ0DMNg27ZtdO/ePXbDSulaTNPE7/ezbds2HA4Hbrd7n9elsBNvsbOx1LIjIpIITqeTXr168cUXX3TaVYbFPpmZmfTu3RuHY987oxR24q3dAGVdVFBEJDGys7MZMGAAgYBa1Lsyp9OJy+Xa79Y5hZ14i4zZsQYo6z+diEiiOJ1OnE6n3WVIEtAA5XiLdGNlG62Egn78wc65l4mIiIjsGYWdeEvPjb300qzWHRERkQRT2Ik3pws81v068oxGjdsRERFJMIWdRIh0Zen0cxERkcRT2EkEXVhQRETENgo7iRC7GajOyBIREUk0hZ1EiHZj6Vo7IiIiCaewkwiRCwvm0USTT2FHREQkkRR2EiHdOhsr22ih2R+yuRgREZEDi8JOIkROPc+hmUa17IiIiCSUwk4iRMOO0UKzwo6IiEhCKewkgicHgGxaaPSpG0tERCSRFHYSIT3astNMs18tOyIiIomksJMI7Vp2mjRAWUREJKEUdhLB09ayo1PPRUREEkthJxEiYSebFoUdERGRBLM17Nxyyy0YhtHhMWjQoNj81tZWpk6dSmFhIdnZ2UyaNInq6uoO66isrGTChAlkZmZSVFTEDTfcQDCYZIEiep0dWmn2+W0uRkRE5MDisruAww47jFdffTX23uVqK+m6665jwYIFPPXUU+Tm5jJt2jTOOusslixZAkAoFGLChAmUlJTwzjvvsHXrVi666CLS0tK4/fbbE74v3ygyZsdhmOBrsrkYERGRA4vtYcflclFSUrLL9Lq6Oh5++GEef/xxjj/+eAAeeeQRBg8ezNKlSzn66KN55ZVX+Oijj3j11VcpLi5mxIgRzJo1ixtvvJFbbrkFt9u92236fD58Pl/sfX19fXx2LsqVjulIwwgHMPxx3paIiIh0YPuYnQ0bNtCzZ08OPvhgJk+eTGVlJQArV64kEAhQXl4eW3bQoEH07t2biooKACoqKhg6dCjFxcWxZcaNG0d9fT1r1qz5xm3Onj2b3Nzc2KO0tDROexdhGJiR1h13qJlgKBzf7YmIiEiMrWFnzJgxzJs3j5dffpkHH3yQjRs38r3vfY+Ghgaqqqpwu93k5eV1+ExxcTFVVVUAVFVVdQg60fnRed9kxowZ1NXVxR6bN2/u3B3bDaPdLSN0+rmIiEji2NqNdcopp8ReDxs2jDFjxtCnTx/++c9/kpGREbftejwePB5P3Na/W+lWy06O0UKzP0huRlpity8iInKAsr0bq728vDwGDhzIJ598QklJCX6/n9ra2g7LVFdXx8b4lJSU7HJ2VvT97sYB2cnw5AI6/VxERCTRkirsNDY28umnn9KjRw9GjRpFWloaixYtis1ft24dlZWVlJWVAVBWVsbq1aupqamJLbNw4UK8Xi9DhgxJeP3fyhNt2WmmSffHEhERSRhbu7Guv/56Jk6cSJ8+fdiyZQu/+c1vcDqdnH/++eTm5nLppZcyffp0CgoK8Hq9XHXVVZSVlXH00UcDcNJJJzFkyBAuvPBC5syZQ1VVFTfffDNTp05NfDfVd0lvd2FB3R9LREQkYWwNO1988QXnn38+27dvp3v37hx77LEsXbqU7t27A3D33XfjcDiYNGkSPp+PcePG8cADD8Q+73Q6mT9/PldeeSVlZWVkZWUxZcoUbr31Vrt26ZupZUdERMQWhmmapt1F2K2+vp7c3Fzq6urwer3x2cirv4W37+IvwZMpPPsuTh9xUHy2IyIicoDY0+/vpBqzk9KiLTs006gByiIiIgmjsJMo0TE7RgvN6sYSERFJGIWdRGl353O17IiIiCSOwk6iRK+gbDTTrLOxREREEkZhJ1FiY3ZaaFQ3loiISMIo7CSKJxuALKNVLTsiIiIJpLCTKO5I2KFVt4sQERFJIIWdRGkXdhpbAzYXIyIicuBQ2EmUSDeWwzAJ+5ttLkZEROTAobCTKGmZmBgAmL5Gm4sRERE5cCjsJIphEE7Lsl76m2wuRkRE5MChsJNApjsSdgJq2REREUkUhZ0EMt3WtXacAbXsiIiIJIrCTgIZkZYdd7iZQChsczUiIiIHBoWdBHKkWy072bTS7NdVlEVERBJBYSeBHJFbRugqyiIiIomjsJNIkW4s6yrKatkRERFJBIWdRIreH4sWteyIiIgkiMJOIkVvGWH4NGZHREQkQRR2Esmtlh0REZFEU9hJpGg3lqExOyIiIomisJNI7QYoq2VHREQkMRR2EilyBWWrG0stOyIiIomgsJNIkW6sbEMXFRQREUkUhZ1EinRjZdJKk0/dWCIiIomgsJNI7rYBymrZERERSQyFnUTyRO+N1aKWHRERkQRR2EmkWDeWT2djiYiIJIjCTiJFurHSjBB+X4vNxYiIiBwYFHYSKdKyAxD2NdpYiIiIyIFDYSeRHE5Czgzrta/B3lpEREQOEAo7CRZKs1p3DH+TzZWIiIgcGBR2Esx0K+yIiIgkksJOokUGKTuCGrMjIiKSCAo7CWZErrXjCjRjmqbN1YiIiKQ+hZ0EMyL3x8qgBX8obHM1IiIiqU9hJ8Gc6dE7n7fS7NMtI0REROJNYSfBHJGWnSxaaNJVlEVEROJOYSfRdDNQERGRhFLYSbRYy47CjoiISCIo7CRapGUn22ilWXc+FxERiTuFnUSL3fm8lSa17IiIiMSdwk6iRa6zk00LzRqgLCIiEncKO4kWbdkxfBqzIyIikgAKO4nmbnfqucbsiIiIxF3ShJ077rgDwzC49tprY9NaW1uZOnUqhYWFZGdnM2nSJKqrqzt8rrKykgkTJpCZmUlRURE33HADwWASh4hYN5bOxhIREUmEpAg7K1as4I9//CPDhg3rMP26667jhRde4KmnnmLx4sVs2bKFs846KzY/FAoxYcIE/H4/77zzDn/961+ZN28eM2fOTPQu7LlYN1arLiooIiKSALaHncbGRiZPnsyf//xn8vPzY9Pr6up4+OGHueuuuzj++OMZNWoUjzzyCO+88w5Lly4F4JVXXuGjjz7i73//OyNGjOCUU05h1qxZzJ07F7/f/43b9Pl81NfXd3gkTPTUc1ppUcuOiIhI3NkedqZOncqECRMoLy/vMH3lypUEAoEO0wcNGkTv3r2pqKgAoKKigqFDh1JcXBxbZty4cdTX17NmzZpv3Obs2bPJzc2NPUpLSzt5r75F5KKCHiNAS6svcdsVERE5QNkadp588kn++9//Mnv27F3mVVVV4Xa7ycvL6zC9uLiYqqqq2DLtg050fnTeN5kxYwZ1dXWxx+bNm/dzT/ZCpGUHINzakLjtioiIHKBcdm148+bNXHPNNSxcuJD09PSEbtvj8eDxeBK6zRhnGiGHG2fYT9jXaE8NIiIiBxDbWnZWrlxJTU0NRxxxBC6XC5fLxeLFi7n33ntxuVwUFxfj9/upra3t8Lnq6mpKSkoAKCkp2eXsrOj76DLJKOSyBimbPrXsiIiIxJttYeeEE05g9erVrFq1KvYYPXo0kydPjr1OS0tj0aJFsc+sW7eOyspKysrKACgrK2P16tXU1NTEllm4cCFer5chQ4YkfJ/2VCjN6soy/GrZERERiTfburFycnI4/PDDO0zLysqisLAwNv3SSy9l+vTpFBQU4PV6ueqqqygrK+Poo48G4KSTTmLIkCFceOGFzJkzh6qqKm6++WamTp1qXzfVHjDdWdAEjoDCjoiISLzZFnb2xN13343D4WDSpEn4fD7GjRvHAw88EJvvdDqZP38+V155JWVlZWRlZTFlyhRuvfVWG6v+bmZkkLIz0GRzJSIiIqkvqcLOG2+80eF9eno6c+fOZe7cud/4mT59+vDiiy/GubLOZUSuouxS2BEREYk726+zcyBypFthJy3UhGmaNlcjIiKS2hR2bOCMhJ0sWmkNhG2uRkREJLUp7NjAlREJO0aL7o8lIiISZwo7NoiO2cmilWaf7o8lIiISTwo7dojeDNRopTmglh0REZF4UtixQ+RmoFm00KSWHRERkbhS2LGDu103lsbsiIiIxJXCjh080W4steyIiIjEm8KOHdzRbqxWWjRmR0REJK4UduwQHbNjtKplR0REJM4UduwQGbOTQ7PG7IiIiMSZwo4dPG3dWE2tCjsiIiLxpLBjh8iYHZcRJuBvtrkYERGR1KawY4dI2AEINjfYWIiIiEjqU9ixg8NBwJkBQNinsCMiIhJPCjs2CbqyAAi3KuyIiIjEk8KOTUKRsGMEGm2uREREJLUp7NgklGaN2zF8CjsiIiLxpLBjl8ggZUegyeZCREREUpvCjk3MyLV2nEG17IiIiMSTwo5NjEjYSQuqZUdERCSeFHZs4ky3bhmRFtRFBUVEROJJYccm0bDjDjcTCps2VyMiIpK6FHZs4srwApBNKy0B3flcREQkXhR2bOLKsFp2sowWmn26GaiIiEi8KOzYxPBEwg6tNPvVsiMiIhIvCjt2iVxnJ5tWmvxq2REREYkXhR27eNp1Y6llR0REJG4UduwSadnJopUmjdkRERGJG4Udu0QuKphttNCilh0REZG4UdixS/uWHYUdERGRuFHYsUtkzE620Uqzz29zMSIiIqlLYccukZYdAH+zbgYqIiISLwo7dknLIBw5/KHWepuLERERSV0KO3YxDPzOTABCrQ02FyMiIpK6FHZsFHBmARBW2BEREYkbhR0bBV1Wy47p05gdERGReNmnsPPXv/6VBQsWxN7/4he/IC8vj2OOOYZNmzZ1WnGpLpQWGaSssCMiIhI3+xR2br/9djIyMgCoqKhg7ty5zJkzh27dunHdddd1aoGpzHRb3ViOgMKOiIhIvLj25UObN2+mf//+ADz33HNMmjSJyy+/nLFjx/KDH/ygM+tLaWG3da0dZ0BjdkREROJln1p2srOz2b59OwCvvPIKJ554IgDp6em0tLR0XnUpzvB4AUhT2BEREYmbfWrZOfHEE/nJT37CyJEjWb9+PePHjwdgzZo19O3btzPrS20ZeQC4g+rGEhERiZd9atmZO3cuZWVlbNu2jX/9618UFhYCsHLlSs4///xOLTCVOTOslp30kMKOiIhIvOxTy05eXh7333//LtN/+9vf7ndBBxJnRi4A6eEmmysRERFJXfvUsvPyyy/z9ttvx97PnTuXESNG8OMf/5idO3d2WnGpLi0rD4Bss4lgKGxvMSIiIilqn8LODTfcQH29dT+n1atX8/Of/5zx48ezceNGpk+fvsfrefDBBxk2bBherxev10tZWRkvvfRSbH5raytTp06lsLCQ7OxsJk2aRHV1dYd1VFZWMmHCBDIzMykqKuKGG24gGAzuy24lnDsSdnKMFpoDIXuLERERSVH7FHY2btzIkCFDAPjXv/7Fqaeeyu23387cuXM7hJXv0qtXL+644w5WrlzJu+++y/HHH8/pp5/OmjVrALjuuut44YUXeOqpp1i8eDFbtmzhrLPOin0+FAoxYcIE/H4/77zzDn/961+ZN28eM2fO3JfdSjhXZh4AOTTT7FPYERERiYd9GrPjdrtpbm4G4NVXX+Wiiy4CoKCgINbisycmTpzY4f1tt93Ggw8+yNKlS+nVqxcPP/wwjz/+OMcffzwAjzzyCIMHD2bp0qUcffTRvPLKK3z00Ue8+uqrFBcXM2LECGbNmsWNN97ILbfcgtvt3u12fT4fPp8v9n5vau5MRro1ZifHaKbJ3zVao0RERLqafWrZOfbYY5k+fTqzZs1i+fLlTJgwAYD169fTq1evfSokFArx5JNP0tTURFlZGStXriQQCFBeXh5bZtCgQfTu3ZuKigrAunrz0KFDKS4uji0zbtw46uvrY61DuzN79mxyc3Njj9LS0n2qeb9Fww4tatkRERGJk30KO/fffz8ul4unn36aBx98kIMOOgiAl156iZNPPnmv1rV69Wqys7PxeDxcccUVPPvsswwZMoSqqircbjd5eXkdli8uLqaqqgqAqqqqDkEnOj8675vMmDGDurq62GPz5s17VXOniVxUMMdooanV9x0Li4iIyL7Yp26s3r17M3/+/F2m33333Xu9rkMPPZRVq1ZRV1fH008/zZQpU1i8ePG+lLXHPB4PHo8nrtvYI+ne2EtfUx1QZF8tIiIiKWqfwg5Y3U7PPfcca9euBeCwww7jtNNOw+l07tV63G537D5bo0aNYsWKFfzhD3/g3HPPxe/3U1tb26F1p7q6mpKSEgBKSkpYvnx5h/VFz9aKLpPUXB78pOEmgK9Rp+yLiIjEwz51Y33yyScMHjyYiy66iGeeeYZnnnmGCy64gMMOO4xPP/10vwoKh8P4fD5GjRpFWloaixYtis1bt24dlZWVlJWVAVBWVsbq1aupqamJLbNw4UK8Xm/sbLFk1+q07nzub6q1txAREZEUtU8tO1dffTWHHHIIS5cupaCgAIDt27dzwQUXcPXVV7NgwYI9Ws+MGTM45ZRT6N27Nw0NDTz++OO88cYb/Oc//yE3N5dLL72U6dOnU1BQgNfr5aqrrqKsrIyjjz4agJNOOokhQ4Zw4YUXMmfOHKqqqrj55puZOnVqcnRT7YFWZw7eUC2hllq7SxEREUlJ+xR2Fi9e3CHoABQWFnLHHXcwduzYPV5PTU0NF110EVu3biU3N5dhw4bxn//8J3YX9bvvvhuHw8GkSZPw+XyMGzeOBx54IPZ5p9PJ/PnzufLKKykrKyMrK4spU6Zw66237stu2cLvygY/hJrtOf1dREQk1e1T2PF4PDQ0NOwyvbGx8RuvbbM7Dz/88LfOT09PZ+7cucydO/cbl+nTpw8vvvjiHm8z2QTTcqwXrXX2FiIiIpKi9mnMzqmnnsrll1/OsmXLME0T0zRZunQpV1xxBaeddlpn15jSQtGw41PLjoiISDzsU9i59957OeSQQygrKyM9PZ309HSOOeYY+vfvzz333NPJJaY2M3KtHYdfYUdERCQe9qkbKy8vj3//+9988sknsVPPBw8eHDuFXPZC5Fo7Lv+u3YIiIiKy//Y47HzX3cxff/312Ou77rpr3ys6wDgyrFtGuIIKOyIiIvGwx2Hnvffe26PlDMPY52IORNGw4w422lyJiIhIatrjsNO+5UY6T1pmHgDpoSZ7CxEREUlR+zRAWTqPOysPgIywwo6IiEg8KOzYzJOdD0CW2UQwFLa5GhERkdSjsGOz9Bwr7HiNZpp8IZurERERST0KOzaLdmPl0EyDL2BvMSIiIilIYcduHutsrCzDR2NLq83FiIiIpB6FHbtFLioI0NJQa18dIiIiKUphx27ONFrxANDauNPmYkRERFKPwk4SaHZkARBo3GFzJSIiIqlHYScJtDitrqxgk1p2REREOpvCThJodVlhJ9yssCMiItLZFHaSgD/NOiPLbFHYERER6WwKO0kgEDn93KGwIyIi0ukUdpJAyJMHgNNXa2sdIiIiqUhhJxlkWLeMcPlr7a1DREQkBSnsJAFHphV2PIF6mysRERFJPQo7ScCZXQhAelBhR0REpLMp7CQBdyTsZIYabK5EREQk9SjsJIEMrxV2sk2FHRERkc6msJMEMnK7AeA1GwmHTZurERERSS0KO0kgO687ABmGn8Ymte6IiIh0JoWdJJCelUfQtH4UjbVf2VyNiIhIalHYSQaGQYORDUBzncKOiIhIZ1LYSRKNkbDTWr/d5kpERERSi8JOkmh2Wnc+DzQq7IiIiHQmhZ0k0eKywk5QYUdERKRTKewkiYDbuvN5uFl3PhcREelMCjtJIhp2aFXYERER6UwKO0kinG7dDNTZWmtvISIiIilGYSdZZFhhx+WvtbcOERGRFKOwkyQcmVbYcfvrbK5EREQktSjsJAlXlnUz0PRgvc2ViIiIpBaFnSThzikAICuke2OJiIh0JoWdJOHJse58nm0q7IiIiHQmhZ0kkRW583kWLRD02VyNiIhI6lDYSRLZed0JmE4Agg01NlcjIiKSOhR2kkRORhrbsW4Z0byzyuZqREREUofCTpJIczrYiXUV5RaFHRERkU6jsJNE6hx5APjrqu0tREREJIXYGnZmz57NkUceSU5ODkVFRZxxxhmsW7euwzKtra1MnTqVwsJCsrOzmTRpEtXVHcNAZWUlEyZMIDMzk6KiIm644QaCwWAid6VTNLryAI3ZERER6Uy2hp3FixczdepUli5dysKFCwkEApx00kk0NTXFlrnuuut44YUXeOqpp1i8eDFbtmzhrLPOis0PhUJMmDABv9/PO++8w1//+lfmzZvHzJkz7dil/dKcZl1rx2zcZnMlIiIiqcMwTdO0u4iobdu2UVRUxOLFiznuuOOoq6uje/fuPP7445x99tkAfPzxxwwePJiKigqOPvpoXnrpJU499VS2bNlCcXExAA899BA33ngj27Ztw+12f+d26+vryc3Npa6uDq/XG9d9/DZP/+F6zt75ZzYedBr9LvubbXWIiIh0BXv6/Z1UY3bq6qz7QhUUWC0cK1euJBAIUF5eHltm0KBB9O7dm4qKCgAqKioYOnRoLOgAjBs3jvr6etasWbPb7fh8Purr6zs8kkEgw7plhLNZLTsiIiKdJWnCTjgc5tprr2Xs2LEcfvjhAFRVVeF2u8nLy+uwbHFxMVVVVbFl2ged6PzovN2ZPXs2ubm5sUdpaWkn780+yrQuLOj2bbe5EBERkdSRNGFn6tSpfPjhhzz55JNx39aMGTOoq6uLPTZv3hz3be4Jl7cIgHT/TpsrERERSR0uuwsAmDZtGvPnz+fNN9+kV69eseklJSX4/X5qa2s7tO5UV1dTUlISW2b58uUd1hc9Wyu6zNd5PB48Hk8n78X+8+RaLVLZwZ1gmmAYNlckIiLS9dnasmOaJtOmTePZZ5/ltddeo1+/fh3mjxo1irS0NBYtWhSbtm7dOiorKykrKwOgrKyM1atXU1PTdrr2woUL8Xq9DBkyJDE70kky8q1w5iIIrXU2VyMiIpIabG3ZmTp1Ko8//jj//ve/ycnJiY2xyc3NJSMjg9zcXC699FKmT59OQUEBXq+Xq666irKyMo4++mgATjrpJIYMGcKFF17InDlzqKqq4uabb2bq1KlJ2XrzbfK8OdSbGXiNFmjaBhl5dpckIiLS5dnasvPggw9SV1fHD37wA3r06BF7/OMf/4gtc/fdd3PqqacyadIkjjvuOEpKSnjmmWdi851OJ/Pnz8fpdFJWVsYFF1zARRddxK233mrHLu2X/Ew3283IqXNNOiNLRESkMyTVdXbskizX2dnZ5OfT/xvLaMd6gpPm4Rp6pm21iIiIJLsueZ2dA503I41qMx+Alh3JcYaYiIhIV6ewk0ScDoOdLutaO4EdX9hcjYiISGpQ2EkyDW7rWjvhui9trkRERCQ1KOwkmZZ061o7joatNlciIiKSGhR2kkwguwcA7maFHRERkc6gsJNkzJyeAGS01kA4bHM1IiIiXZ/CTpJxeXsQMg2cZhCav7K7HBERkS5PYSfJ5OVkso086029BimLiIjsL4WdJFOQ5abKLLDe1G+xtxgREZEUoLCTZAqy3GxV2BEREek0CjtJpignvV3LjrqxRERE9pfCTpIp9npiLTvhWl1FWUREZH8p7CSZ/Ew3VUb0lhGbbK5GRESk61PYSTIOh0FDRqn1eudGm6sRERHp+hR2kpDf2weAtJZt4Gu0uRoREZGuTWEnCWXlFrLDzLbe7Pzc1lpERES6OoWdJFTsTafStG4Iyo7P7C1GRESki1PYSUJFOR42RcOOxu2IiIjsF4WdJFTsTefzWMuOwo6IiMj+UNhJQkVeD5VhdWOJiIh0BoWdJFSUk84ms8h6o24sERGR/aKwk4SKvR42mSUAmHVfQNBnc0UiIiJdl8JOEsrPdFPrzKPezMQww/DVBrtLEhER6bIUdpKQw2FQkpvBx6Z1JWVq1tpbkIiISBemsJOkSvMzWR/uZb2p+cjeYkRERLowhZ0kVZqfybpYy47CjoiIyL5S2ElSpQUZrAsr7IiIiOwvhZ0kVVrQrmWnthJ8DfYWJCIi0kUp7CSpXvkZ1JHNNgqsCTUf21uQiIhIF6Wwk6RK8zMBWBs+yJpQ/aGN1YiIiHRdCjtJqnuOB4/LwQfhg60JX660tyAREZEuSmEnSRmGQa/8DN4PH2JN+PK/9hYkIiLSRSnsJLFe+ZmsioadbWvB12hvQSIiIl2Qwk4S612QyTbyqXcXgxmGLe/ZXZKIiEiXo7CTxPoXZQOwPu1Qa4LG7YiIiOw1hZ0kFg07KwP9rAlfrLCxGhERka5JYSeJRcPOwsZI2KmsgHDYxopERES6HoWdJFaU4yEn3cWq8MGEXZnQvF23jhAREdlLCjtJzDAM+hdlE8TFV4WjrYkb37S3KBERkS5GYSfJ9e9udWWtyxhhTVDYERER2SsKO0luQLEVdt4JD7EmbFoCoaCNFYmIiHQtCjtJLjpI+Y3aEsjIB189bF5mc1UiIiJdh8JOkhvcwwvA+q9aCPU/yZq4/iUbKxIREelaFHaSXIk3nW7ZHkJhk03djrMmrlPYERER2VMKO0nOMAyG9coFYKkxAhxpsP0T+GqDvYWJiIh0EbaGnTfffJOJEyfSs2dPDMPgueee6zDfNE1mzpxJjx49yMjIoLy8nA0bOn7J79ixg8mTJ+P1esnLy+PSSy+lsTG1bph5+EFW2FlZFYJ+37Mmrn3exopERES6DlvDTlNTE8OHD2fu3Lm7nT9nzhzuvfdeHnroIZYtW0ZWVhbjxo2jtbU1tszkyZNZs2YNCxcuZP78+bz55ptcfvnlidqFhBgWCTsfflkHQ86wJq7+l30FiYiIdCGGaZqm3UWA1V3z7LPPcsYZZwBWq07Pnj35+c9/zvXXXw9AXV0dxcXFzJs3j/POO4+1a9cyZMgQVqxYwejR1kX3Xn75ZcaPH88XX3xBz54992jb9fX15ObmUldXh9frjcv+7Y/q+lbG3L4IhwEf/nIMmfcOhpAfrnwHig+zuzwRERFb7On3d9KO2dm4cSNVVVWUl5fHpuXm5jJmzBgqKioAqKioIC8vLxZ0AMrLy3E4HCxb9s2nZ/t8Purr6zs8klmxN51ir4ewCau3GzAgclbW6qfsLUxERKQLSNqwU1VVBUBxcXGH6cXFxbF5VVVVFBUVdZjvcrkoKCiILbM7s2fPJjc3N/YoLS3t5Oo735F9CwBYtnEHDP2RNfH9JyEUsLEqERGR5Je0YSeeZsyYQV1dXeyxefNmu0v6TmMOLgRg6Wfb4dBTIKs7NGzVaegiIiLfIWnDTklJCQDV1dUdpldXV8fmlZSUUFNT02F+MBhkx44dsWV2x+Px4PV6OzySXdnBVsvOfyt34sMFR1xkzVjx/2ysSkREJPklbdjp168fJSUlLFq0KDatvr6eZcuWUVZWBkBZWRm1tbWsXLkytsxrr71GOBxmzJgxCa85ng7pnk23bDetgTAffFEHo/4HDAdsXAzb1ttdnoiISNKyNew0NjayatUqVq1aBViDkletWkVlZSWGYXDttdfyv//7vzz//POsXr2aiy66iJ49e8bO2Bo8eDAnn3wyl112GcuXL2fJkiVMmzaN8847b4/PxOoqDMNgTD+rK6vi0+2QVwoDT7FmLnvIxspERESSm61h591332XkyJGMHDkSgOnTpzNy5EhmzpwJwC9+8QuuuuoqLr/8co488kgaGxt5+eWXSU9Pj63jscceY9CgQZxwwgmMHz+eY489lj/96U+27E+8HdPfCjuL12+zJhx9pfX83t+gfotNVYmIiCS3pLnOjp2S/To7UVtqWzjmjtcwDFh584kUZKbBI+Oh8h046qcwfo7dJYqIiCRMl7/OjuyqZ14Gg3t4MU1YvL4GDAN+cKM1c+U8qN9qa30iIiLJSGGnizl+UHcAXvs40pXV7/tQejSEfPD6/9pYmYiISHJS2Olijh9kXWTxjY9r8AVDVuvOSbOsme/9Hb5Y+S2fFhEROfAo7HQxI0vzKPGm0+ALsnhdpHWn9CgYfr71+qUbIBy2r0AREZEko7DTxTgcBqcO6wHA8++3OwOr/BZw58CXK2F5ap6NJiIisi8Udrqg00ZY1xB6dW01Tb6gNTGnBE68xXr96m9g2zp7ihMREUkyCjtd0NCDculbmElrIMyCD9qdgTX6UjjkBAi2wjOXQ9BnX5EiIiJJQmGnCzIMg3OP7A3A35dtaj8DTr8fMvJh6ypYMB10GSURETnAKex0UeeM7oXb6eCDL+p4f3Nt2wxvT5j0sHXfrPf+rvE7IiJywFPY6aIKsz2xgcqPVmzqOLP/CVD+W+v1SzfC6qcTXJ2IiEjyUNjpwi4o6wPACx9sYVvD18bnHHMVjL4EMK3xOx89n/gCRUREkoDCThc2sjSP4aV5+INhHlmyseNMw4Dxd8Kwc8EMwVNT4N2/2FOoiIiIjRR2ujDDMPjZDw4B4G8Vm6hvDXRcwOGA0x+AIy4CMwzzr7O6tYJ+G6oVERGxh8JOF3fi4GIGFGXT4Avy/97auOsCThdMvBe+/0vr/bKH4C/jYMdulhUREUlBCjtdnMNhcN2JAwH485ufUV3fuutChgE/nAHn/wPS82DLf+GBMnjz92rlERGRlKewkwJOObyEI3rn0RIIcdcr6795wUNPhivegr7fg2ALvDYL5h4F7z8J4VDiChYREUkghZ0UYBgGN00YAsA/V27mgy9qv3nhvN4w5QU468+QVQQ7N8KzP4W5Y+C/j4K/OTFFi4iIJIjCTooY1Sef04b3xDThF09/gD/4LXc+NwwYdg5c/R6c8BvrisvbN8DzV8Fdg+ClX1o3FNXVl0VEJAUYpqlvtPr6enJzc6mrq8Pr9dpdzj7b3ujjxLvfZEeTn2vLB3Bt+cA9+2BrPax8BFY8DLXtLlCY3xcOOxMGngK9RoPDGZe6RURE9sWefn8r7JA6YQfg+fe3cPUT7+FyGPzjp0czqk/Bnn84HIZPXoX3H4f1/4FAuy6t9Dzrysz9T4RDjoec4k6vXUREZG8o7OyFVAo7pmly1RPvMf+DrZR401lw9bEUZnv2fkX+JivwrH0ePn0NWus6zu82EPqMhb7HWs/eHp2zAyIiIntIYWcvpFLYAWj0BTnt/rf5bFsTZQcXMu+SI/G49qMLKhSEL9+FDa/AhoVQ9cGuyxQcAr2PhtIx1qPbQOuihiIiInGisLMXUi3sAKyvbuDMuUto8oc4dVgP7j1vJA6H0Tkrb94BlRXw+RL4/C2oWg187Z9Reh6UHhV5HA0HHQHurM7ZvoiICAo7eyUVww7AWxu2ccm8FQRCJucf1Zvbzji88wJPey21sHlZ5LEcvnjXuo5Pe4YTSobCQaOg50jr0X2QdYVnERGRfaCwsxdSNewA/HvVl1z7j1WYJpw58iB+d/YwXM44dy+FAlZrTzQAVS6Dhi27LufKgB7D2sJPz5FQ2F9nfYmIyB5R2NkLqRx2wAo80//5PqGwydj+hdx//hHkZ7kTV4BpQt0X8MVy2PIebFllPfwNuy7rzoYeI6DniLYAVHCwdW0gERGRdhR29kKqhx2AVz+q5uon36PZH6JXfgb3nDuC0X334rT0zhYOw/ZPIuEn8tj6/q7dXwDpuR1bf3qOhNxSBSARkQOcws5eOBDCDsDHVfVc/uhKKnc0Yxhw6dh+TD9pIJnuJBk3EwrCV+utG5VGA1DVagjt5malmd2sMUDFh1mPoiHWGKC09MTXLSIitlDY2QsHStgBqG8NMOuFj3hq5RcAFOV4mH7iQM4e1Sv+Y3n2RdAP29bCl+0CUM1HEA7uuqzhsMb8FA1pC0DFh0FeH50GLyKSghR29sKBFHaiXvu4mt88v4bNO6xuo94FmVx6bD9+NLpX8rT0fJNAK1SvgerVUP2RFX6qP4SWnbtfPi0LuvW3glBhf+uaQAX9rLFAmYXqDhMR6aIUdvbCgRh2AHzBEI8treS+1zawszkAQLbHxfihJZw5shdj+hXE51T1eDBNaKiCmjWRIPSR9Xrbut13g0W5cyLBpx/kRwJQNAjl9FSLkIhIElPY2QsHatiJavYH+dfKL3j47Y18vr3tfliFWW6+f2h3jh9UxPcGdCc3I83GKvdRKAA7PrMGQ2//BLZ/ar3fsRHqv/j2zzo9kN/HuiFqbinklVrP0dfZxTpNXkTERgo7e+FADztR4bDJu5t28sx/v2DB6q00tLaNi3EYMKAohxGleQwvzWNEaR4Di7OTc5zPngq0Wnd5j4afHZ/Bzo3W69pNux8X1J7hhOwiyOoOub3A2xO8B0UePayWoZwS8GQnZn9ERA4wCjt7QWFnV/5gmHc37eD1j2t47eMaPt3WtMsyGWlOhvbKZehBuQwoyqZ/UTYDinLIzeyCLUBfFwpaLT87PoPaSqjdDHWbresF1W6G+i/BDO3ZujxeK/RkF1vBKLsIsrpZr7O6Q1a79+4sjSESEdlDCjt7QWHnu9XUt/Le5lre31zLqs21fPBFHY2+3bd8dM/x0L97NgOKrQAUDUHdst0YqfJFHgpCU401Tqixxgo/9V9C/ZbI81Zr3u4unPhtXBmQ3b1dEOrWFoacbvDktL2OBiVPttXKZBjqVhORA4rCzl5Q2Nl7obDJZ9saeW9zLWu31vNJTSOf1DSyta71Gz+Tm5HGwd2z6F2Q2fFRmElxTnrXGQy9N3wNkeCz1QpFTduskNS0DZq+sp4bI9OC33zsvp1hnXbvzoJuA9pCkcdrPZthqzUpPc8KQ2mZ1rJpmZCW0fbanWmduebOtN4rOIlIklPY2QsKO52noTXAp9ua+KSmkQ01DXwaCUGVO5oJf8u/NLfLQWl+RrsA1DEUZbhT/IvXNMHfFAlCkRDUPgg174BwAFrrrPkhvxWeWmvjV5Mr3QpRaZnWsxmyApMZguwSKyQ508DhijyndXzvdH9tnqvdMpHnvZ7Xft2ReQ3VVjBzpgGGNX4qekxDPmtZM2xdmiC7qG1eqrQyihzAFHb2gsJO/LUGQmz8qolN25vYtL2Zyh1tjy93thD8tiSE1TXWuyCTPgWZlLZrEepTkEn3HE/qdI/trVAQWnZYrUJN26wv/pAPfI3gq7dalsAKRr5660vf3wyBpshzsxWyAs1t7+nivxIcaZHB5ZH9cLjaBpunZVmhMS3DusaSv8nqAswsgHDIOnZmGDIKrDAXFWixlmneYXUbujKsgFW32ZpvmlbIyikBDGvbzdutoNVQZZ3Rl5FvLetKt7brb7QCWrRVLiPfCmR5fazlmrdb280ubuuibN4eaX3LskKwOwdcbqv27CJoqYV0b2RfAtZ+m2Gry7Nhq3XrFU+ONd3hsmp1uqzwGvJZ2wu2WoPrQ34I+qz3QZ/VJetKjwTesPUItIDLY+1nyGfd2y463Zlm7ZMZttYRaLXWmZZh7XP9l1Y9QR80VkOP4db+YFr7ET02Zshaf6AlElprreOTWWBtzx0J4yG/Nc/hsn7GJtaJAnVfQlah9TNyOK0/GNzZ1mcCLdbx8uRYxyvQbE1zZ1s/ix2fWtflcnmsZfxN1nadbmu9Ib81PT3X+sPD4438mzIix72o7b3Tbf3M03OtbYdD1njAkD/Supph/Tz8TVbdjjRreU+OdR2xrO7W/3Gn2/r36XBaP8dgq7VsRp61TrCOXVqmdcJFzcdQcrh1gdZAs3UihTPNOh71X1pXozdDVq3Rf/+NNZDXGz5/29qut6e1Pqc7cpwjv3Nc6dbvDZfHOm55pdbvntZaaz/SMqx/L+m5cbu6vcLOXlDYsVcwFGZrXWuHAFTZLhDVtQS+9fPpaQ5K8zPpU9gWhHrlZ9IjN52eeRnkZ6YduGFob5mm9UsrEAk+oYD1S80MW19Wvjrrl1j0fTjQ9qUaCli/CKOvvz4v+j72OvgNy/i/ZV4wso2AVQNYXxzOyBc+5nefRSdyIIgGkz0WCenfONvR9n9ur2vxWIH/R/OgeMi+reMb7On3d5JfKlcOBC6ng9JIi83Y3cyvaw50DEI7mmKvt9S20hoIs6GmkQ01jbtdv9vpoMjrodibTnHsOfI6J52iyOtsj0uhyDCsv5TdmXZX8t3CYSv0GA7rr/loa0NDVVvXlctjtWiFQ9a+hUNWWPM1ROanWzefNcNWC4/DGVmm0WolcHmsv/BDfmsbHq8VAs1wJAi2WJ8LB60WivbjnJxua5nsIusveF99ZFyWEWkd8Fh1pGVYAbP5K+tzDVXWPkVbdFrrIi00JmBa63R5rL+Wm7dbf7Gne616DcNazuVuOwahgNUilZFnrael1ppnYO2raVqtPs40qxZHmvWXuyvd2k702eGC1nqrBsPRFjKjxyMctP7Kd2e2hc/WOuuYuNKthxm2jj9EWinS2lpHjEiri8MVaTFotFrR0jKtZVyRFqGWHda8jPy2cB7y09aSlxY5NpHjmVFgfSb6M8nIb2vB+noYiNbpa4i0vgSs7Zphq9XDld5xbJ3DZdVghiItioGO874zeBvtQsk+tDt8WwBpv2/RbXy9xvZ1tN++4dz1bNOvb8fpsY7J7pYF6+eGYbUih3zw1Trr36lNFHYk6eVmpjE0M5ehvXJ3mRcIhdlS20LljmY2bW9mc+T5y9oWtta18FWjH38ozBc7W/hi527uqN5OpttJsTedbtluCrM8dMtx0z07nW45brple+iW7aEwy01htlvBKBk4HODwtL03nIDTakpvL7MgoWVJAnx9zFUoEPn503bV82i3VHpuW/fO1wfdhyLdfNHutej8aAh0tvuKDPrautOi3VkOp7Vcay14cq0QlpYR+WyaNb7Ok90WVF0ZVuuo4bDWl9U9EsIjNUSDe/NX1rM7ywq/Wd2tkJWRb4XmtCzrfVrkjxIzHAmKDus4RPc9s113bPSYhYJWOImGl2CrFeKbt0e6+lxWKKn/0gqK0TAe7UY0DCucurOs7Thcke5vw9r/1jqri9idZYWrYKsVpmsrIadHJ/0D2HvqxkLdWKnMFwxRU++jpqGV6nof1fXWc019K9XtprW/gOKecLscFGa5Kchyk5/pJjczjfzMNPIy3ORlppGfaT3nZbrJzUjDm+EiNyMNjyvFB1qLiCSQurFEAI/LGesi+zbN/iA1keDzVaOfrxp9sce2Bh/bGv1sb/Sxo8lPsz+EP2iNM/q2U+13X48Db0Ya3nQX2emRZ4+LnHQX2Z40stNdZHucZHms6VluF540B+lpTnIz0sh0O/G4nHjSHHhcDtxOh1qYRES+g8KOCJDpdtG3m4u+3bK+c9lmf5DtjX52NFmP2hY/O5sC1Db7qW0JsLM58ro5wM5mP/UtARp8QUwTfMGwFZ4afJ1St2FYAcrjcuJxWaHI43JEwpCT9LS2eR3n72ZaLES1hanoZx2GEduWwzBwGAYZbidul4M0p4HLYT0reIlIMlLYEdlLmW4XmQWu72wtai8cNmn0B6lvCVDfEqSuJUCjL0ijL0BDa7DdI0CzP0SjL0hT5OELhmkJhKhrCdDiD+ELtg0UNE1oDYRpDezjWRKdzOkwcEUeToeBy+mITYvNczpwOQzSnA4cDgOHAU7DwOEwIs/gMKzlnYYVoJwOa93R6dHAFZ1uGNaybctY62hb59e2E3kf287X1tlhO47oumm3jDW9xR/CYUCWx4UBGJFQaC1nvW//7Gg3f9flDAzAHwpT3xIgP8saGxY9DiHTJBAK43JYYdbtdGCaEDbNWE2GAS7H3ofOUNjENM2ufa87kW+RMmFn7ty5/O53v6Oqqorhw4dz3333cdRRR9ldlggADoeBNz0Nb3oa5O/fukzTxB8K4wuGaQ2E8AWs175giNaA9ewLhiPTQ23PwXafCYbxBXYzLdi2vvbTwqYVrHyBECYQDO8+YIXCJqGwSee0W8m+ckWCT3sG1rS2kNUWuFoDIUJhk9yMNJwOg7BpYhgdQ6rDMGIn7ZixdUYuIeOIrq8t1DkMIiFz18AXDaiOyCpDpnUJCtOELI8Tl8MRq9WIhMC2Z2LBEMPaL0d02dg+Rp5pmx6tga+to+PyHT/Xth3r2fH19e7mc9FlgA77GFu2/XaJ/gys13xtHV/fp1a/NdDaG/k5RX/Opglm5Kficlh/TATDJk6HgS8YwsDAtZsW2GjN0VrbXls10K5Oh+Prx6ftH1j7ny9AMGwSDFn1ZLqd1u8F06Q0PxO3y55AnRJh5x//+AfTp0/noYceYsyYMdxzzz2MGzeOdevWUVRUZHd5Ip3KMIxI95LTCk82MU2TQMgkGA4TCJoEwmGCkfehsEkwEnyCIes5EJkeCIVj08OmNc96hpBptTBEQ1PYNAmbtFvGjLRCWMuGwibhyC/SsEnb63brjH2uw7rpsO1wu+mmabatO/bccd3Wc9uJP/5Ia5sVCs1Yi0s48iUUjqw39t5s9z5ae+RzYN1apb4lQEsg1OGCmy6HEdmPb//Z7P4ind99Lsr2pr25LovI3nn9+h/Qbw+GCsRDSpyNNWbMGI488kjuv/9+AMLhMKWlpVx11VX88pe//M7P62wsEUlW0YAWbQ2Jtuz5g+FYC0A0EGJarW6ByF/V0b/2zUhrjNkuKIXbhSwD8KQ5aWwNEgiFcToMK1CG28JrKGx2aBGIrjcaFqOvo2G0/frD4Xavo49wW8Czujyt/WvyBa2wZpqRmtuWi+5DtP62adZ7aB82rf2PLkO7sBmdFo68iK432oIZXabjdtrWS3Qd0dpo+xy7TGu/HXM3+2OtLxaUd9mftsAcMs3Iz73tZx7txnQY1vqif3A4DKuFzu1yYGAQCIUJhMIEw237Q2z7bc+xY7ibY9xWn1VvrFWp3c/fhFh3NVhjHKPdx89PO7bTw84BczaW3+9n5cqVzJgxIzbN4XBQXl5ORUXFbj/j8/nw+doa2uvr6+Nep4jIvjAMKwi0fx9t2RORPdPlR6N99dVXhEIhiouLO0wvLi6mqqpqt5+ZPXs2ubm5sUdpaelulxMREZGur8uHnX0xY8YM6urqYo/NmzfbXZKIiIjESZfvxurWrRtOp5Pq6uoO06urqykpKdntZzweDx6PZ7fzREREJLV0+ZYdt9vNqFGjWLRoUWxaOBxm0aJFlJWV2ViZiIiIJIMu37IDMH36dKZMmcLo0aM56qijuOeee2hqauJ//ud/7C5NREREbJYSYefcc89l27ZtzJw5k6qqKkaMGMHLL7+8y6BlEREROfCkxHV29peusyMiItL17On3d5cfsyMiIiLybRR2REREJKUp7IiIiEhKU9gRERGRlKawIyIiIilNYUdERERSmsKOiIiIpLSUuKjg/opeaqi+vt7mSkRERGRPRb+3v+uSgQo7QENDAwClpaU2VyIiIiJ7q6Ghgdzc3G+crysoY904dMuWLeTk5GAYRqett76+ntLSUjZv3qwrM8eRjnPi6Fgnho5zYug4J068jrVpmjQ0NNCzZ08cjm8emaOWHcDhcNCrV6+4rd/r9eo/UgLoOCeOjnVi6Dgnho5z4sTjWH9bi06UBiiLiIhISlPYERERkZSmsBNHHo+H3/zmN3g8HrtLSWk6zomjY50YOs6JoeOcOHYfaw1QFhERkZSmlh0RERFJaQo7IiIiktIUdkRERCSlKeyIiIhISlPYiaO5c+fSt29f0tPTGTNmDMuXL7e7pC5j9uzZHHnkkeTk5FBUVMQZZ5zBunXrOizT2trK1KlTKSwsJDs7m0mTJlFdXd1hmcrKSiZMmEBmZiZFRUXccMMNBIPBRO5Kl3LHHXdgGAbXXnttbJqOc+f58ssvueCCCygsLCQjI4OhQ4fy7rvvxuabpsnMmTPp0aMHGRkZlJeXs2HDhg7r2LFjB5MnT8br9ZKXl8ell15KY2NjonclaYVCIX7961/Tr18/MjIyOOSQQ5g1a1aHeyfpOO+bN998k4kTJ9KzZ08Mw+C5557rML+zjusHH3zA9773PdLT0yktLWXOnDn7X7wpcfHkk0+abrfb/Mtf/mKuWbPGvOyyy8y8vDyzurra7tK6hHHjxpmPPPKI+eGHH5qrVq0yx48fb/bu3dtsbGyMLXPFFVeYpaWl5qJFi8x3333XPProo81jjjkmNj8YDJqHH364WV5ebr733nvmiy++aHbr1s2cMWOGHbuU9JYvX2727dvXHDZsmHnNNdfEpus4d44dO3aYffr0MS+++GJz2bJl5meffWb+5z//MT/55JPYMnfccYeZm5trPvfcc+b7779vnnbaaWa/fv3MlpaW2DInn3yyOXz4cHPp0qXmW2+9Zfbv3988//zz7dilpHTbbbeZhYWF5vz5882NGzeaTz31lJmdnW3+4Q9/iC2j47xvXnzxRfOmm24yn3nmGRMwn3322Q7zO+O41tXVmcXFxebkyZPNDz/80HziiSfMjIwM849//ON+1a6wEydHHXWUOXXq1Nj7UChk9uzZ05w9e7aNVXVdNTU1JmAuXrzYNE3TrK2tNdPS0synnnoqtszatWtNwKyoqDBN0/qP6XA4zKqqqtgyDz74oOn1ek2fz5fYHUhyDQ0N5oABA8yFCxea3//+92NhR8e589x4443mscce+43zw+GwWVJSYv7ud7+LTautrTU9Ho/5xBNPmKZpmh999JEJmCtWrIgt89JLL5mGYZhffvll/IrvQiZMmGBecsklHaadddZZ5uTJk03T1HHuLF8PO511XB944AEzPz+/w++OG2+80Tz00EP3q151Y8WB3+9n5cqVlJeXx6Y5HA7Ky8upqKiwsbKuq66uDoCCggIAVq5cSSAQ6HCMBw0aRO/evWPHuKKigqFDh1JcXBxbZty4cdTX17NmzZoEVp/8pk6dyoQJEzocT9Bx7kzPP/88o0eP5kc/+hFFRUWMHDmSP//5z7H5GzdupKqqqsOxzs3NZcyYMR2OdV5eHqNHj44tU15ejsPhYNmyZYnbmSR2zDHHsGjRItavXw/A+++/z9tvv80pp5wC6DjHS2cd14qKCo477jjcbndsmXHjxrFu3Tp27ty5z/XpRqBx8NVXXxEKhTr88gcoLi7m448/tqmqriscDnPttdcyduxYDj/8cACqqqpwu93k5eV1WLa4uJiqqqrYMrv7GUTnieXJJ5/kv//9LytWrNhlno5z5/nss8948MEHmT59Or/61a9YsWIFV199NW63mylTpsSO1e6OZftjXVRU1GG+y+WioKBAxzril7/8JfX19QwaNAin00koFOK2225j8uTJADrOcdJZx7Wqqop+/frtso7ovPz8/H2qT2FHkt7UqVP58MMPefvtt+0uJeVs3ryZa665hoULF5Kenm53OSktHA4zevRobr/9dgBGjhzJhx9+yEMPPcSUKVNsri51/POf/+Sxxx7j8ccf57DDDmPVqlVce+219OzZU8f5AKZurDjo1q0bTqdzlzNWqqurKSkpsamqrmnatGnMnz+f119/nV69esWml5SU4Pf7qa2t7bB8+2NcUlKy259BdJ5Y3VQ1NTUcccQRuFwuXC4Xixcv5t5778XlclFcXKzj3El69OjBkCFDOkwbPHgwlZWVQNux+rbfGyUlJdTU1HSYHwwG2bFjh451xA033MAvf/lLzjvvPIYOHcqFF17Iddddx+zZswEd53jprOMar98nCjtx4Ha7GTVqFIsWLYpNC4fDLFq0iLKyMhsr6zpM02TatGk8++yzvPbaa7s0a44aNYq0tLQOx3jdunVUVlbGjnFZWRmrV6/u8J9r4cKFeL3eXb50DlQnnHACq1evZtWqVbHH6NGjmTx5cuy1jnPnGDt27C6XT1i/fj19+vQBoF+/fpSUlHQ41vX19SxbtqzDsa6trWXlypWxZV577TXC4TBjxoxJwF4kv+bmZhyOjl9tTqeTcDgM6DjHS2cd17KyMt58800CgUBsmYULF3LooYfucxcWoFPP4+XJJ580PR6POW/ePPOjjz4yL7/8cjMvL6/DGSvyza688kozNzfXfOONN8ytW7fGHs3NzbFlrrjiCrN3797ma6+9Zr777rtmWVmZWVZWFpsfPSX6pJNOMletWmW+/PLLZvfu3XVK9HdofzaWaeo4d5bly5ebLpfLvO2228wNGzaYjz32mJmZmWn+/e9/jy1zxx13mHl5eea///1v84MPPjBPP/303Z66O3LkSHPZsmXm22+/bQ4YMOCAPyW6vSlTppgHHXRQ7NTzZ555xuzWrZv5i1/8IraMjvO+aWhoMN977z3zvffeMwHzrrvuMt977z1z06ZNpml2znGtra01i4uLzQsvvND88MMPzSeffNLMzMzUqefJ7L777jN79+5tut1u86ijjjKXLl1qd0ldBrDbxyOPPBJbpqWlxfzZz35m5ufnm5mZmeaZZ55pbt26tcN6Pv/8c/OUU04xMzIyzG7dupk///nPzUAgkOC96Vq+HnZ0nDvPCy+8YB5++OGmx+MxBw0aZP7pT3/qMD8cDpu//vWvzeLiYtPj8ZgnnHCCuW7dug7LbN++3Tz//PPN7Oxs0+v1mv/zP/9jNjQ0JHI3klp9fb15zTXXmL179zbT09PNgw8+2Lzppps6nMqs47xvXn/99d3+Xp4yZYppmp13XN9//33z2GOPNT0ej3nQQQeZd9xxx37Xbphmu8tKioiIiKQYjdkRERGRlKawIyIiIilNYUdERERSmsKOiIiIpDSFHREREUlpCjsiIiKS0hR2REREJKUp7IiIiEhKU9gREfmaN954A8MwdrkBqoh0TQo7IiIiktIUdkRERCSlKeyISNIJh8PMnj2bfv36kZGRwfDhw3n66aeBti6mBQsWMGzYMNLT0zn66KP58MMPO6zjX//6F4cddhgej4e+ffty5513dpjv8/m48cYbKS0txePx0L9/fx5++OEOy6xcuZLRo0eTmZnJMcccw7p16+K74yISFwo7IpJ0Zs+ezaOPPspDDz3EmjVruO6667jgggtYvHhxbJkbbriBO++8kxUrVtC9e3cmTpxIIBAArJByzjnncN5557F69WpuueUWfv3rXzNv3rzY5y+66CKeeOIJ7r33XtauXcsf//hHsrOzO9Rx0003ceedd/Luu+/icrm45JJLErL/ItK5dNdzEUkqPp+PgoICXn31VcrKymLTf/KTn9Dc3Mzll1/OD3/4Q5588knOPfdcAHbs2EGvXr2YN28e55xzDpMnT2bbtm288sorsc//4he/YMGCBaxZs4b169dz6KGHsnDhQsrLy3ep4Y033uCHP/whr776KieccAIAL774IhMmTKClpYX09PQ4HwUR6Uxq2RGRpPLJJ5/Q3NzMiSeeSHZ2duzx6KOP8umnn8aWax+ECgoKOPTQQ1m7di0Aa9euZezYsR3WO3bsWDZs2EAoFGLVqlU4nU6+//3vf2stw4YNi73u0aMHADU1Nfu9jyKSWC67CxARaa+xsRGABQsWcNBBB3WY5/F4OgSefZWRkbFHy6WlpcVeG4YBWOOJRKRrUcuOiCSVIUOG4PF4qKyspH///h0epaWlseWWLl0ae71z507Wr1/P4MGDARg8eDBLlizpsN4lS5YwcOBAnE4nQ4cOJRwOdxgDJCKpSy07IpJUcnJyuP7667nuuusIh8Mce+yx1NXVsWTJErxeL3369AHg1ltvpbCwkOLiYm666Sa6devGGWecAcDPf/5zjjzySGbNmsW5555LRUUF999/Pw888AAAffv2ZcqUKVxyySXce++9DB8+nE2bNlFTU8M555xj166LSJwo7IhI0pk1axbdu3dn9uzZfPbZZ+Tl5XHEEUfwq1/9KtaNdMcdd3DNNdewYcMGRowYwQsvvIDb7QbgiCOO4J///CczZ85k1qxZ9OjRg1tvvZWLL744to0HH3yQX/3qV/zsZz9j+/bt9O7dm1/96ld27K6IxJnOxhKRLiV6ptTOnTvJy8uzuxwR6QI0ZkdERERSmsKOiIiIpDR1Y4mIiEhKU8uOiIiIpDSFHREREUlpCjsiIiKS0hR2REREJKUp7IiIiEhKU9gRERGRlKawIyIiIilNYUdERERS2v8HJz6ewDQ2plIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습 결과 시각화\n",
    "plt.plot(train_loss_list, label='train_loss')\n",
    "plt.plot(val_loss_list, label='val_loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습결과 시각화 로그스케일\n",
    "plt.plot(train_loss_list, label='train_loss')\n",
    "plt.plot(val_loss_list, label='val_loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 저장\n",
    "\n",
    "## 모델 전체 저장 및 불러오기\n",
    "- 모델구조, 파라미터 저장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "# 모델 저장 경로\n",
    "save_path = r'./models/{model_target}/'\n",
    "# 모델 파일 이름\n",
    "model_file_name = r'{model_name}{dict}_{YYMMDDhhmm}.pth'\n",
    "\n",
    "#현 시간을 기준으로 파일 이름 생성\n",
    "def get_timestamp(save_datetime=True):\n",
    "    import datetime\n",
    "    if save_datetime:\n",
    "        return datetime.datetime.now().strftime('%Y%m%d%H%M')\n",
    "    else:\n",
    "        return ''\n",
    "# 모델 저장 경로 생성\n",
    "def get_path(model_name, model_target, save_datetime=True):\n",
    "    file_name = model_file_name.format(model_name=model_name, dict=r'{dict}', YYMMDDhhmm=get_timestamp(save_datetime=save_datetime))\n",
    "    return save_path.format(model_target=model_target) + file_name\n",
    "# 모델 저장 함수\n",
    "def save_model(model, model_name, model_target, save_dict=False, save_datetime=True):\n",
    "    # 모델 저장 경로 생성\n",
    "    os.makedirs(save_path.format(model_target=model_target), exist_ok=True)\n",
    "    # 총 경로\n",
    "    path = get_path(model_name, model_target)\n",
    "    path = path.format(dict='_dict') if save_dict else path.format(dict='')\n",
    "    if save_dict:\n",
    "        # 모델의 state_dict 저장\n",
    "        torch.save(model.state_dict(), path)\n",
    "    else:\n",
    "        # 모델 저장\n",
    "        torch.save(model, path)\n",
    "    \n",
    "    print(f'{model_name} model saved in {path}')\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boston model saved in ./models/boston/boston_202306080759.pth\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장\n",
    "path = save_model(boston_model, 'boston', 'boston')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'./models/boston/boston_202306080759.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기\n",
    "load_boston_model = torch.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 17.62517\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "# 검증 단계\n",
    "###################################\n",
    "# GPU로 이동\n",
    "load_boston_model = load_boston_model.to(DEVICE)\n",
    "# 검증 모드로 변경\n",
    "load_boston_model.eval()\n",
    "# loss 계산을 위한 변수 초기화\n",
    "val_loss = 0.0\n",
    "# 역전파를 통한 gradient 계산 비활성화\n",
    "with torch.no_grad():\n",
    "    for X, y in boston_test_loader:\n",
    "        # DEVICE로 이동\n",
    "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "        # 1. 모델 추정\n",
    "        y_pred = load_boston_model(X)    # forward propagation(순전파)\n",
    "        # 2. loss 계산 및 누적\n",
    "        val_loss += loss_func(y_pred, y).item()\n",
    "# batch에 대한 loss 평균 계산\n",
    "val_loss /= len(boston_test_loader)\n",
    "######### epoch 검증 종료 #########\n",
    "print(f'val_loss: {val_loss:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## state_dict 저장 및 로딩\n",
    "- 모델 파라미터만 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boston model saved in ./models/boston/boston_dict_202306080759.pth\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장(모델의 state_dict 저장)\n",
    "path = save_model(boston_model, 'boston', 'boston', save_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 불러오기\n",
    "load_boston_model_2 = BostonModel()\n",
    "load_boston_model_2.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 17.62517\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "# 검증 단계\n",
    "###################################\n",
    "# GPU로 이동\n",
    "load_boston_model_2 = load_boston_model_2.to(DEVICE)\n",
    "# 검증 모드로 변경\n",
    "load_boston_model_2.eval()\n",
    "# loss 계산을 위한 변수 초기화\n",
    "val_loss = 0.0\n",
    "# 역전파를 통한 gradient 계산 비활성화\n",
    "with torch.no_grad():\n",
    "    for X, y in boston_test_loader:\n",
    "        # DEVICE로 이동\n",
    "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "        # 1. 모델 추정\n",
    "        y_pred = load_boston_model_2(X)    # forward propagation(순전파)\n",
    "        # 2. loss 계산 및 누적\n",
    "        val_loss += loss_func(y_pred, y).item()\n",
    "# batch에 대한 loss 평균 계산\n",
    "val_loss /= len(boston_test_loader)\n",
    "######### epoch 검증 종료 #########\n",
    "print(f'val_loss: {val_loss:.5f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 분류 (Classification)\n",
    "\n",
    "## Fashion MNIST Dataset - 다중분류(Multi-Class Classification) 문제"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "10개의 범주(category)와 70,000개의 흑백 이미지로 구성된 [패션 MNIST](https://github.com/zalandoresearch/fashion-mnist) 데이터셋. \n",
    "이미지는 해상도(28x28 픽셀)가 낮고 다음처럼 개별 의류 품목을 나타낸다:\n",
    "\n",
    "<table>\n",
    "  <tr><td>\n",
    "    <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\"\n",
    "         alt=\"Fashion MNIST sprite\"  width=\"600\">\n",
    "  </td></tr>\n",
    "  <tr><td align=\"center\">\n",
    "    <b>그림</b> <a href=\"https://github.com/zalandoresearch/fashion-mnist\">패션-MNIST 샘플</a> (Zalando, MIT License).<br/>&nbsp;\n",
    "  </td></tr>\n",
    "</table>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "이미지는 28x28 크기이며 Gray scale이다. *레이블*(label)은 0에서 9까지의 정수 배열이다. 아래 표는 이미지에 있는 의류의 **클래스**(class)들이다.\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>레이블</th>\n",
    "    <th>클래스</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0</td>\n",
    "    <td>T-shirt/top</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>Trousers</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>2</td>\n",
    "    <td>Pullover</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>3</td>\n",
    "    <td>Dress</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>4</td>\n",
    "    <td>Coat</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>5</td>\n",
    "    <td>Sandal</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>6</td>\n",
    "    <td>Shirt</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>7</td>\n",
    "    <td>Sneaker</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>8</td>\n",
    "    <td>Bag</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>9</td>\n",
    "    <td>Ankle boot</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 위스콘신 유방암 데이터셋 - 이진분류(Binary Classification) 문제\n",
    "\n",
    "- **이진 분류 문제 처리 모델의 두가지 방법**\n",
    "    1. positive(1)일 확률을 출력하도록 구현\n",
    "        - output layer: units=1, activation='sigmoid'\n",
    "        - loss: binary_crossentropy\n",
    "    2. negative(0)일 확률과 positive(1)일 확률을 출력하도록 구현 => 다중분류 처리 방식으로 해결\n",
    "        - output layer: units=2, activation='softmax', y(정답)은 one hot encoding 처리\n",
    "        - loss: categorical_crossentropy\n",
    "        \n",
    "- 위스콘신 대학교에서 제공한 종양의 악성/양성여부 분류를 위한 데이터셋\n",
    "- Feature\n",
    "    - 종양에 대한 다양한 측정값들\n",
    "- Target의 class\n",
    "    - 0 - malignant(악성종양)\n",
    "    - 1 - benign(양성종양)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "512px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
