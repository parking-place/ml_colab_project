{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c408c92e",
   "metadata": {},
   "source": [
    "# [YOLOv8](https://docs.ultralytics.com/)\n",
    "\n",
    "## 설치\n",
    "\n",
    "1. 파이토치 설치\n",
    "2. YOLOv8 설치\n",
    "    - `pip install ultralytics`\n",
    "3. 주피터노트북에서 실행할 경우 프로그래스바를 실행하기 위해서 다음을 설치한다. (필수는 아님)\n",
    "    - `conda install -y -c conda-forge ipywidgets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48b0210d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (8.0.117)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from ultralytics) (0.12.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from ultralytics) (4.7.0.72)\n",
      "Requirement already satisfied: requests>=2.23.0 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from ultralytics) (2.28.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from ultralytics) (6.0)\n",
      "Requirement already satisfied: torch>=1.7.0 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from ultralytics) (2.0.1+cu118)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from ultralytics) (4.65.0)\n",
      "Requirement already satisfied: torchvision>=0.8.1 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from ultralytics) (0.15.2+cu118)\n",
      "Requirement already satisfied: psutil in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from ultralytics) (5.9.5)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from ultralytics) (9.3.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from ultralytics) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from ultralytics) (1.10.1)\n",
      "Requirement already satisfied: matplotlib>=3.2.2 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from ultralytics) (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (1.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (23.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (1.24.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (4.39.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.13)\n",
      "Requirement already satisfied: typing-extensions in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from torch>=1.7.0->ultralytics) (4.4.0)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from torch>=1.7.0->ultralytics) (2.0.0)\n",
      "Requirement already satisfied: networkx in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from torch>=1.7.0->ultralytics) (3.0)\n",
      "Requirement already satisfied: filelock in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from torch>=1.7.0->ultralytics) (3.9.0)\n",
      "Requirement already satisfied: jinja2 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from torch>=1.7.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: sympy in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from torch>=1.7.0->ultralytics) (1.11.1)\n",
      "Requirement already satisfied: cmake in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (3.25.0)\n",
      "Requirement already satisfied: lit in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (15.0.7)\n",
      "Requirement already satisfied: six>=1.5 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from jinja2->torch>=1.7.0->ultralytics) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from sympy->torch>=1.7.0->ultralytics) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "01f3d95a",
   "metadata": {},
   "source": [
    "## 사용\n",
    "- CLI (command line interface)에서 터미널 명령어로 추론/평가/학습을 진행할 수 있다.\n",
    "- Python lib 를 이용해 코드상에 원하는 추론/평가/학습을 진행할 수 있다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5bbfe070",
   "metadata": {},
   "source": [
    "# CLI 기본 명령어 구조\n",
    "\n",
    "- 구문\n",
    "    - <span style='font-size:1.3em'>**yolo**  **task**=detect|classify|segment  **mode**=train|val|predict  **model**=yolov8n.yaml|yolov8n.pt|..  **args**</span>\n",
    "    - <b style='font-size:1.2em'>task:</b> \\[detect, classify, segment\\] 중 하나를 지정한다. \\[optional\\]로 생략하면 model을 보고 추측해서 task를 정한다.\n",
    "        - **detect:** Object detection\n",
    "        - **classify:** Image classification\n",
    "        - **segment:** Instance segmentation\n",
    "    - <b style='font-size:1.2em'>mode:</b> \\[train, val, predict, export\\] 중 하나를 지정한다. \\[필수\\]로 입력해야 한다.\n",
    "        - **train:** custom dataset을 train 시킨다.\n",
    "        - **val:** 모델 성능을 평가한다.\n",
    "        - **predict:** 입력 이미지에 대한 추론을 한다.\n",
    "        - **export:** 모델을 다른 형식으로 변환한다.\n",
    "    - <b style='font-size:1.2em'>model:</b> **pretrained 모델**이나 **모델 설정 yaml 파일**의 경로를 설정한다. \\[필수\\]로 입력해야 한다.\n",
    "        - pretrained 모델 파일경로\n",
    "            - task에 맞는 pretrained 모델파일의 저장 경로를 지정한다.\n",
    "            - transfer learnging을 하거나 fine tuning 시 방법\n",
    "        - 모델 구조 설정 yaml 파일 경로\n",
    "            - task에 맞는 pretrained 모델 설정파일(yaml파일)의 경로를 지정한다.\n",
    "            - train mode에서 지정하며 모델을 새로 생성해서 처음부터 학습 시킬 경우 지정한다.\n",
    "        - Ultralytics에서 제공하는 Pretrained 모델\n",
    "            - 모델 크기에 따라 5개의 모델을 제공하며 큰 모델은 작은 모델에 비해 추론 성능이 좋은대신 속도는 느리다.\n",
    "            - 모델은 처음 추론또는 학습할때 local 컴퓨터에 없으면 download 받는다.\n",
    "            - https://github.com/ultralytics/ultralytics#models\n",
    "            - ### 제공 모델\n",
    "            \n",
    "            | **task\\모델크기**           | **nano** | **small_** | **medium** | **large** | **xlarge** |\n",
    "            |:--------------------|----------|-------------|------------|-----------|----------|\n",
    "            | **detection**      | yolov8n  | yolov8s     | yolov8m    | yolov8l   | yolov8x    |\n",
    "            | **segmentation**   | yolov8n-seg  | yolov8s-seg     | yolov8m-seg    | yolov8l-seg   | yolov8x-seg    |\n",
    "            | **classification** | yolov8n-cls  | yolov8s-cls     | yolov8m-cls    | yolov8l-cls   | yolov8x-cls    |         \n",
    "            | **pose estimation** | yolov8n-pose  | yolov8s-pose     | yolov8m-pose    | yolov8l-pose   | yolov8x-pose    |\n",
    "            \n",
    "            - 확장자가 `pt`이면 pretrained 된 모델을, `yaml`이면 모델 구조 설정파일을 download하여 실행한다.\n",
    "                - pretrained model은 fine tuning이나 추론할 때, yaml설정파일은 처음부터 학습할 경우 설정하여 받는다.\n",
    "    - <b style='font-size:1.2em'>args:</b> task와 mode과 관련한 추가 설정값들을 지정한다.\n",
    "        - https://docs.ultralytics.com/cfg/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb7e10cd",
   "metadata": {},
   "source": [
    "# [Object Detection](https://docs.ultralytics.com/tasks/detection/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ca360a0",
   "metadata": {},
   "source": [
    "##  Predict (추론)\n",
    "\n",
    "### 모델로딩\n",
    "- Ultralytics에서 제공하는 Pretrained Model이나 직접 학습시킨 모델을 이용해 추론한다.\n",
    "- Ultralytics는 Object Detection을 위한 [Pretrained 모델](#제공-모델)을 제공한다.\n",
    "    - Object Detection 모델은 COCO dataset으로 학습되었다.\n",
    "    - 모델 명을 지정하면 자동으로 다운로드를 받는다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8235d4bc",
   "metadata": {},
   "source": [
    "### CLI\n",
    "`yolo task=detect mode=predict model=model_path source=추론할_image_path`\n",
    "- 추가 설정 (configuration)\n",
    "    - https://docs.ultralytics.com/cfg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "631c8155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (8.0.117)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from ultralytics) (9.3.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from ultralytics) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from ultralytics) (4.65.0)\n",
      "Requirement already satisfied: torchvision>=0.8.1 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from ultralytics) (0.15.2+cu118)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from ultralytics) (0.12.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from ultralytics) (4.7.0.72)\n",
      "Requirement already satisfied: requests>=2.23.0 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from ultralytics) (2.28.1)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from ultralytics) (2.0.2)\n",
      "Requirement already satisfied: psutil in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from ultralytics) (5.9.5)\n",
      "Requirement already satisfied: torch>=1.7.0 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from ultralytics) (2.0.1+cu118)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from ultralytics) (1.10.1)\n",
      "Requirement already satisfied: matplotlib>=3.2.2 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from ultralytics) (3.7.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (1.24.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (1.0.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (4.39.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from matplotlib>=3.2.2->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2.1.1)\n",
      "Requirement already satisfied: filelock in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from torch>=1.7.0->ultralytics) (3.9.0)\n",
      "Requirement already satisfied: networkx in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from torch>=1.7.0->ultralytics) (3.0)\n",
      "Requirement already satisfied: sympy in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from torch>=1.7.0->ultralytics) (1.11.1)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from torch>=1.7.0->ultralytics) (2.0.0)\n",
      "Requirement already satisfied: typing-extensions in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from torch>=1.7.0->ultralytics) (4.4.0)\n",
      "Requirement already satisfied: jinja2 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from torch>=1.7.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: cmake in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (3.25.0)\n",
      "Requirement already satisfied: lit in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (15.0.7)\n",
      "Requirement already satisfied: six>=1.5 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from jinja2->torch>=1.7.0->ultralytics) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/parking/anaconda3/envs/ml/lib/python3.10/site-packages (from sympy->torch>=1.7.0->ultralytics) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b52437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd /home/parking/ml/ml_colab_project/Object_Detection/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d91578f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T07:29:55.783401Z",
     "start_time": "2023-03-09T07:29:46.404535Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.117 🚀 Python-3.10.11 torch-2.0.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3060, 12042MiB)\n",
      "YOLOv8s summary (fused): 168 layers, 11156544 parameters, 0 gradients\n",
      "\n",
      "/home/parking/anaconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/conv.py:459: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "image 1/1 /home/parking/ml/ml_colab_project/Object_Detection/test_image/3.jpg: 448x640 1 car, 1 cup, 1 chair, 1 tv, 1 mouse, 1 keyboard, 3 cell phones, 128.3ms\n",
      "Speed: 1.3ms preprocess, 128.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict3\u001b[0m\n",
      "1 label saved to runs/detect/predict3/labels\n"
     ]
    }
   ],
   "source": [
    "!yolo  task=detect  mode=predict   model=models/yolov8s.pt   source=test_image/3.jpg  save=True  save_txt=True  line_width=1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7b0f28a7",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64f37008",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T07:38:46.694238Z",
     "start_time": "2023-03-09T07:38:42.088027Z"
    }
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "522e29bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T07:40:51.237815Z",
     "start_time": "2023-03-09T07:40:25.206490Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8x.pt to models/yolov8x.pt...\n",
      "100%|██████████| 131M/131M [00:04<00:00, 28.4MB/s] \n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"models/yolov8x.pt\")  # YOLO 클래스 객체 생성하면서 사용할 pretrained model의 경로를 지정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2881ee4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T07:48:11.948615Z",
     "start_time": "2023-03-09T07:48:09.261815Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/parking/ml/ml_colab_project/Object_Detection/test_image/bus.jpg: 640x480 5 persons, 1 bicycle, 1 bus, 141.8ms\n",
      "Speed: 12.7ms preprocess, 141.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict7\u001b[0m\n",
      "3 labels saved to runs/detect/predict7/labels\n"
     ]
    }
   ],
   "source": [
    "image_path = 'test_image/bus.jpg'\n",
    "result_list = model(image_path, save=True, save_txt=True, line_width=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e271a9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T08:08:59.743991Z",
     "start_time": "2023-03-09T08:08:59.729442Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result_list), len(result_list)\n",
    "# 리스트에 추론한 결과를 추론한 이미지별로 저장해서 반환."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb48e01f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T08:10:01.164886Z",
     "start_time": "2023-03-09T08:10:01.155305Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.yolo.engine.results.Results"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result_list[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f33daef5",
   "metadata": {},
   "source": [
    "### 한번에 여러장 추론\n",
    "- 추론할 파일경로를 리스트로 묶어서 추론한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "17a4ca18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T08:12:43.479144Z",
     "start_time": "2023-03-09T08:12:43.459754Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_image/1433148424953500.jpg',\n",
       " 'test_image/2.jpg',\n",
       " 'test_image/3.jpg',\n",
       " 'test_image/4.jpg',\n",
       " 'test_image/6.jpg',\n",
       " 'test_image/1.jpg',\n",
       " 'test_image/5.jpg',\n",
       " 'test_image/catsss.jpg',\n",
       " 'test_image/bus.jpg']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "file_path = glob('test_image/*.jpg')\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9373630b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T08:14:18.181503Z",
     "start_time": "2023-03-09T08:14:09.443734Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 11 persons, 2 elephants, 1: 640x640 15 persons, 6 cars, 4 buss, 4 traffic lights, 1 umbrella, 2: 640x640 1 car, 2 chairs, 1 tv, 1 mouse, 1 keyboard, 2 cell phones, 3: 640x640 3 elephants, 1 zebra, 4: 640x640 3 persons, 1 wine glass, 2 cups, 1 fork, 1 knife, 3 pizzas, 3 dining tables, 5: 640x640 9 persons, 5 bicycles, 5 cars, 1 motorcycle, 1 bus, 4 traffic lights, 1 dog, 1 backpack, 1 handbag, 6: 640x640 9 persons, 1 tie, 1 bottle, 15 wine glasss, 3 cups, 3 forks, 1 knife, 1 spoon, 1 bowl, 1 potted plant, 1 dining table, 1 vase, 7: 640x640 10 cars, 2 cats, 1 bowl, 8: 640x640 4 persons, 1 bicycle, 1 bus, 329.8ms\n",
      "Speed: 1.6ms preprocess, 36.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict10\u001b[0m\n",
      "9 labels saved to runs/detect/predict10/labels\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('models/yolov8x.pt')\n",
    "result_list = model(file_path, save=True, save_txt=True, line_width=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca45b257",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T08:19:58.998534Z",
     "start_time": "2023-03-09T08:19:58.979069Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, ultralytics.yolo.engine.results.Results)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result_list), type(result_list[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "471f3231",
   "metadata": {},
   "source": [
    "### web 상의 이미지 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6c7a79d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T08:22:05.173435Z",
     "start_time": "2023-03-09T08:22:02.111740Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading https://ultralytics.com/images/bus.jpg to bus.jpg...\n",
      "100%|██████████| 476k/476k [00:00<00:00, 3.83MB/s]\n",
      "image 1/1 /home/parking/ml/ml_colab_project/Object_Detection/bus.jpg: 640x480 5 persons, 1 bicycle, 1 bus, 38.1ms\n",
      "Speed: 10.5ms preprocess, 38.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict8\u001b[0m\n",
      "7 labels saved to runs/detect/predict8/labels\n"
     ]
    }
   ],
   "source": [
    "result_list = model(\"https://ultralytics.com/images/bus.jpg\", save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "488fd9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading https://d2u3dcdbebyaiu.cloudfront.net/uploads/atch_img/169/f531ef142dbb8dd3211fb40d3fca8f5a_res_a..gif to f531ef142dbb8dd3211fb40d3fca8f5a_res_a..gif...\n",
      "100%|██████████| 159k/159k [00:00<00:00, 1.51MB/s]\n",
      "\n",
      "    WARNING ⚠️ stream/video/webcam/dir predict source will accumulate results in RAM unless `stream=True` is passed,\n",
      "    causing potential out-of-memory errors for large sources or long-running streams/videos.\n",
      "\n",
      "    Usage:\n",
      "        results = model(source=..., stream=True)  # generator of Results objects\n",
      "        for r in results:\n",
      "            boxes = r.boxes  # Boxes object for bbox outputs\n",
      "            masks = r.masks  # Masks object for segment masks outputs\n",
      "            probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (1/1) /home/parking/ml/ml_colab_project/Object_Detection/f531ef142dbb8dd3211fb40d3fca8f5a_res_a..gif: 384x640 1 person, 2 benchs, 1 cat, 126.1ms\n",
      "Speed: 20.7ms preprocess, 126.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict10\u001b[0m\n",
      "10 labels saved to runs/detect/predict10/labels\n"
     ]
    }
   ],
   "source": [
    "result_list = model('https://d2u3dcdbebyaiu.cloudfront.net/uploads/atch_img/169/f531ef142dbb8dd3211fb40d3fca8f5a_res_a..gif', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ffcea49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading https:\\jjal.today\\data\\file\\gallery\\1850094512_s9OJf0Qw_0d61635e94751fd731caba342e24a60ab5a5e0f5.gif to 1850094512_s9OJf0Qw_0d61635e94751fd731caba342e24a60ab5a5e0f5.gif...\n",
      "100%|██████████| 1.19M/1.19M [00:00<00:00, 1.27MB/s]\n",
      "\n",
      "    WARNING  stream/video/webcam/dir predict source will accumulate results in RAM unless `stream=True` is passed,\n",
      "    causing potential out-of-memory errors for large sources or long-running streams/videos.\n",
      "\n",
      "    Usage:\n",
      "        results = model(source=..., stream=True)  # generator of Results objects\n",
      "        for r in results:\n",
      "            boxes = r.boxes  # Boxes object for bbox outputs\n",
      "            masks = r.masks  # Masks object for segment masks outputs\n",
      "            probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (1/18) e:\\Python\\ml_colab_project\\Object_Detection\\1850094512_s9OJf0Qw_0d61635e94751fd731caba342e24a60ab5a5e0f5.gif: 384x640 7 persons, 2 ties, 1 cup, 1 clock, 917.2ms\n",
      "video 1/1 (2/18) e:\\Python\\ml_colab_project\\Object_Detection\\1850094512_s9OJf0Qw_0d61635e94751fd731caba342e24a60ab5a5e0f5.gif: 384x640 5 persons, 2 ties, 856.1ms\n",
      "video 1/1 (3/18) e:\\Python\\ml_colab_project\\Object_Detection\\1850094512_s9OJf0Qw_0d61635e94751fd731caba342e24a60ab5a5e0f5.gif: 384x640 5 persons, 2 ties, 830.3ms\n",
      "video 1/1 (4/18) e:\\Python\\ml_colab_project\\Object_Detection\\1850094512_s9OJf0Qw_0d61635e94751fd731caba342e24a60ab5a5e0f5.gif: 384x640 6 persons, 2 ties, 815.2ms\n",
      "video 1/1 (5/18) e:\\Python\\ml_colab_project\\Object_Detection\\1850094512_s9OJf0Qw_0d61635e94751fd731caba342e24a60ab5a5e0f5.gif: 384x640 6 persons, 2 ties, 854.3ms\n",
      "video 1/1 (6/18) e:\\Python\\ml_colab_project\\Object_Detection\\1850094512_s9OJf0Qw_0d61635e94751fd731caba342e24a60ab5a5e0f5.gif: 384x640 6 persons, 3 ties, 1 cup, 963.8ms\n",
      "video 1/1 (7/18) e:\\Python\\ml_colab_project\\Object_Detection\\1850094512_s9OJf0Qw_0d61635e94751fd731caba342e24a60ab5a5e0f5.gif: 384x640 6 persons, 3 ties, 836.0ms\n",
      "video 1/1 (8/18) e:\\Python\\ml_colab_project\\Object_Detection\\1850094512_s9OJf0Qw_0d61635e94751fd731caba342e24a60ab5a5e0f5.gif: 384x640 6 persons, 3 ties, 895.3ms\n",
      "video 1/1 (9/18) e:\\Python\\ml_colab_project\\Object_Detection\\1850094512_s9OJf0Qw_0d61635e94751fd731caba342e24a60ab5a5e0f5.gif: 384x640 6 persons, 3 ties, 845.2ms\n",
      "video 1/1 (10/18) e:\\Python\\ml_colab_project\\Object_Detection\\1850094512_s9OJf0Qw_0d61635e94751fd731caba342e24a60ab5a5e0f5.gif: 384x640 8 persons, 844.3ms\n",
      "video 1/1 (11/18) e:\\Python\\ml_colab_project\\Object_Detection\\1850094512_s9OJf0Qw_0d61635e94751fd731caba342e24a60ab5a5e0f5.gif: 384x640 10 persons, 862.7ms\n",
      "video 1/1 (12/18) e:\\Python\\ml_colab_project\\Object_Detection\\1850094512_s9OJf0Qw_0d61635e94751fd731caba342e24a60ab5a5e0f5.gif: 384x640 8 persons, 899.4ms\n",
      "video 1/1 (13/18) e:\\Python\\ml_colab_project\\Object_Detection\\1850094512_s9OJf0Qw_0d61635e94751fd731caba342e24a60ab5a5e0f5.gif: 384x640 9 persons, 857.6ms\n",
      "video 1/1 (14/18) e:\\Python\\ml_colab_project\\Object_Detection\\1850094512_s9OJf0Qw_0d61635e94751fd731caba342e24a60ab5a5e0f5.gif: 384x640 8 persons, 868.2ms\n",
      "video 1/1 (15/18) e:\\Python\\ml_colab_project\\Object_Detection\\1850094512_s9OJf0Qw_0d61635e94751fd731caba342e24a60ab5a5e0f5.gif: 384x640 8 persons, 834.4ms\n",
      "video 1/1 (16/18) e:\\Python\\ml_colab_project\\Object_Detection\\1850094512_s9OJf0Qw_0d61635e94751fd731caba342e24a60ab5a5e0f5.gif: 384x640 11 persons, 839.0ms\n",
      "video 1/1 (17/18) e:\\Python\\ml_colab_project\\Object_Detection\\1850094512_s9OJf0Qw_0d61635e94751fd731caba342e24a60ab5a5e0f5.gif: 384x640 8 persons, 865.6ms\n",
      "video 1/1 (18/18) e:\\Python\\ml_colab_project\\Object_Detection\\1850094512_s9OJf0Qw_0d61635e94751fd731caba342e24a60ab5a5e0f5.gif: 384x640 7 persons, 839.6ms\n",
      "Speed: 2.4ms preprocess, 862.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result_list = model(r'https://jjal.today/data/file/gallery/1850094512_s9OJf0Qw_0d61635e94751fd731caba342e24a60ab5a5e0f5.gif', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4fe0fb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T08:24:59.228076Z",
     "start_time": "2023-03-09T08:24:57.908118Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading https://storage3.ilyo.co.kr/contents/article/images/2015/0601/1433148424953500.jpg to 1433148424953500.jpg...\n",
      "100%|██████████| 228k/228k [00:00<00:00, 14.7MB/s]\n",
      "image 1/1 /home/parking/ml/ml_colab_project/Object_Detection/1433148424953500.jpg: 448x640 12 persons, 2 elephants, 31.1ms\n",
      "Speed: 2.5ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict8\u001b[0m\n",
      "8 labels saved to runs/detect/predict8/labels\n"
     ]
    }
   ],
   "source": [
    "result_list = model('https://storage3.ilyo.co.kr/contents/article/images/2015/0601/1433148424953500.jpg', save=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fcd00d48",
   "metadata": {},
   "source": [
    "## 추론결과"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "49ea25ad",
   "metadata": {},
   "source": [
    "### ultralytics.yolo.engine.results.Results\n",
    "- 모델의 추론 결과는 list에 이미지별 예측결과를 Results에 담아 반환한다.\n",
    "- **Results** : 한개 이미지에 대한 추론결과를 담는 객체\n",
    "- 추론 종류에 따라 다음 속성을 이용해 결과를 조회한다.\n",
    "    - Detection: `result.boxes` - Boxes type\n",
    "    - Segmentation: `result.masks` - Masks type\n",
    "    - Classification: `result.probs` - torch.Tensor type\n",
    "    - Pose: `result.keypoints` - Keypoints type\n",
    "- 추가 정보\n",
    "    - Results.orig_img: 추론한 원본 이미지\n",
    "    - Results.orig_shape: 추론한 원본 이미지의 크기 (height, width)\n",
    "    - Results.path: 추론한 원본이미지의 경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1163e3a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T02:37:27.849021Z",
     "start_time": "2023-03-10T02:37:25.757658Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https:\\github.com\\ultralytics\\assets\\releases\\download\\v0.0.0\\yolov8x.pt to models\\yolov8x.pt...\n",
      "100%|██████████| 131M/131M [00:25<00:00, 5.46MB/s] \n",
      "\n",
      "image 1/1 e:\\Python\\ml_colab_project\\Object_Detection\\test_image\\bus.jpg: 640x480 5 persons, 1 bicycle, 1 bus, 1016.8ms\n",
      "Speed: 8.5ms preprocess, 1016.8ms inference, 14.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('models/yolov8x.pt')\n",
    "result_list = model('./test_image/bus.jpg', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "decff4f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T00:47:22.201958Z",
     "start_time": "2023-03-10T00:47:22.181626Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 1, ultralytics.yolo.engine.results.Results)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result_list), len(result_list), type(result_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18ae20f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T01:18:30.976636Z",
     "start_time": "2023-03-10T01:18:30.946843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 이미지 경로: e:\\Python\\ml_colab_project\\Object_Detection\\test_image\\bus.jpg\n",
      "원본 이미지 크기: (1080, 810)\n",
      "원본 이미지: (1080, 810, 3)\n"
     ]
    }
   ],
   "source": [
    "# 추론한 원본 이미지에 대한 정보\n",
    "result = result_list[0]\n",
    "print('원본 이미지 경로:', result.path)\n",
    "print('원본 이미지 크기:', result.orig_shape)\n",
    "print('원본 이미지:', result.orig_img.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2825ee77",
   "metadata": {},
   "source": [
    "### Object Detection 결과값 조회\n",
    "\n",
    "- ultralytics.yolo.engine.results.**Boxes**에 추론 결과를 담아 반환\n",
    "    - Results.boxes로 조회\n",
    "- 주요 속성\n",
    "    - shape: 결과 shape. (찾은 물체개수, 6)\n",
    "    - boxes\n",
    "        - 6: 좌상단 x, 좌상단 y, 우하단 x, 우하단 y, confidence score, label\n",
    "    - xyxy\n",
    "        - bounding box의 `좌상단 x, 좌상단 y, 우하단 x, 우하단 y` 좌표 반환\n",
    "    - xyxyn\n",
    "        - xyxy를 이미지 대비 비율로 반환\n",
    "    - xywh\n",
    "        - bounding box의 `center x, center y, 너비, 높이` 를 반환\n",
    "    - xywhn\n",
    "        - xywh를 이미지 대비 비율로 반환\n",
    "    - cls: 찾은 물체의 label\n",
    "    - conf: cls에 대한 confidence score (그 물체일 확률)\n",
    "    - boxes\n",
    "        - `x, y, x, y, conf, cls` tensor를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6487f920",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T01:27:01.037555Z",
     "start_time": "2023-03-10T01:27:01.020187Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'ultralytics.yolo.engine.results.Boxes'>\n"
     ]
    }
   ],
   "source": [
    "boxes = result.boxes  # detection한 결과를 조회 (Boxes 객체)\n",
    "print(type(boxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2f364174",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T01:27:30.413278Z",
     "start_time": "2023-03-10T01:27:30.389162Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 6])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes.shape\n",
    "# [n, 6] : n-찾은 bbox(object) 개수,  6-x y x y label conf  (x y x y : 좌상단 우하단 좌표)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "66c40a74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T01:31:12.123370Z",
     "start_time": "2023-03-10T01:31:12.101794Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 0., 0., 0., 0., 0., 1.], device='cuda:0')\n",
      "tensor([0.9679, 0.9310, 0.9183, 0.9019, 0.6982, 0.5386, 0.4340], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# 찾은 bbox들에 대한 classification 정보\n",
    "print(boxes.cls)  # 찾은 n개 bbox에 대한 class 들을 반환.\n",
    "print(boxes.conf) # 찾은 n개 bbox에대한 confidence score(확률) 들을 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "647c242e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T01:37:16.938027Z",
     "start_time": "2023-03-10T01:37:16.918682Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1235e+00, 2.3052e+02, 8.0427e+02, 7.4187e+02],\n",
      "        [6.6853e+02, 3.9216e+02, 8.0958e+02, 8.7981e+02],\n",
      "        [5.0541e+01, 3.9819e+02, 2.4758e+02, 9.0089e+02],\n",
      "        [2.2195e+02, 4.0614e+02, 3.4399e+02, 8.6009e+02],\n",
      "        [2.1829e-01, 5.5076e+02, 7.8429e+01, 8.7218e+02],\n",
      "        [2.3839e-01, 5.5012e+02, 7.9403e+01, 1.0642e+03],\n",
      "        [6.6626e+02, 1.5416e+01, 7.4804e+02, 9.0127e+01]], device='cuda:0')\n",
      "tensor([[1.3871e-03, 2.1345e-01, 9.9293e-01, 6.8692e-01],\n",
      "        [8.2535e-01, 3.6311e-01, 9.9948e-01, 8.1464e-01],\n",
      "        [6.2397e-02, 3.6869e-01, 3.0566e-01, 8.3416e-01],\n",
      "        [2.7402e-01, 3.7606e-01, 4.2468e-01, 7.9638e-01],\n",
      "        [2.6949e-04, 5.0996e-01, 9.6825e-02, 8.0757e-01],\n",
      "        [2.9431e-04, 5.0937e-01, 9.8028e-02, 9.8534e-01],\n",
      "        [8.2254e-01, 1.4274e-02, 9.2351e-01, 8.3451e-02]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# bbox의 위치정보\n",
    "print(boxes.xyxy)  # 좌상단 우하단 x/y좌표\n",
    "print(boxes.xyxyn) #이미지크기 대비 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0bd37164",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T01:38:38.165810Z",
     "start_time": "2023-03-10T01:38:38.146348Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[402.6980, 486.1974, 803.1489, 511.3451],\n",
      "        [739.0540, 635.9849, 141.0457, 487.6580],\n",
      "        [149.0612, 649.5397, 197.0400, 502.7070],\n",
      "        [282.9735, 633.1169, 122.0391, 453.9442],\n",
      "        [ 39.3234, 711.4676,  78.2103, 321.4178],\n",
      "        [ 39.8206, 807.1424,  79.1645, 514.0389],\n",
      "        [707.1486,  52.7720,  81.7828,  74.7110]], device='cuda:0')\n",
      "tensor([[0.4972, 0.4502, 0.9915, 0.4735],\n",
      "        [0.9124, 0.5889, 0.1741, 0.4515],\n",
      "        [0.1840, 0.6014, 0.2433, 0.4655],\n",
      "        [0.3494, 0.5862, 0.1507, 0.4203],\n",
      "        [0.0485, 0.6588, 0.0966, 0.2976],\n",
      "        [0.0492, 0.7474, 0.0977, 0.4760],\n",
      "        [0.8730, 0.0489, 0.1010, 0.0692]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(boxes.xywh)  # center x, y좌표, bbox width, height\n",
    "print(boxes.xywhn)  # center x, y좌표, bbox width, height 이미지크기 대비 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c782961a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T01:45:00.968554Z",
     "start_time": "2023-03-10T01:45:00.949314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(205, 92, 92)\n",
      "person\n",
      "goldfish, Carassius auratus\n"
     ]
    }
   ],
   "source": [
    "from module import util\n",
    "\n",
    "print(util.get_color(0))\n",
    "print(util.get_coco80_classname(0))\n",
    "print(util.get_imagenet_classname(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "753dfe79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T01:49:19.595145Z",
     "start_time": "2023-03-10T01:49:19.585693Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bus'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = boxes.cls[0]\n",
    "\n",
    "util.get_coco80_classname(int(idx.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55a13893",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T02:39:36.686733Z",
     "start_time": "2023-03-10T02:39:34.470549Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/parking/anaconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/conv.py:459: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "image 1/1 /home/parking/ml/ml_colab_project/Object_Detection/test_image/1.jpg: 480x640 8 persons, 2 bicycles, 5 cars, 1 motorcycle, 2 buss, 3 traffic lights, 1 dog, 1 backpack, 2 handbags, 129.8ms\n",
      "Speed: 1.1ms preprocess, 129.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict13\u001b[0m\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'util' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m pt1 \u001b[39m=\u001b[39m xyxy_arr[:\u001b[39m2\u001b[39m]\n\u001b[1;32m     22\u001b[0m pt2 \u001b[39m=\u001b[39m xyxy_arr[\u001b[39m2\u001b[39m:]\n\u001b[0;32m---> 24\u001b[0m label_name \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mget_coco80_classname(\u001b[39mint\u001b[39m(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mitem()))\n\u001b[1;32m     25\u001b[0m txt \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlabel_name\u001b[39m}\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m{\u001b[39;00mconf\u001b[39m.\u001b[39mitem()\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m color \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mget_color(\u001b[39mint\u001b[39m(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mitem()) \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'util' is not defined"
     ]
    }
   ],
   "source": [
    "# 원본 이미지에 추론 결과를 출력\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('models/yolov8m.pt')\n",
    "path = 'bus.jpg'\n",
    "path = 'test_image/1.jpg'\n",
    "result_list = model(path, save=True)\n",
    "result = result_list[0]\n",
    "\n",
    "org_img = result.orig_img  #BGR\n",
    "img = org_img.copy()\n",
    "\n",
    "boxes = result.boxes\n",
    "xyxy_list = boxes.xyxy  #좌상단/우하단 좌표\n",
    "cls_list = boxes.cls    #label\n",
    "conf_list = boxes.conf  #label  확률.\n",
    "for xyxy, cls, conf in zip(xyxy_list, cls_list, conf_list):\n",
    "#     print(xyxy, conf, cls)\n",
    "    xyxy_arr = xyxy.to('cpu').numpy().astype('int32')\n",
    "    pt1 = xyxy_arr[:2]\n",
    "    pt2 = xyxy_arr[2:]\n",
    "    \n",
    "    label_name = util.get_coco80_classname(int(cls.item()))\n",
    "    txt = f\"{label_name}-{conf.item()*100:.2f}\"\n",
    "    \n",
    "    color = util.get_color(int(cls.item()) % 10)\n",
    "    # bbox\n",
    "    cv2.rectangle(img, pt1=pt1, pt2=pt2, color=color, thickness=2)\n",
    "    # label\n",
    "    cv2.putText(img, text=txt, org=pt1-5, fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.5, \n",
    "                color=color, thickness=1, lineType=cv2.LINE_AA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f4d39f28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T02:47:26.274458Z",
     "start_time": "2023-03-10T02:47:08.973212Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m코드를 실행할 수 없습니다. 세션이 삭제되었습니다. 커널을 다시 시작해 보세요."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "cv2.imshow('frame', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59ff3703",
   "metadata": {},
   "source": [
    "## 실시간 Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d0397a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T05:27:33.119152Z",
     "start_time": "2023-03-10T05:27:05.214673Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from module import util\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# 웹캠 연동\n",
    "cap = cv2.VideoCapture(0)\n",
    "# 모델 생성\n",
    "model = YOLO('models/yolov8n.pt')\n",
    "while True:\n",
    "    # 한 Frame 읽기\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        print('프레임을 읽지 못함')\n",
    "        break\n",
    "        \n",
    "    frame = cv2.cvtColor(cv2.flip(frame, 1), cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    result = model(frame)[0]\n",
    "    xyxy_list = result.boxes.xyxy.to('cpu').numpy().astype('int32')\n",
    "    cls_list = result.boxes.cls.to('cpu').numpy().astype('int32')\n",
    "    conf_list = result.boxes.conf.to('cpu').numpy()\n",
    "    \n",
    "    for xyxy, cls, conf in zip(xyxy_list, cls_list, conf_list):\n",
    "        pt1, pt2 = xyxy[:2], xyxy[2:]\n",
    "        txt = f\"{util.get_coco80_classname(cls)}-{conf*100:.2f}%\"\n",
    "        color = util.get_color(cls % 10)\n",
    "        cv2.rectangle(frame, pt1, pt2, color=color)\n",
    "        cv2.putText(frame, txt, org=pt1, fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1,\n",
    "                    color=color, thickness=2, lineType=cv2.LINE_AA)\n",
    "        \n",
    "    # 화면에 출력\n",
    "    cv2.imshow('frame', cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    if cv2.waitKey(1) == 27: # esc \n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "d6bb26803bcea62f49e4c67963aa289be587a14c784102c9499967ce94407a08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
